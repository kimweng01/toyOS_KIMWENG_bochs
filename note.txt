#電腦啟動
電腦啟動時，BIOS會從0xffff0進入，然後跳到0xfe05b處，正式開始BIOS
接著BIOS會檢查硬體、建立中斷向量表，
然後呼叫bios中斷，檢查第一磁區的最後兩個單位是不是0x55和0xaa，
如果是，則將第一磁區載入到0x7c00，然後跳到0x7c00(32KB-1KB=0x7c00)。


#在MBR中
顯示1 MBR，然後讀取硬碟位於第二個磁區的loader到0x900，然後跳到0x900。
(載到0x900的原因在3.6.1)

#在loader中
構建GDT，構建選擇子(SELECTOR_CODE equ (0x0001<<3) + TI_GDT + RPL0...這種)，
構建GDT暫存器(gdt_ptr  dw  GDT_LIMIT...)，紀錄GDT的起始位置及界限。

/第四章
顯示2 loader in real，
打开A20以關閉迴繞，加载GDT，
cr0第0位置1，正式開啟保護模式，
jmp刷新管線，最後顯示P

/第五章
測量記憶體大小，
打开A20以關閉迴繞，建立GDT，設置GDTR，
cr0第0位置1，正式開啟保護模式，
jmp刷新管線，建立分頁(call setup_page)，
然後把GDT暫存器從CPU裡面載回gdt_ptr，修改VIDEO段描述符號的段基址，加上0xc0000000，
再將GDT暫存器的GDT_BASE，加上0xc0000000，
開啟分頁後，任何位址只要是0xc0000000一定會被洗成0x00000000!
(0xc0000000的高10位元乘以4後是0xc00，
而分頁目錄表是從0x100000開始算，所以此結果會對應到記憶體0x100c00的位置)，
接著賦予分頁目錄表地址，打開cr0的pg，正式進入分頁模式，最後顯示V。

/第六章
測量記憶體大小，
打開A20以關閉迴繞，建立GDT，設置GDTR，
cr0第0位置1，正式開啟保護模式，
	然後從硬碟的第9區開始把kernel載到記憶體的0x70000處
jmp刷新管線，建立分頁(call setup_page)，
然後把GDT暫存器從CPU裡面載回gdt_ptr，修改VIDEO段描述符號的段基址，加上0xc0000000，
再將GDT暫存器的GDT_BASE，加上0xc0000000，
開啟分頁後，任何位址只要是0xc0000000一定會被洗成0x00000000!
(0xc0000000的高10位元乘以4後是0xc00，
而分頁目錄表是從0x100000開始算，所以此結果會對應到記憶體0x100c00的位置)，
接著賦予分頁目錄表地址，打開cr0的pg，正式進入分頁模式，
	然後，顯示Virtual kernel while(1)。
	接著查elf把kernel複製到它應該要在的位置，然後跳到kernel"真正可執行程式"的開始處，即0xc0001500。


#在kernel中
/第六章
在print.S實現一系列的印刷函數，顯示I am a kernel、數字等字。
	
/第七章
/a
沿用第六章實現的一系列的印刷函數，要輸出文字訊息時會用到。
在kernel.S創建中斷處理常式"群(表)"，
在interrupt.c建立IDT，把IDT內的33個中斷門描述符號都一一設好。
初始化中斷控制晶片8259A，然後設置只允許時脈中斷(IR0)。
然後把裡面寫滿33個中斷門描述符號的IDT的基址和表界線賦予CPU內的IDT暫存器(IDTR)。
/b
內容基本上跟a差不多，只不過中斷處理常式的一部份寫在interrupt.c的general_intr_handler函數裡面，
進入中斷處理常式後，不再顯示"interrupt occur!"，會call進general_intr_handler並傳入中斷號的數字，
在interrupt.c顯示"int vector : 中斷號"。
/c
跟b一樣，不過有額外加入timer.c去修改PIT8253的計時頻率

-----------------------------------------------------------------------------------------------
/第七章最後統整(從idt_init開始說起):


<宣告>
/在interrupt.c中
宣告static struct gate_desc idt[IDT_DESC_CNT]，裡面放的是 中斷門描述符號 ，共0x21個，
							^~~			  				  ^~~~~~~~~~~~~~
宣告intr_handler idt_table[IDT_DESC_CNT]，裡面放的是 中斷處理常式 ，共0x21個，
				 ^~~~~~~~~			 				 ^~~~~~~~~~~~
intr_handler的類型為void*，void* 表示此類型是一個指標，指向任何類型皆可，idt_table[IDT_DESC_CNT]。


<初始化>
/在interrupt.c中
首先顯示"idt_init start\n"，然後進入idt_desc_init以初始化中斷門描述符號"表"，
	在idt_desc_init內用for迴圈連續呼叫0x21次make_idt_desc，以建立 中斷門描述符號，
	
	###&idt[i]會傳入make_idt_desc，
	###idt[i]表示IDT中第i個中斷門描述符號(struct gate_desc)，
	###&idt[i]代表第i個中斷門描述符號(struct gate_desc)的位址，
	###&idt[i]傳入make_idt_desc會變成p_gdesc，
	###藉由p_gdesc->XXX為中斷門描述符號(struct gate_desc)的內容賦值。
	
		在make_idt_desc內填入:
		第i個中斷處理常式 所在的低位址(function低16位) 、
		GDT選擇子(此選擇子對應的段描述符號的段基址為0，所以 第i個中斷處理常式 所在的位址可以直接拿來當偏移量使用)、
		p_gdesc->dcount(中斷門描述符未使用的部分 直接填0)、
		p_gdesc->attribute = attr(權限等級，以IDT_DESC_ATTR_DPL0傳入，其內容定義在global.h)，
		第i個中斷處理常式 所在的高位址(function高16位)，
		
		###在kernel.S的intr_entry_table中
		###用巨集的方式宣告了0x20=[0~32]=33個 intr_entry_table內 "一模一樣" 的東西，
		###即intr_entry_table內有33個 "一模一樣" 的中斷處理常式
		###(call [idt_table + %1*4]的idt_table的內容定義在interrupt.c，這條code除外)
		###例如33有個section .text、section .data和intrXXentry，
		
		###intr_entry_table[i]傳入make_idt_desc變成function，
		###kernel的起始位置在0xc0001500，
		###intr_entry_table為中斷處理常式"群(表)"所在的位址，定義在kernel.S，
		###intr_entry_table[i]為"群中"的第i個中斷處理常式在記憶體的位址，即0xc000XXXX，
		###由於在平坦模式下，段基址為0，所以0xc000XXXX可以直接拿來當偏移量使用，
		###而由於kernel.S的巨集定義，intr_entry_table[i]內的內容一模一樣，
		###只有call [idt_table + %1*4]因為idt_table定義在interrupt.c的關係，所以這條code除外，
		
	從make_idt_desc返回並顯示"   idt_desc_init done\n"。

進入exception_init，以初始化(註冊)中斷處理常式，
	
	在exception_init內同樣用for迴圈在 idt_table[i]內 放入中斷處理常式的函數位址(函數名字代表函數的位址)，
	共放0x21個，裡面先全放general_intr_handler(默認，即暫時先統一賦予一樣的 中斷處理常式)，
	同時也初始化intr_name[i]，裡面暫時先全放"unknown"，
	然後再一一把中斷處理常式的名字依序填入intr_name[i]中，這樣沒填到的都會是"unknown"，

接著賦予idt_operand中斷描述符號暫存器(IDTR)的內容，
高32位存IDT的基礎位址，其值為idt，
低16位元為IDT的表界線，其值為sizeof(idt)-1，從0開始算，
然後用asm volatile("lidt %0" : : "m" (idt_operand))把中斷描述符號暫存器的內容放入CPU內的中斷描述符號暫存器(IDTR)，
最後顯示"idt_init done\n"，完成所有有關中斷的初始化。

HINT:
IDT內有33個中斷門描述符號，33個中斷門描述符號中的選擇子都是要選GDT的第1個段描述符，
GDT的第1個段描述符號描述的中斷處理常式的段基址為0(平坦模式)，
中斷處理常式的各個偏移量為kernel.S中巨集內的各個section，值為0xc000XXXX。
由於段基礎位址為0，所以0xc000XXXX可以直接拿來當偏移量使用。
中斷門描述符號中的偏移量(會存入EIP)+段基址(會存入CS)即可得到中斷處理常式的實際位址。


<運行>
首先先初始化跟中斷有關的內容，再初始化計時控制器8259A，接著開中斷，等到時脈(計時器)中斷發生(在timer.c有修改計時控制器內容)，
然後CPU會先壓棧，如果有特權等級變化，會先壓入SS(堆疊基址)和ESP，沒有特權等級變化則不壓這兩個入棧，
然後壓入EFLAGS、CS、EIP、ERROR_CODE，

然後用 中斷描述符號暫存器(IDTR)找到IDT的基礎地址，
接著用中斷向量號(時脈中斷是0x20)找對應的中斷門描述符號，
中斷門描述符內有GDT選擇子，可以選擇GDT內第幾個段描述符號，
得到段基礎位址，然後把IDT內的偏移量+段基礎位址，得到 中斷處理常式在記憶體的位址(即intr_entry_table[0x20]) ，

/kernel.S
###由於kernel.S的巨集定義，intr_entry_table[i]內的內容一模一樣，
###只有call [idt_table + %1*4]因為idt_table定義在interrupt.c的關係，所以這條code除外，

保存上下文環境，發送EOI指令，設為手動結束，
壓入中斷向量號(把中斷向量號當參數傳入)，
然後call [idt_table + %1*4]，

###需要注意:                                                                                  
###	在組合語言，函數的呼叫方式就是 call 函數名字，                                            
###	所以函數的名字本質就是個地址，    	                                                      
###	把這i個 中斷處理常式的地址 放入idt_table[i]中，共放0x21個，                               
###	[idt_table + %1*4]為放 欲存取的 中斷處理常式的地址，                                      
###	call [idt_table + %1*4] 等於 call 欲存取的 中斷處理常式的地址。

/interrupt.c
進入general_intr_handler，不處理偽中斷，
再顯示三組文字，分別是put_str("int vector: 0x") put_int(vec_nr) put_char('\n')，然後離開general_intr_handler，

/kernel.S
jmp intr_exit，恢復上下文環境，然後從中斷返回。
-----------------------------------------------------------------------------------------------

/第八章
/a
interrupt.c再加入中斷開、關函數，然後加入debug.c以實現ASSERT。
###---------------------------------------------------------
###(ASSERT的巨集設置解釋在debug.h)
###ASSERT的括號內的內容一定要成立，不然ASSERT就會觸發!
###---------------------------------------------------------
編寫Makefile，使指令輸入能簡化
/b
新增string.h並實現其大致的內容
/c
新增點陣圖
/d
新增核心池、使用者池、虛擬位址池，
為三者計算出大小、起始地址、配置點陣圖。
/e
實現分頁分配(malloc_page)函數，詳細解釋在memory.c最下面

-----------------------------------------------------------------------------------------------
第八章最後統整:


/memeory.c
<需要注意>
目前已經開啟分頁模式，也就是CPU看到的都是虛擬地址，需要做三次映射才會到物理地址上。
因此物理地址只能填在分頁目錄表或分頁表裡，
讓CPU用 看到的地址 去分頁目錄表或分頁表裡找 物理地址 去作映射，
物理地址不能直接給CPU!

/loader.S
還在loader.S中的時候:
分頁目錄表全歸0，
分頁目錄表的 高四分之一處的 第0個位置(從0開始算)寫第0個分頁的基底位址，
分頁目錄表的 高四分之一處的 第1個位置(從0開始算)寫第1個分頁的基底位址...
分頁目錄表的 高四分之一處的 最後一個位置寫 分頁目錄表自己的 基底位址，即指向分頁目錄表自己，
最後往 分頁目錄表的高四分之一處 寫256個 分頁表的位址，第0個分頁表的低四分之一處 寫256個 分頁的位址。

核心的虛擬位址都要是0xcXXXXXXX開頭，即 高10位元 拆出來都對應到的 分頁目錄表高四分之一處 的位置，
小於0xcXXXXXXX的地址的 高10位元 拆出來會對應到 分頁目錄表的 低四分之三處 位置，
這些都是 使用者 要用的用的 虛擬位址。

而虛擬位址小於0xc0100000的 中10位元 拆出來會對應到 分頁表內最一開始在loader被寫256次的地方，
所以虛擬位址(vaddr)要從0xc0100000開始算起。

點陣圖有三個，
核心的點陣圖檢查核心內存池(在實體記憶體0x200000以上的位置)的每個 分頁 有沒有被使用，
使用者的點陣圖檢查使用者內存池(在實體記憶體0x200000以上的位置)的每個 分頁 有沒有被使用，
虛擬位址的點陣圖檢查該虛擬位址(從0xc0100000開始算)有沒有被使用，
三個點陣圖使用前都會先歸0。
三個點陣圖使用前都會先歸0。


<函數介紹>
vaddr_get函數在找pg_cnt個沒被使用的虛擬位址(該虛擬位址指向分頁的基底位址，所以一定要是000結尾)，
找到的話把點陣圖的pg_cnt個位元置1，
返回這 "pg_cnt個"沒被使用的 虛擬位址的 "第0個"的 "虛擬地址"，
該地址的計算方法為 找到的"pg_cnt個"沒被使用的 "第0個"的 "點陣圖位址"，
把這"點陣圖位址"乘4K(點陣圖的一個位元代表1個分頁大小) 再+虛擬位址的起始地址="第0個"的 "虛擬地址"。
vaddr_get只是在檢查該 虛擬位址 有沒有被使用而已，沒被使用就會被分配出去，不觸及內存池!

pte_ptr函數的目的在獲得 指向vaddr的指標(黑色箭頭)的 存放"位址" (黑色箭頭畫在筆記照相記憶體圖裡)，
意即要取得 從vaddr拆出的中10位 要填的"位址"，
此指標的構建方法為:
在高10位元寫10個1(0xffc00000)，
vaddr原本高10位元的寫到中10位元處，
vaddr原本高10位元的寫到低12位元處並乘以4(低12位元處理器不會自動乘4)，
在高10位元寫10個1，等於對應到分頁目錄表裡最後一個項目，該項目指向自己，
等於最一開始多打轉了一圈，處理器只剩下兩次映射的機會，最後的結果就是存黑色箭頭(指標)的"位址"。

pde_ptr函數的目的在獲得 指向vaddr的黑色箭頭的 紅色箭頭(看筆記照相圖) 的 存放"位址"，
原理跟pte_ptr函數差不多，只是在高20位元全部寫1，vaddr原本的高10位元寫到低12位元並乘4，
等於最一開始多打轉了兩圈，處理器只剩下一次映射的機會，最後的結果就是存紅色箭頭(指標)的"位址"。

palloc函數等於在核心存池或使用者內存池尋找1個能用的 分頁，
找到的話把該位元置1，並回傳內存池內的 該分頁表的 基底物理位址。
該地址的計算方法為 找到的"1個"沒被使用的 "XX物理點陣圖的位"，
把這"XX物理點陣圖的位"乘4K(點陣圖的一個位元代表1個分頁大小) 再+XX物理位址的起始地址=找到的"1個"沒被使用的 物理地址。

page_table_add函數目的在 虛擬地址_vaddr 與 物理地址_page_phyaddr 作映射，
(該物理地址是分頁的物理地址，所以一定是像0xXXXXX000三個0作結為)
意思是要確保把虛擬地址(_vaddr)給CPU映射3次後的結果能落到正確的物理地址(_page_phyaddr)上，
如果分頁目錄表和分頁表內沒有出現該有的值要填寫進去，這會用到pte_ptr函數和pde_ptr函數，
要先檢查_vaddr映射到分頁目錄表內的內容是否存在，即判斷紅色箭頭是否存在，
如果紅色箭頭存在(*pde & 0x00000001 == true)，
	會檢查_vaddr映射到的分頁表內的內容(分頁)是否存在，即檢查黑色箭頭是否存在，
	如果存在(*pte & 0x00000001 == true)，
		等於是你要創造的分頁已經存在了，在malloc_page函數中，
		只要一找到pg_cnt個虛擬位址就會為它們填表，並為虛擬位址的點陣圖填1。
		所以不可能發生找到的虛擬位址(虛擬位址點陣圖為0)的數值已經填入表內的狀況，
		所以會ASSERT。
	如果不存在(*pte & 0x00000001 == false)，
		則直接把物理地址跟PG_US_U | PG_RW_W | PG_P_1作OR運算並寫進去分頁表內，
		這樣CPU映射兩次完到分頁表內的時候，可以直接拿分頁表內的地址映射到物理地址上(第三次)。
		分頁內的內容要不要歸0交給類似get_kernel_pages的這種外部的函數來決定。
如果連紅色箭頭也不存在(*pde & 0x00000001 == false)的話，那就得先創造紅色箭頭再創黑色箭頭，
因為在loader.S的時候只要有創一個 分頁表 就會讓紅色箭頭指向它，
所以表示說現在連紅色箭頭都沒有表示連個 分頁表 也都沒有，
需要在原本放 分頁 的地方額外讓出一個放 分頁表 的大小的空間(分頁表大小=分頁大小)給分頁表，
即用創 分頁 的方式創一個 分頁表。
	用palloc函數創造一個新的分頁表，回傳值為 新分頁表的 基底物理位址，
	把 新分頁表的 基底物理位址跟PG_US_U | PG_RW_W | PG_P_1作OR運算並寫進去分頁目錄表內，
	然後新創的分頁表裡面要全歸0，但是要用"CPU讀的地址"去歸0，
	也就是這地址是要給CPU讀的，不是寫進XXX表裡的，所以要給CPU"虛擬地址"去歸0。
	分頁表的 虛擬起始位址 就是把原本 存黑色箭頭的地址 從0xXXXXXXXX 變成 0xXXXXX000，
	把該地址(0xXXXXX000)給mem_set，要歸0的數量=1個頁表的大小=4K，這樣就可以全歸0了。
需要注意，一定要先看紅色箭頭在不在再去找黑色箭頭，要不然直接找黑色箭頭結果沒有紅色箭頭就會page_fault!
	
malloc_page函數目的是要分配pg_cnt個 分頁，
然後返回申請到的 配pg_cnt個分頁的 第0個分頁的 虛擬地址，該虛擬地址經過三次映射後會對應到物理地址，
也就是兩個表裡面該寫的內容都要填進去，等於要用到以上所有的函數。
首先要找到pg_cnt個能用的虛擬位址，要用vaddr_get函數獲得pg_cnt個沒被使用的 "第0個"的 "虛擬地址"，
然後進入while迴圈，
	用palloc函數為pg_cnt個分頁一個一個尋找能用的分頁，得到一個分頁的 物理地址。
	然後用page_table_add把該填的 物理地址的數值 填到兩個表內
	然後 vaddr+分頁大小(vaddr是 "分頁" 的 虛擬地址，所以vaddr的下一個地址是+分頁大小)， 
	再去為下一個分頁尋找能用的 物理地址 並填表。
最後返回pg_cnt個分頁的 第0個分頁的 虛擬位址。
需要注意的是，虛擬地址是連續的，可以在vaddr_get直接給pg_cnt傳進去函數一次找完，
而物理地址可以是不連續的需要在while迴圈內 一個分頁一個分頁 找。	

get_kernel_pages函數是本memory.c的最終目的，要從核心的物理內存池申請pg_cnt個分頁，
需調用malloc_page函數，再把申請到的pg_cnt個分頁全部清0。	*/
-----------------------------------------------------------------------------------------------

/第九章

a/
/thread.c
加入thred.c，實現執行緒大部分內容，為執行緒的PCB分配分頁，實現為PCB內加入三大內容的函數，
PCB(一個分頁)的低地址處放 程式控制結構(task_struct) ，
高地址處放 中斷堆疊(intr_stack)，次高地址處放 執行緒堆疊(thread_stack)，
 執行緒堆疊 會往低地址處擴張，與位於低地址的 程式控制結構 漸漸"夾止"

b/
/thread.c
加入list.c，加入鏈結串列結構以及相關函數，
需要注意，鏈結串列結構為雙向的，有head和tail，struct的type為list_elem皆只有*prev和*next，沒有val，因為不需要，
head和tail又被封裝在struct list內，struct的type為list，所以存取頭或尾需要用類似list->head.next的方式。

c/
/thread.c
修改init_thread，
在init_thread加入對main函數的stat的設置，如果是main，直接設為TASK_RUNNING，因為main一直是在執行的，
其他函數的話要先init成TASK_READY，
然後加入make_main_thread函數，
為main函數在0xc009e000處打造成一個屬於main的主執行緒，
因為main主執行緒的位置在0xc009e000，不需要另外再配一個分頁，
然後只將main加入thread_all_list中，因為main已經在執行了，所以不需要加入thread_ready_list!
/interrupt.c
修改general_intr_hander函數內的 中斷處理常式 ，加入將游標設置為0，把上四行清空並添加能顯示中斷訊息的程式。
/print.S
修改print.S，
新增global set_cursor，讓interrupt.c可以呼叫
/timer.c
修改timer.c，為時脈中斷額外配置一個"專屬的"中斷處理常式，
然後在timer_init函數用register_handler函數註冊安裝"專屬的"中斷處理常式。
/interrupt.c
為 時脈中斷額外配置的中斷處理常式 安裝註冊到idt_table[0x20]中，
把原本idt_table[0x20]內默的 中斷處裡常式(general_intr_handler) 換成時脈中斷"專屬的"中斷處理常式。
加入schedule函數，實現工作排程。
-----------------------------------------------------------------------------------------------

/第十章
a/
加入PV操作幾乎所有的內容，在thread加入thread_block與thread_unblock函數，分別為執行緒阻塞和解除阻塞，
新增sync.c加入 鎖 、 號誌 的相關函數
b/
測試終端機的PV操作，加入console.c

-----------------------------------------------------------------------------------------------
第九章+第十章PV操作統整


<PCB內三大struct的位置(上為低地址，下為高地址)>

							---------PCB(分頁)基址---------
##################################################################################
##	struct task_struct {                                               			##
##		uint32_t* self_kstack;	// 各内核线程都用自己的内核栈                  	##
##		enum task_status status;                                                ##
##		char name[16];                                                          ##
##		uint8_t priority;                                                       ##
##		uint8_t ticks;	   		// 每次在处理器上执行的时间嘀嗒数               ##
##                                                                              ##
##		此任务自上cpu运行后至今占用了多少cpu嘀嗒数,                             ##
##		也就是此任务执行了多久                                                  ##
##		uint32_t elapsed_ticks;                                                 ##
##                                                                              ##
##		general_tag的作用是用于线程在一般的队列中的结点                         ##
##		struct list_elem general_tag;				                            ##
##                                                                              ##
##		all_list_tag的作用是用于线程队列thread_all_list中的结点                 ##
##		struct list_elem all_list_tag;                                          ##
##		                                                                        ##
##		uint32_t* pgdir;		// 进程自己页表的虚拟地址                		##
##		uint32_t stack_magic;	// 用这串数字做栈的边界标记,用于检测栈的溢出	##
##	};                                                                 			##
##################################################################################

										/\
									   /||\
										||
										||
										||
										||
										||
					執行緒堆疊(thread_stack)由高地址往低地址生長
##############################################################################################
##	struct thread_stack {                                          							##
##		uint32_t ebp;                                              							##
##		uint32_t ebx;                                              							##
##		uint32_t edi;                                              							##
##		uint32_t esi;                                              							##
##	                                                               							##
##		void (*eip) (thread_func* func, void* func_arg);           							##
##		void (*unused_retaddr);                                    							##
##		thread_func* function;	由Kernel_thread所调用的函数名，類型為void (*function)(void*)##
##		void* func_arg;    	  	由Kernel_thread所调用的函数所需的参数						##
##	};                                                              						##
##############################################################################################
				!!!thread_stack緊接在intr_stack的上面(低地址處)!!!
##############################################################################################
##	struct intr_stack {                                                           			##
##		uint32_t vec_no;	 <---低地址		kernel.S 宏VECTOR中push %1压入的中断号    		##
##		uint32_t edi;                                                                 		##
##		uint32_t esi;                                                                 		##
##		uint32_t ebp;                                                                 		##
##		uint32_t esp_dummy;	 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略		##
##		uint32_t ebx;                                                                 		##
##		uint32_t edx;                                                                 		##
##		uint32_t ecx;                                                                 		##
##		uint32_t eax;                                                                 		##
##		uint32_t gs;                                                                  		##
##		uint32_t fs;                                                                  		##
##		uint32_t es;                                                                  		##
##		uint32_t ds;                                                                  		##
##		                                                                              		##
##		以下由cpu从低特权级进入高特权级时压入                                         		##
##		uint32_t err_code;	err_code会被压入在eip之后                                 		##
##		void (*eip) (void);                                                           		##
##		uint32_t cs;                                                                  		##
##		uint32_t eflags;                                                              		##
##		void* esp;                                                                    		##
##		uint32_t ss; 	    <---高地址                                                		##
##	};                                                                            			##
##############################################################################################
							---------PCB(分頁)頂端---------
							
-------------------------------------------------------------------------------------------

<初始化>
/thread.c
在thread_init函數內，顯示"thread_init start\n"，
初始化兩個鏈結串列結構，分別是thread_ready_list和thread_all_list，這兩個的type都是list，
	
	list_init定義在list.c，功能為把head跟tail互指，

進入make_main_thread，
	
	用running_thread取得現在esp所在的PCB(分頁)的基底位址，
		
		running_thread的原理就是用0xfffff000作and，就可以獲得esp所在的PCB(分頁)的基底位址了，返回該基底位址。
	
	把返回的PCB(分頁)基底位址給main_thread。
		
		###PCB(分頁)的基底位址為 程式控制結構(task_struct) 的第一個元素 ，即 uint32_t* self_kstack。

	進入init_thread，傳入剛獲得的PCB基底位址(main_thread)、名字("mian")、優先級(31)，	
		
		用memset把PCB整個清0(每次使用新分頁都要先清0)，
		用strcpy把名字賦予pthread->name，
		把 pthread(剛申請到的分頁的虛擬基底位址) 整個用 memset 清0，
		把 名字(name) 複製到 pthread->name (strcpy要兩個參數都為NULL才會ASSERT，由於傳入的name不為NULL，所以不會ASSERT)，
		pthread->status的 status 為 列舉task_status 內的 "標號"，把號碼給status，由於現在是初始化main函數，所以號碼為TASK_RUNNING，
		pthread->priority = prio即把優先順序(priority)賦予prio
		pthread->self_kstack = (uint32_t*)((uint32_t)pthread + PG_SIZE)即把 分頁頂的地址 給self_kstack，self_kstack為堆疊底，PG_SIZE為4096，
		由於堆棧會由高地址往低地址生長，所以為了不撞到位在底層的struct task_struct，所以要定一個界線，目前暫定為0x19960927。
	
	ASSERT檢查main是否符合 不在就緒對列(thread_ready_list)中 ，
	把main放入所有工作佇列(thread_all_list)。
	

<無PV的運行>
####假如A、B、C函數內要輸出螢幕到文字的函數都用PV包圍，
####而main的時間到時，main在PV外，而A時間到時，A正在執行PV內的輸出到螢幕的函數，

############################################
##init_all以後，目前鏈結串列的情況:       ##
##	                                      ##
##	thread_ready_list:		A<-B<-C<-D    ##
##	正在執行:				main          ##
##  waiters:              	無		      ##
##  中斷:                  	關            ##
############################################

init_all以後，用thread_start函數封裝A、B、C、D三個函數，

/thread.c
	假如現在要封裝A函數，在thread_start中，先申請一個kernel分頁，此分頁作為PCB，thread為該PCB(分頁)的基底地址，
	把為A函數申請的PCB的基底地址、函數名字、優先級傳入init_thread(在初始化main時進去過一次)，
		
		進入init_thread，由於目前系統正在進行的是main函數，還沒進行A函數，所以在init_thread中，把pthread->status設為TASK_READY，
		其餘做的事情跟 初始化main時 ，在init_thread中做的事情相同。
	
	進入thread_create，目前PCB的棧頂是在PCB的最頂端，
	先保留中斷使用堆疊(intr_stack)的空間、再保留執行緒使用堆疊(thread_stack)的空間，
	把減完兩次的self_kstack 強制轉化 為執行緒堆疊指標(struct thread_stack*)，賦予struct thread_stack* kthread_stack，
	因此現在的棧頂變成在執行緒堆疊(thread_stack)的低地址處(棧頂值一直存放在pthread->self_kstack的位置)，
	把現在的棧頂值給struct thread_stack* kthread_stack，
	
	kthread_stack->eip = kernel_thread; 把kernel_thread函數(定義在本檔最上面)的地址給eip，
	kthread_stack->function = function; 把function給函數指標(名字也叫function)，此時為賦予A函數，
	kthread_stack->func_arg = func_arg; 賦予void function(void*)的參數，此時賦予A的一個參數，
	kthread_stack->ebp = kthread_stack->ebx = kthread_stack->esi = kthread_stack->edi = 0; 剩下的暫存器全歸0，
	
	A函數的PCB要有 中斷使用堆疊(intr_stack) 和 執行緒堆疊(thread_stack)的原因是:
	假如main要交出CPU給A，則函數從main轉移到A需要用到上面kthread_stack的內容，
	由於main是最頂端的函數，沒有人會交棒給他，所以main的PCB不需要有這兩個結構，
	
	用list_append函數把 A函數的 PCB的 程式控制結構(struct task_struct)內的 general_tag 放入就緒隊列(thread_ready_list)，
	用list_append函數把 A函數的 PCB的 程式控制結構(struct task_struct)內的 all_list_tag 放入全部執行緒隊列(thread_all_list)，
	放入前都要先用ASSERT檢查是不是都沒在隊列裡面，
	
	返回PCB(分頁)的基底位址，至此A函數封裝完成。
	
	P.S. 現在thread_start函數內沒有這條code:
	asm volatile ("movl %0, %%esp; pop %%ebp; pop %%ebx; pop %%edi; pop %%esi; ret" : : "g" (thread->self_kstack) : "memory")，
	這是在 第九章a 的時候測試PCB用的，當時不需時脈中斷，thread_create函數內最後執行此code即可執行被封裝的函數!
	
用thread_start封裝剩下的B、C、D函數，封裝完後，開啟中斷。

現在正在執行main函數，等待時脈中斷出現，時脈中斷出現後，會進入kernel.S的intr_entry_table，

/kernel.S
壓棧保護棧存器並開啟EOI動調整後，接著call進時脈中斷的中斷處理常式(intr_timer_handler)，
若沒有特別註冊安裝則會進入general_intr_handler，

/timer.c
用running_thread()獲得現在的PCB的基礎地址，此值賦予cur，
在intr_timer_handler中，檢查程式控制結構(task_struct)的最末元素是不是跟最開始設的一樣，
如果不一樣，表示被執行緒堆疊(thread_stack)覆蓋上去了，即越界，要ASSERT，
紀錄main執行緒經過的tick(中斷一次則 +1 tick)，紀錄從開啟中斷以來經過的tick數，
每中斷一次就cur_thread->ticks--並回到kernel.S從離開中斷處理常式，
減到0的話表示該執行緒時間到，準備被換下CPU，調用thread的schedule()函數，

	/thread.c
	在schedule()中，檢查中斷是否INTR_OFF(進入中斷處理常式CPU會關掉中斷)，
	現在是因為時間到而進入schedule()，所以 cur->status 一定會等於 TASK_RUNNING ，
	把main放入就緒隊列"尾"，重置mian函數的執行緒的ticks數，把cur->status變成TASK_READY，

	ASSERT檢查，就緒隊列不能為空，
	清空thread_tag，因為thread_tag是全域變數，清空一下比較保險，
	把就緒隊列第一個執行緒的general_tag彈出，將該general_tag賦予thread_tag，
	用elem2entry從general_tag推導出此general_tag所屬的PCB的基底位址，將該值給struct task_struct* next，
	把next->status設為TASK_RUNNING，然後進入switch_to函數，傳入cur和next，

		/switch.S
		進入switch_to函數，壓入esi edi ebx ebp四個暫存器，根據ABI約定，call自己寫的組語程式要保護這四個暫存器可以確保對結果不會有影響
		(P.S. 進入中斷處理常式的話要保護所有暫存器保護現場)，
		獲取傳入的參數cur(cur為目前main所在PCB的基底位址)，把現在的esp放入main所在PCB的基底位址保存，<=============重要!!!!!!

		獲取下一個參數next(下個順位的PCB的基底位址)，從下個順位的PCB的基底位址拿取下個順位的PCB的esp，
		###!!!因為下個順位(A執行緒)還沒被執行過，也就是A的esp還沒被動過!!!###，<===================================重要!!!!!!
		所以根據struct thread_stack的結構，esp在switch.S被更新成A的esp的瞬間，esp會指著向"A的PCB"的下圖的位置:

		##############################################################################################
		##	struct thread_stack {                                          							##
		##		uint32_t ebp;  <==esp!!!                                            				##
		##		uint32_t ebx;                                              							##
		##		uint32_t edi;                                              							##
		##		uint32_t esi;                                              							##
		##	                                                               							##
		##		void (*eip) (thread_func* func, void* func_arg);           							##
		##		void (*unused_retaddr);                                    							##
		##		thread_func* function;	由Kernel_thread所调用的函数名，類型為void (*function)(void*)##
		##		void* func_arg;    	  	由Kernel_thread所调用的函数所需的参数						##
		##	};                                                              						##
		##############################################################################################

		switch_to的最後，
		彈出四個數值給CPU內真正的暫存器，等於把 "A的PCB"的 struct thread_stack的 esi edi ebx ebp的值 彈出給CPU內四個真的esi edi ebx ebp暫存器，
		彈出後，esp會指向(*eip) (thread_func* func, void* func_arg)，
		這個eip是個名字，它是指標，指向某個函數，
		在thread_start的時候，這個eip(只是名字)已經被初始化為函數kernel_thread的地址了，
		所以下一個步驟ret，等於pop eip，程式跳到函數kernel_thread的位址運行，等於進入kernel_thread函數，
		
		/thread.c
		在kernel_thread函數內，準備要進入A函數，程式會跑到這裡是因為被時脈中斷，然後進入中斷處理常式才來的，
		CPU發生中斷會自動關掉中斷，所以要用intr_enable()開回來，這也是要準備進入A函數前要先傳來kernel_thread的原因，
		此時esp會指向下圖位置:
		
		##############################################################################################
		##	struct thread_stack {                                          							##
		##		uint32_t ebp;                                              							##
		##		uint32_t ebx;                                              							##
		##		uint32_t edi;                                              							##
		##		uint32_t esi;                                              							##
		##	                                                               							##
		##		void (*eip) (thread_func* func, void* func_arg);           							##
		##		void (*unused_retaddr);   	<==esp!!!                                 				##
		##		thread_func* function;	由Kernel_thread所调用的函数名，類型為void (*function)(void*)##
		##		void* func_arg;    	  	由Kernel_thread所调用的函数所需的参数						##
		##	};                                                              						##
		##############################################################################################
		
		通常ret和call是搭配使用的，如果是用正常管道call進kernel_thread函數，此時esp指的會是返回地址，
		但現在是用旁門左道進來thread_stack函數的，所以esp現在指向的返回值為空值，
		但取kernel_thread的兩個傳入參數的方式還是用esp+4和esp+8，
		為了避免取錯值，所以特別要用void (*unused_retaddr)佔位，
		取出function和func_arg後，組成function(func_arg)，正式進入A函數。

												!!!重要!!!
		###特別注意，main是因為時間到被中斷交棒給A的，等於main重新獲得執行權限後，要回到main被中斷的程式處繼續執行，
		###main當初被中斷後，進入中斷處理常式，一路經過intr_timer_handler、schedule()，最後才走到switch_to，
		###所以當初main 被中斷後 是把自己跑進switch_to函數後的 esp 存在main的PCB的基底位址，
		###假如現在執行緒D因為時間到要把CPU的使用權限交回給main，則D進入中斷處理常式、intr_timer_handler、schedule()、
		###進入switch_to函數，把自己現在的esp存入自己的PCB的基底位址(cur)後，現在要去main的PCB的基底位址(next)拿main的esp，
		###
		###一個正在執行的執行緒交棒一定要經由時脈中斷以進入中斷處理常式，就是因為main執行過，
		###所以此時main的PCB的基底位址(next)存放的是: 當初main被中斷後，跑進switch_to函數後的 esp ，
		###等於D交棒給main後，esp回到main當初進入switch_to時的esp，
		###所以這時候esp+4~esp+12的esi edi ebx ebp也是當初main進入switch_to時壓入的值，
		###連esp+16也是main當初進入switch_to後，要從switch_to返回的位址，
		###因此執行緒D在switch_to交棒給main時，拿到當初esp的值 並 pop四個暫存器值後，
		###ret會回到當初呼叫switch_to的地方，也就是 schedule()函數 內，
		###
		###由於switch_to函數是schedule()內最後一個函數，所以接著會從schedule()返回，回到timer.c的intr_timer_handler函數，
		###此時intr_timer_handler的後面也沒東西了，所又會從intr_timer_handler返回，回到kernel.S，
		###再從kernel.S的iretd指令返回，回到main當初被時脈中斷的地方。


<鎖的結構>

#############################################################################
##	/* 锁结构 */                                                           ##
##	struct lock {                                                          ##
##	   struct   task_struct* holder;	    // 锁的持有者                  ##
##	   struct   semaphore semaphore;	    // 用二元信号量实现锁          ##
##	   uint32_t holder_repeat_nr;		    // 锁的持有者重复申请锁的次数  ##
##	};                                                                     ##
#############################################################################

##########################################################################
##	/* 信号结构 */             											##
##	struct semaphore {         											##
##	   uint8_t  value;         											##
##	   struct   list waiters;  //紀錄在等鎖的持有者釋放的人(函數)有誰	##
##	};                         											##
##########################################################################

###需要注意:
###以上兩個結構同一種PV都只會有一個!!!
###同一種PV，鎖在同一個時間只會由一個執行緒佔有!
###
###以上的結構共有三層，struct   list waiters是鏈結串列，
###等待者會把自己加入鏈結串列waiters中。
###
###若A函數含有不想被打擾的螢幕輸出函數，除了用PV把這個函數包圍外，還可以在螢幕輸出函數的錢跟後分別關中斷跟開中斷，
###然而，假設螢幕輸出函數非常非常非常的長，且B、C都有螢幕輸出函數的函數，
###則在關中斷的情況下，B和C都要等A螢幕輸出函數執行完才能上CPU，
###而PV操作的好處是，當A在執行螢幕輸出函數時被換下處理器，
###如果輪到B，那B可以先執行被PV包圍的程式，等到執行到了PV處再被BLOCK，再輪到C，
###可以避免A的螢幕輸出函數的程式過長而讓A長期獨佔CPU!


<有PV的運行(A取得鎖)>

A從main獲得權限，開始執行，由於A有PV，進入PV時，會先進入lock_acquire函數，

	/syn.c
	在lock_acquire內，如果現在鎖的持有者不是自己，即plock->holder != running_thread()，則進入sema_down函數，
	
	###需要注意:
	###因為A可能有巢狀的PV，即:
	###
	###			P()
	###				P()
	###				
	###				V()
	###			P()
	###
	###每摸到一次P就要申請一次鎖，所以A可能有申請兩次鎖的情況，
	###如果A摸到第二個P而要申請第二的鎖，
	###即lock_acquire內的if(plocl->holder != running_thread不成立)，
	###plock->holder_repeat_nr直接+1即可，
	###之後在V操作時每摸到一次V會減一次1回去。

		進入sema_down函數後，先關中斷，
		因為A第一個進入PV，所以psema->value == 1(初始值)，所以A把psema->value減1，檢查psema->value是否=0，然後恢復關中斷前設置，
		
		###需要注意:
		###sema_down函數內的while(psema->value == 0)前面需要關中斷，
		###假如不關中斷，則while(psema->value == 0)判斷結束的一剎那時脈中斷來臨，A還來不及psema->valu--就被換給B，
		###如果B進入PV時，成功執行lock_acquire內的psema->valu--，使psema->valu為0，
		###然後在執行PV內的程式時時間到了，如果此時B要把棒交回給A，會回到A當初被中斷的地方，即while(psema->value == 0)之後、psema->valu--之前，
		###此時A已經在判斷while(psema->value == 0)後面的地方了，所以接著會執行psema->valu--，把psema->valu變成-1，
		###這樣就會出錯，所以sema_down函數內的while(psema->value == 0)前面需要關中斷!
		###
		###離開sema_down函數時要 "恢復關中斷前的設置" ，
		###因為A可能再執行一個需要關中斷的程式，而程式內又有一部分需要PV，
		###這樣離開sema_down函數後才能回到進入sema_down函數前的設置。
		###
		###補充說明:
		###而在main交棒給還沒執行過的A時，會經過thread.c的kernel_thread函數，									<==========重要!!!
		###此時是直接intr_enable()，
		###因為A還沒執行過，所以交給A的時候要給它最初始的狀態，即交棒給A時直接開中斷!
		###
		###如果某執行緒(例如main)執行過了，棒交回給main時，根據前面分析，執行過的程式會從kernel.S的iretd返回，
		###由於會進入中斷處理常式一定是在開中斷的情況下，所以iretd指令會讓CPU自動開中斷!
		###也就是回到進入中斷處理常式前的狀態。
	
	A返回到lock_acquire函數，再從lock_acquire返回，
	
A的P操作完成，此後執行緒A正式鎖住PV資源。


<有PV的運行(B被block)>

執行緒A鎖住PV資源後，如果在執行PV內的程式時間到了，A被交棒給B執行緒，
B執行一段程式後，如果此時要執行PV內的程式，則會跟A一樣，會先進入lock_acquire函數，

	在lock_acquire函數內，
	由於A把psema->value變成了0，所以此時B會進入while迴圈，檢查自己是否 不在等待隊列(psema->waiters)，
	然後把自己加入等待隊列，然後進入thread_block函數，並傳入TASK_BLOCKED(進入函數會變stat)，

		/thread.c
		在thread_block函數中，由於傳入值為TASK_BLOCKED，所以不會ASSERT，然後進入schedule，

			在schedule函數中，由於B是因為要進入PV結果被阻擋所以才跑到schedule的，
			所以此時B暫時不能再執行了，不能上就緒隊列，因此直接執行schedule的下半部，即送入switch_to函數，
			
				/switch.S
				進入switch_to函數，把B換給就緒隊列中的第一位，即換給C，
				然後C執行到PV的地方又被block，再換給D，D再換給main，main再換給A，


<有PV的運行(A釋放鎖)>

/syn.c
此時如果A的PV部分執行完了，會執行lock_release函數，

	在lock_release函數內，確認鎖的持有者是不是自己，
	如果plock->holder_repeat_nr > 1 則，減1就好，然後return，
	若現在plock->holder_repeat_nr == 1，把鎖的持有者變成NULL，
	再把plock->holder_repeat_nr變0，進入sema_up函數，

		/thread.c
		在sema_up函數內，先關中斷，判斷psema->value是不是等於0，
		然後檢查等待隊列是否有執行緒，
		如果有，用elem2entry從general_tag推導出等待隊列的第一個元素所屬的PCB的基底位址，將該值給struct task_struct* thread_blocked，
		然後呼叫thread_unblock函數，把剛從等待隊列(waiters)拿出的thread_blocked傳進去(傳入後變成pthread)，
		
		###需要注意:
		###此elem2entry內含有list_pop(&psema->waiters)，
		###等於會執行list_pop函數，把等待隊列(waiters)的第一個執行緒pop掉!
		###
		###sema_up函數內有改變鏈結串列的函數，避免沒接完A的時間就到，然後下一棒要用沒接完的鏈結串列的情況，
		###所以sema_up函數內要關中斷，離開後要回到進入 sema_up函數前 的狀態
		###(傳入intr_set_status函數的old_status是定義在 sema_up函數內的開頭 的)。

			在thread_unblock函數內，再關一次中斷，判斷pthread->stat是不是等於TASK_BLOCKED、TASK_WAITING、TASK_HANGING其中一種，
			通常會跑進thread_unblock函數代表pthread->stat一定不會等於TASK_READY，
			但還是if(pthread->stat != TASK_READY)多判斷一下放心，
			再判斷pthread有沒有在就緒隊列，因為pthread是剛從等待隊列拿出來的，理論上現在不應該出現在就緒隊列中，
			用list_push把該pthread放入就緒隊列的最前面，讓它可以最速獲得排程，
			再把pthread->stat切換成TASK_READY，
			最後intr_set_status(old_status)，離開thread_unblock函數，回到sync.c的sema_up函數，

			###需要注意:
			###thread_block 和 thread_unblock 都是要改變鏈結串列的函數，
			###如果鏈結串列還沒接完，結果時間到棒被交出去，下一棒就會用到沒接完的鏈結串列，
			###所以關係到鏈結串列的函數為了保險起見，函數前後還是用關中斷、恢復關中斷前的中斷狀態把函數包起來，
			###
			###thread_block 和 thread_unblock的最後不是直接開中斷，而是用intr_set_status(old_status)，
			###即恢復到 關中斷前的中斷狀態 ，因為進入到 thread_block 或 thread_unblock 前程式可能也是在關中斷的狀態，
			###所以離開 thread_block 或 thread_unblock 後，要回到 進入 thread_block 或 thread_unblock 前 的狀態，
			###
			###intr_set_status(old_status)的 old_status 是定義在 thread_block函數 和 thread_unblock函數內的，
			###即enum intr_status old_status，因此B要 恢復關中斷前的中斷狀態時，
			###傳進intr_set_status的 參數是 定義在thread_block函數開頭的old_status ，
			###也就是恢復到當初B進入到thread_block函數時 關中斷前的狀態。

		/sync.c
		接著會回到sema_up函數內，把pema->value++(變回1)，至此開始會有人搶PV區，復原中斷前狀態後，離開sema_up函數，
		
	回到lock_release函數，檢查pema->value是否==1，
	然後恢復關中斷前的狀態，再離開sema_up函數，最後從lock_release函數返回，鎖的釋放操作(V操作)至此完成。

	###需要注意:
	###lock_release函數的plock->holder = NULL的操作必須放在sema_up之前，
	###因為lock_release函數運行時不會關閉中斷，如果sema_up在plock->holder = NULL前面，
	###sema_up會把psema->value變回1，變成1表示開始會有人搶鎖，如果這個時候還來不及plock->holder = NULL結果A的時間到，
	###A交棒給B，此時若B如果進入PV(psema->value已經等於1了，所以B可以進PV區)，會把鎖拿走並把plock->holder = B，
	###此時假如B在PV內時間到了，把棒交回給A時，由於A執行過，根據之前推論會回到A被中斷的地方，
	###也就是sema_up函數 與 plock->holder = NULL 的中間，
	###此時A會執行下一條程式，即plock->holder = NULL，把plock->holder = B 變成 plock->holder = NULL，造成混亂，
	###所以lock_release函數的plock->holder = NULL的操作必須放在sema_up之前!


<運行(PV區被A釋放，B被重新排上就緒隊列，B拿回CPU之後的運行狀況)>
				
				/switch.S
				A釋放PV區，重新把B放上就緒隊列首後，假如A現在時間到，現在要交棒給B執行緒了，
				由於B執行過，A要把棒交給B，運行到switch_to函數時，會在switch_to函數內修改esp，
				使 esp 回到B之前在switch_to函數內 把棒交出去前的狀態，esp pop四個暫存器值後，
				再ret，意即pop eip，所以程式會離開switch_to，回到當初 呼叫switch_to函數的 函數內部，即schedule函數內部)，
				
			/thread.c
			返回到schedule函數，由於switch_to已經是schedule函數內最後一個函數了，所以程式接著會離開schedule函數，
			由於B是因為進入PV區時不成功，被送進thred_block函數內把自己放到等待隊列後，再進入schedule函數把棒交出去的，
			所以B離開schedule函數後現在會回到thred_block函數，

		回到thred_block函數，恢復關中斷前的中斷狀態 後，離開thred_block函數，回到sema_down函數，

	/syn.c
	接著會回到sema_down函數的while迴圈的最下面，
	然後迴圈到while頂部判斷psema->value是否等於0，理論上現在應該等於1(A在sema_up函數設成1的)，所以會脫離迴圈，
	然後psema->value--，即把psema->value變成0，最後恢復關中斷前的狀態，並從sema_down函數返回到lock_acquire函數，

	###需要注意:
	###
	###書上說:
	###sema_down函數內用while判斷的原因是 "通用原則" ，
	###
	###如果當時A在V操作時，在thread_unblock內把B排在 就緒隊列中 C的後面，即下一棒交棒給C，
	###如果C進行P操作，把psema->value變成0後，執行到PV內部時C的時間到了，
	###
	###然後C的下一棒是B，B把棒拿回後，如果是while迴圈，則B會再判斷一次psema->value是不是等於0，
	###此時psema->value被C設為0，所以B又會再度被加入等待隊列，然後進入thread_block函數，
	###
	###假如接下來B把棒拿回後，如果是if，則B不會再判斷一次psema->value是不是等於0，
	###會直接進行接下來的程式，也就是psema->value--，把psema->value減為負的，
	###這樣就不對，
	###
	###所以為了避免以上狀況，sema_down函數內會用while判斷，
	###但由於當時A在V操作時，在thread_unblock函數內寫的程式是 把B從等待隊列拿出後 排在就緒隊列的第一個，
	###也就是A執行完V操作(離開PV區)後若時間到了，B會直接拿下一棒，從thread_block返回到sema_down後，接著會psema->value--，
	###不會因為PV釋放後，B排在還 沒進去過PV的C 後面，結果C進行P操作先psema->value--的問題，
	###所以這裡用if仍然是可以的，
	###用while判斷還是通用性的問題。
	#########################################################################################################
	###
	###								!!!後來測試發現，還是得用while!!!									<==============重要!!!
	###假如A函數內有一個迴圈，而迴圈內又有PV區，
	###當A要從PV區離開時，執行V操作，把B從 等待隊列 移到 就緒隊列 後，
	###進行一次迴圈，又再度進入到了PV區，執行P了操作，做了psema->value--，
	###若A此時還沒離開PV區結果時間到了，若下一棒是B，則B從thread_block返回到sema_down後，
	###假設sema_down函數內用if判斷，B不會再迴圈一次去檢查 psema->value 使否等於0 ，
	###所以接著會psema->value--，把psema->value減為負的，所以sema_down函數內還是得用while判斷!!!
	###	

在lock_acquire函數內把 plock->holder 變成 B 自己，檢查plock->holder_repeat_nr是否等於0，
把plock->holder_repeat_nr變成1(因為B現在是第1次獲得鎖)，
最後從lock_acquire函數函數返回，至此 B 獲得鎖(P操作)正式完成。

###需要注意:
###如果等待隊列有B、C兩個
###A執行V操作時會把B放到就緒隊列首，
###然後A的下一棒給B後，B做完P操作，執行完PV的內容，要進V操作時，
###還會在sema_up函數內檢查等待隊列有沒有人還在，
###此時C還在，所以B的程式會把C從等待隊列pop出，然後進入thread_unblock函數把C排到就緒隊列首，
###整個程式運行到最後等待隊列一定會被清空(假設沒有發生死結的情況)。

-----------------------------------------------------------------------------------------------

c/
/kernel.S
再增加16個中斷入口

/interrupt.c
為了使測試簡單，暫時關時脈中斷

/keybord.c
新增keybord.c，內含有 鍵盤的中斷處理常式 和 鍵盤初始化函數，
在鍵盤初始化函數內為 鍵盤的中斷處理常式 註冊安裝。

d/
/keybord.c
擴充keybord.c整個內容，讓 鍵盤的中斷處理常式 支援大多數常用的按鍵

e/
實現生產者和消費者的緩衝區測試

---------------------------------------------------------------------------
生產者和消費者統整(無星號的表示實際會運行到的狀況，為什麼輸出會是" A_k"可以只看無星號的分析就可理解):

																	/sync.h
														----------> struct lock {
                                                        |           struct   task_struct* holder;	    // 锁的持有者
                                                        |           struct   semaphore semaphore;	    // 用二元信号量实现锁
                                                        |           uint32_t holder_repeat_nr;		    // 锁的持有者重复申请锁的次数
/ioqueue.h                                              |           };
struct ioqueue {                                        |
    struct lock lock; -----------------------------------           /thread.h
    struct task_struct* producer; --------------------------------> struct task_struct {
                                                                    uint32_t* self_kstack;	// 各内核线程都用自己的内核栈
    struct task_struct* consumer; -----------------------	        enum task_status status;  
    char buf[bufsize];	// 缓冲区大小                   |			char name[16];  
    int32_t head;		// 队首,数据往队首处写入        |           uint8_t priority;  
	int32_t tail;		// 队尾,数据从队尾处读出		|           uint8_t ticks;			// 每次在处理器上执行的时间嘀嗒数  
};                                                      |           										                                                                                                            
                                                        |           uint32_t elapsed_ticks;
                                                        |                                                                 	                                                             
                                                        |           struct list_elem general_tag;				    
														|			struct list_elem all_list_tag;
														|			
														|           uint32_t* pgdir;		// 进程自己页表的虚拟地址
														|           uint32_t stack_magic;	// 用这串数字做栈的边界标记,用于检测栈的溢出
														|           };
														|           
														|           /thread.h
														--------->  struct task_struct {
														            uint32_t* self_kstack;	// 各内核线程都用自己的内核栈
														            enum task_status status;  
														            char name[16];  
														            uint8_t priority;  
														            uint8_t ticks;			// 每次在处理器上执行的时间嘀嗒数  
														            										                            
														            uint32_t elapsed_ticks;
														                                                                  	            
														            struct list_elem general_tag;				    
														            struct list_elem all_list_tag;
														            
														            uint32_t* pgdir;		// 进程自己页表的虚拟地址
														            uint32_t stack_magic;	// 用这串数字做栈的边界标记,用于检测栈的溢出
														            };																																							

/main.c
while迴圈內，先用關、恢復中斷包起來，
否則東西放入緩衝區或者從緩衝區拿出後，指著緩衝區的游標來不及跟著移動就被換成新的執行緒，
那新執行緒會把游標目前指著的位置放東西進去或拿東西出來，這就不對，
所以if(!ioq_empty(&kbd_buf))...之操作到緩衝區的code要用關、恢復中斷包起來(也可以用PV包?)。
如果緩衝區不是空的( !!!表示剛剛鍵盤已經放"k"進去!!! )，表示可以從緩衝區拿東西出來，
先顯示:" A_"，然後進入ioq_getchar函數，傳入struct ioqueue kbd_buf的地址，即&kbd_buf，			<=============顯示" A_"!!!
	
/ioqueue.c
	在ioq_getchar函數內，先確認是否中斷已關，然後用while判斷緩衝區是不是空的，
	***如果是空的，表示根本從緩衝區根本拿不出東西來，
	***需要進入ioq_wait函數，設法把現在的執行緒block住，
	
	***(由於main.c的k_thread_a中，要進入ioq_getchar函數一定要經過if(!ioq_empty(&kbd_buf))之關卡，
	***如果緩衝區是空的，表示根本不會進入ioq_getchar函數，
	***所以ioq_getchar函數內的while在這裡可能是: 如果main.c沒有if之關卡，
	***則這裡的while可以派上用場，目前如果緩衝區是空的話在main.c會先被if擋下，所以在此while暫無作用)
	
	***(while內的ioq_wait函數被PV包圍，但是while前面會先ASSERT看進入ioq_getchar函數時有沒有關中斷，
	***意即ioq_wait函數執行到一半不可能執行緒被換走，所以用PV包應該也只是多一份保險?)
		
	***假如main.c沒有if(!ioq_empty(&kbd_buf))之關卡，會進入ioq_wait函數，傳進去的是&ioq->consumer，
	***(consumer是一個地址，為指向struck task_struct的指標，
	***由於ioq_wait函數會涉及到把consumer記為 執行緒自己 的操作(將來生產者往緩衝區放東西後才知道要喚醒哪位消費者)，
	***而在此希望此操作也能改變ioq_wait函數的上一個函數(也就是ioq_getchar函數)內的 ioq->consumer，
	***所以ioq_wait函數接收的參數型態是struck task_struct**，也就是把ioq->consumer的地址傳進去)
	
	***(用while迴圈判斷的理由跟syn.c的sema_down函數內的while是類似的，
	***避免消費者被生產者喚醒後另一個消費者把東西全拿走，所以用while迴圈讓被喚醒者回來再判斷一次比較保險)
	
		***ioq_wait函數內，檢查*waiter是不是應該為NULL，因為目前*waiter還沒有被賦予任何執行緒，
		***然後把現在準備被block的執行緒(消費者)基底位址賦予*waiter，
		***然後進入thread_block函數，把目前的執行緒(消費者)交棒給就緒對列第一個執行緒
		
		***(thread_block函數不會把執行緒加入等待隊列，那是進入thread_block函數前要做的事)
		
		***(假如main.c沒有if之關卡，消費者A會進入到 ioq_getchar函數內的 while迴圈內的 ioq_wait函數 ，
		***把執行緒A自己賦予*waiter(即賦予ioq->consumer)，然後進入thread_block函數，把下一棒交給B，
		***然後如果生產者一直不放東西，B同樣會進入到 ioq_wait函數內的 while迴圈內的 ioq_wait函數，
		***把執行緒B自己賦予*waiter(即賦予ioq->consumer)，
		***但是緩衝區是生產者和兩個消費者共用的，所以ioq->consumer原本的記錄的執行緒A會被B覆蓋，
		***但是本code因為在main.c有if之關卡，如果緩衝區為空會在main.c就被擋下，所以不會發生以上情況)
		
	如果ioq_getchar函數內的while判斷結果為緩衝區不是空的(剛剛鍵盤有把"k"放進緩衝區)，則消費者確定可以從緩衝區拿東西，
	把物品("k")從緩衝區拿出，賦予char byte，
	然後把ioq->tail(消費者游標)移動到下一個位置，
	
	***若有生產者被block則用wake_up函數喚醒，
	***因為在wake_up函數內涉及到 把producer變成NULL 的操作，所以要傳&ioq->producer進去，
	***這樣wake_up函數內把*waiter變成NULL後，此改變也能影響到上一個函數(ioq_getchar函數)內的ioq->producer)
	***(因為生產者是鍵盤，消費者是k_thread_a和k_thread_b，
	***鍵盤放k進入緩衝區的速度幾乎不可能贏過k_thread_a和k_thread_b兩個函數內的程式，
	***所以本測試只要鍵盤一放一個k進去幾乎會被消費者立刻拿走，不太可能出現生產者被block的情況)
	
	最後回傳byte(ioq_getchar的返回值是一個char，即k的ASCII碼，不是char*，所以返回值不用static)。
		
回到k_thread_a函數後，把回傳值("k")輸出，最後輸出結果變成" A_k"，恢復中斷，繼續下一迴圈。			<=============再顯示"k"!!!

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
如果在某一個時間點按下鍵盤的某一個按鍵k，會進入鍵盤的中斷處理常式，

/keyboard.c
在鍵盤中斷處理常式末尾檢查緩衝區是不是已經滿了，如果滿了(幾乎不可能發生)，
則不放入任何東西到緩衝區(鍵盤可能會發出逼逼聲通知緩衝區已滿)，
如果緩衝區沒滿，則進入ioq_putchar函數，傳入&kbd_buf和cur_char，

/ioqueue.c
	ioq_putchar函數內，檢查中斷是否被關(因為進入中斷處理常式前CPU會自動關中斷，所以理論上應該會通過ASSERT)，
	然後用while判斷緩衝區是不是已經滿了，
	
	***(由於在keyboard.c也有if(!ioq_full(&kbd_buf))之關卡，
	***理論上如果緩衝區滿了會在ioqueue.c被擋下)，
	***如果前面沒有if關卡，使得程式進入到while迴圈內部，然後呼叫ioq_wait函數把生產者自己block，
	***由於ioq_putchar函數前面會ASSERT是否關中斷，
	***也就是說ioq_wait函數不管有沒有用PV包圍都不會因為時間到被換走，可能只是添保險?)
	
	while判斷緩衝區沒滿，則可以把剛剛從鍵盤收到的k放進緩衝區，
	然後把ioq->head(生產者游標)移動到下一個位置，
	
	***如果有消費者被block，要喚醒它，所以要呼叫wakeup函數，
	***(因為要把ioq->consumer的值變成NULL，所以要傳&ioq->consumer進去，
	***這樣此改變才能影響到ioq_getchar函數內的ioq->consumer)
	***(理論上消費者不會被block，因為消費者在main.c有if關卡，如果緩衝區為空，消費者就進不了ioq_getchar函數，
	***也不會在ioq_getchar函數內因為緩衝區為空把自己block)，
	
	最後返回到interrupt.c

/keyboard.c
從中斷處理常式離開
-----------------------------------------------------------------------------------------------

/第十一章
a/
/global.h
在global.h新增TSS的屬性

/tss.c
新增tss.c，內有TSS結構、GDT描述符號結構(之前是在loader和boot.inc用組語寫，現在用c語言的方式建立GDT描述符號)、
將TSS載入GDT的函數tss_init。


b/
/process.c
新增process.c

/thread.h
struct task_struct內新增struct virtual_addr userprog_vaddr，
struct virtual_addr已經定義在memory.h中，

新增 extern struct list thread_ready_list 和 extern struct list thread_all_list ，
因為這兩個皆定義在thread.c中，這樣外部檔案就可以使用 共同的 就緒對列 和 所有執行緒對列 ，


/thread.c
在schedule函數內加入process_active函數，
進入該函數後(在process.c內)，如果下一棒是使用者，會配置使用者專用的分頁目錄表，且會更新tss內的SS0和esp0，


/memory.c
struct pool新增struct lock lock，為物理池新增 鎖 的結構，

mem_pool_init新增 lock_init(&kernel_pool.lock) 和 lock_init(&user_pool.lock)，
為 核心物理池 和 使用者物理池 初始化鎖，
所有分配記憶體的頂層函數都用PV包圍。
###需要注意:
###	lock_init函數內容在sync.c，
###	此函數內含有sema_init函數，
### sema_init函數除了初始化value，還會呼叫list_init，
###	把struct   list waiters 也初始化。

在vaddr_get函數內新增 尋找連續pg_cnt個沒用過的 虛擬位址 的code，


/global.c
新增eflag屬性。


------------------------------------------------------------------------
第十一章使用者處理程序統整(從main.c開始):

###歸納:
###	如果A進入P(lock_acquire函數)，會先進入sema_down函數，把value減為0，退出sema_down函數後，會把struct   task_struct* holder設為A自己，再把holder_repeat_nr設為1，
###	如果A有巢狀的PV，再進入P時，不會再進入sema_down函數，但會把holder_repeat_nr加1，
###	如果A還在PV區的情況下，B進入P，會進入sema_down函數，會把B自己放入semaphore->waiters，然後會被進入thread_block，把B自己交棒給下一位，
###
###	如果A準備退出PV區，會進入V(lock_release函數)，
###		若A的PV是巢狀，導致holder_repeat_nr的值為2以上，那只會holder_repeat_nr減1而已，
###		若A即將退出的PV區已經是最外層，即holder_repeat_nr == 1，則會先把struct   task_struct* holder設為NULL，再把holder_repeat_nr變成0，
###		##至此開始會允許其他執行緒進入PV區，所以要先 struct   task_struct* holder設為NULL 再 把holder_repeat_nr變成0 ，
###		##因為如果 把holder_repeat_nr變成0後 ，A突然時間到了，交棒給執行緒B後，B進入P，把struct   task_struct* holder設為B自己，
###		##這時如果B還沒離開PV區就交回棒給A，A會把struct   task_struct* holder設為NULL，這樣就亂了。
###		然後進入sema_up函數把semaphore->waiter內的第一個執行緒pop出來，然後藉由thread_unblock函數把它放回就緒隊列的第一個，
### 如果現在B因為被放回執行緒準備要執行了，會從thread_block函數回到sema_down函數，然後繼續做A進入P時做的事情，
###	到時候B要離開PV區而進入V時，會再把semaphore->waiter內的第一個執行緒pop出來，然後藉由thread_unblock函數把它放回就緒隊列的第一個，
###	因此執行到最後semaphore->waiter一定會清空(若沒有發生死結的話)。
																			 
                                                                             /bitmap.h	
                                                                        ---> struct bitmap {
                                                                        |    	uint32_t btmp_bytes_len;
                                                                        |    	uint8_t* bits; //點陣圖的初始虛擬位址
                                                                        |    };	
																		|
																		|	 /sync.h
                                                                        | -> struct lock {
                                                                        | |  	struct   task_struct* holder;	    // 锁的持有者                        /sync.h
/memory.c                                                               | |  	struct   semaphore semaphore;	    // 用二元信号量实现锁 -------------> struct semaphore {
!!!核心用物理記憶體池!!!                                                | |  	uint32_t holder_repeat_nr;		    // 锁的持有者重复申请锁的次数           uint8_t  value;
struct pool {                                                           | |  };                                                                             struct   list waiters; --->等待隊列
   struct bitmap pool_bitmap;// 本内存池用到的位图结构,用于管理物理内存	- |		                                                                         };
   uint32_t phy_addr_start;	 // 本内存池所管理物理内存的起始地址          |   
   uint32_t pool_size;		 // 本内存池字节容量						  | 
   struct lock lock;		 // 申请内存时互斥 ----------------------------  /bitmap.h	
};                                                                        -> struct bitmap {
!!!使用者用用物理記憶體池!!!                                              |  	uint32_t btmp_bytes_len;
struct pool {                                                             |  	uint8_t* bits; //點陣圖的初始虛擬位址
   struct bitmap pool_bitmap;// 本内存池用到的位图结构,用于管理物理内存 ---  };	
   uint32_t phy_addr_start;	 // 本内存池所管理物理内存的起始地址  
   uint32_t pool_size;		 // 本内存池字节容量							 /sync.h
   struct lock lock;		 // 申请内存时互斥 ----------------------------> struct lock {
};                                                                           	struct   task_struct* holder;	    // 锁的持有者                       /sync.h
!!!核心用虛擬記憶體!!!                                                       	struct   semaphore semaphore;	    // 用二元信号量实现锁 ------------> struct semaphore {
/memeory.h                                                                   	uint32_t holder_repeat_nr;		    // 锁的持有者重复申请锁的次数          uint8_t  value;
struct virtual_addr {                                                        };                                                                            struct   list waiters; --->等待隊列
   struct bitmap vaddr_bitmap; --------------------------------------------                                                                             };
   uint32_t vaddr_start;                                                  |
};                                                                        |
																		  |  /bitmap.h	
																		  -> struct bitmap {
																				uint32_t btmp_bytes_len;
																				uint8_t* bits; //點陣圖的初始虛擬位址
																			 };	



/thread.h
struct task_struct {	
	uint32_t* self_kstack;	// 各内核线程都用自己的内核栈 -----------------
	enum task_status status;                                              |
	char name[16];                                                        |
	uint8_t priority;                                                     |
	uint8_t ticks;			// 每次在处理器上执行的时间嘀嗒数             |
	uint32_t elapsed_ticks;                                               |
	struct list_elem general_tag;				                          |
	struct list_elem all_list_tag;                                        |                !!!使用者用虛擬記憶體!!!
	uint32_t* pgdir;		// 进程自己页目錄表的虚拟地址                 | 			   /memeory.h 
	struct virtual_addr userprog_vaddr; ----------------------------------|--------------> struct virtual_addr {                      	/bitmap.h
	uint32_t stack_magic;	// 用这串数字做栈的边界标记,用于检测栈的溢出  | 			      struct bitmap vaddr_bitmap;------------->	struct bitmap {
};                                                                        | 			      uint32_t vaddr_start;                   		uint32_t btmp_bytes_len;
																		  |				   };                                         		uint8_t* bits; //點陣圖的初始虛擬位址
																		  |															  	};
																		  |
																		  |
/thread.h																  |
struct thread_stack { <----------------------------------------------------
    uint32_t ebp;
    uint32_t ebx;
    uint32_t edi;
    uint32_t esi;

    void (*eip) (thread_func* func, void* func_arg);

    void (*unused_retaddr);
    thread_func* function;  // 由Kernel_thread所调用的函数名

    void* func_arg;    		// 由Kernel_thread所调用的函数所
};



/main.c
進入init_all函數，

/init.c
	init_all函數內，進入tss_init()函數，
	
/tss.c
		tss_init函數內，先用sizeof(tss)求得tss的大小，將該值賦予tss_size，
		然後用memset函數把tss清0，
		tss.ss0代表下一個工作的堆疊的基礎位址，該值為SELECTOR_K_STACK，
		tss.io_base即tss的大小，tss沒有io點陣圖(目前都還沒有設置過，且tss不需要)，
		所以 io點陣圖 偏移量 的值直接就是tss_size，即不給io點陣圖在tss內有任何空間，
		
		建立dpl為0的TSS描述符(用make_gdt_desc函數建立)，然後增加到GDT中(增加在loader.S中0xc0000920的位置，不過是在tss.c內用C語言的方式加進去)，
		
		再建立兩個dpl為3的段描述符號(用make_gdt_desc函數建立)，增加到GDT中，分別是 程式碼段 和 資料段 ，
		
		接下來要修改GDTR內的GDT的界線值，目前GDT已經有7個段描述符號(包括第0個)，而GDT的基礎地址依然為0xc0000900，
		把uint64_t gdt_operand賦予((8 * 7 - 1) | ((uint64_t)(uint32_t)0xc0000900 << 16))後，
		用asm volatile ("lgdt %0" : : "m" (gdt_operand))的方式把新的GDTR數值放入GDTR，
		
		用asm volatile ("ltr %w0" : : "r" (SELECTOR_TSS))的方式把TR的數值(SELECTOR_TSS為TR的數值，定義在global.h)放入TR，
		因為TR只有16位元，所以要寫 ltr %w0 。
		
		顯示"tss_init and ltr done\n"後，返回，

/init.c
	離開init_all函數，

/main.c
先封裝k_thread_a和k_thread_b兩個執行緒，
然後進入process_execute函數，傳入的參數有 u_prog_a函數 和 "user_prog_a"(函數名字)，

/process.c
	process_execute函數中，先申請一個分頁，此分頁作為u_prog_a執行緒的PCB，
	並把該分頁(PCB)的基底地址賦予struct task_struct* thread，
	然後呼叫init_thread函數初始化該PCB的struct task_struct的部分，
	接著進入create_user_vaddr_bitmap函數，傳入thread，
		
		create_user_vaddr_bitmap函數內，
		
		user_prog->userprog_vaddr.vaddr_start = USER_VADDR_START;
		USER_VADDR_START為0x80480000，定義在process.h，
		此為Linux使用者程式的入口地址，也是大部分可執行程式的入口地址，
		把0x80480000給user_prog->userprog_vaddr.vaddr_start，
		
		uint32_t bitmap_pg_cnt = DIV_ROUND_UP((0xc0000000 - USER_VADDR_START) / PG_SIZE / 8 , PG_SIZE);
		0xc0000000以上是核心在用的虛擬地址範圍，0xc0000000 - USER_VADDR_START為使用者使用的虛擬地址範圍，
		此範圍可以用長度(單位為byte)為 (0xc0000000 - USER_VADDR_START) / PG_SIZE / 8 的點陣圖來表達，
		該長度除以PG_SIZE即該點陣圖占用的分頁有多少(小數點直接無條件進位)，
		###需要注意:
		###DIV_ROUND_UP為巨集函數，定義在global.h，目的在向上取整(無條件進位)，
		###向上取整的公式為:(a+b-1)/b，如14/4=3...2，向上取整為(14+3)/4...1，
		###即如果商是3.XXX，則把商變成4。
		
		user_prog->userprog_vaddr.vaddr_bitmap.bits = get_kernel_pages(bitmap_pg_cnt);
		在核心記憶體池申請 使用者虛擬地址的點陣圖 所占用的分頁數量個 分頁，
		把返回的虛擬地址給user_prog->userprog_vaddr.vaddr_bitmap.bits，
		此值代表 使用者虛擬地址的點陣圖的 基底虛擬位址，
		###需要注意:
		###描述 核心池、使用者池、核心所用的虛擬地址的點陣圖 設置在低端1MB的0xc009a000以上的位置，
		###而使用者所用的虛擬地址的點陣圖 設置在 核心池 裡面。
		
		user_prog->userprog_vaddr.vaddr_bitmap.btmp_bytes_len = (0xc0000000 - USER_VADDR_START) / PG_SIZE / 8;
		把 使用者所用的虛擬地址的點陣圖的 長度(單位為byte) 賦予 user_prog->userprog_vaddr.vaddr_bitmap.btmp_bytes_len，
		
		bitmap_init(&user_prog->userprog_vaddr.vaddr_bitmap);
		把 使用者所用的虛擬地址的點陣圖 初始化，即點陣圖內全歸零，
		
		退出create_user_vaddr_bitmap函數，
		
	thread_create(thread, start_process, filename)
	初始化本PCB的struct thread_stack 的部分，
	跟第九章相同的是，傳入的第一個參數依然是thread，即本PCB的基底虛擬地址，
	不同的是，傳入的第二個參數為start_process函數，
	傳入的第三個參數為start_process函數的參數，即filename，
	
	進入create_page_dir函數，本函數要為使用者額外再設一個分頁目錄，
		
		create_page_dir函數內，
		先為使用者所使用的分頁目錄申請一個分頁，把該分頁目錄的基底地址賦予page_dir_vaddr，
		然後把原本分頁目錄的第768~1023項(核心所用的部分，佔分頁目錄表的高四分之一，佔1024位元組)複製到 使用者所使用的分頁目錄裡，
		
		用addr_v2p函數把page_dir_vaddr轉化成物理地址(即該分頁基底位址的物理位址)，把該值賦予new_page_dir_phy_addr，
		
		把new_page_dir_phy_addr | PG_US_U | PG_RW_W | PG_P_1賦予page_dir_vaddr[1023]，
		即賦予 使用者所使用的分頁目錄的最後一項 為 使用者分頁目錄的基底虛擬地址，
		即讓 使用者所使用者分頁目錄的最後一項的 黑色箭頭 指向 分頁目錄自己，
		
		最後返回 使用者所使用者分頁目錄的基底地址(page_dir_vaddr)，
		
	開始要對鏈結串列操作，所以要關中斷，
	把PCB自己的thread->general_tag加入到就緒隊列、thread->all_list_tag加入到所有隊列，
	恢復中斷，
	
	從process_execute函數離開，
	
/main.c
開啟中斷，開始會交接執行緒。


---------------------------------------------
當時間到，不論準備 被換掉的執行緒 是核心還是使用者 進入到schedule函數後，進入switch_to函數前，
會先進入到process_activate函數，傳入的參數是 下一棒執行緒PCB的基底位址(即struct task_struct) ，

/process.c	
	process_activate函數內，檢查 下一棒執行緒PCB的基底位址 是不是NULL後，會進入到page_dir_activate函數，傳入的參數是下一棒執行緒PCB的基底位址(struct task_struct)，
		
		page_dir_activate函數內，先把pagedir_phy_addr賦予 原本的分頁目錄表 的基礎"物理地址"，即賦予0x100000，
		
		檢查p_thread->pgdir是不是等於NULL，
		如果等於NULL，表示p_thread->pgdir沒在process_execute內被賦予新的分頁目錄表的 基礎"虛擬地址"，
		表示 下一棒執行緒 是核心執行緒，讓pagedir_phy_addr保持0x100000，
		
		如果p_thread->pgdir不等於NULL，意即有在process_execute內被賦予新的分頁目錄表的 基礎"虛擬地址"，
		表示 下一棒執行緒 是使用者執行緒，要修改pagedir_phy_addr為 新的分頁目錄表的 基礎"物理地址"(頁目錄暫存器(cr3)認的是物理地址)，
		藉由addr_v2p函數把 新的分頁目錄表的 基礎"虛擬地址" 轉換為 新的分頁目錄表的 基礎"物理地址"，
		然後把pagedir_phy_addr修改為 新的分頁目錄表的 基礎"物理地址"，
		用asm volatile ("movl %0, %%cr3" : : "r" (pagedir_phy_addr) : "memory")把 頁目錄暫存器(cr3) 修改為 pagedir_phy_addr，
		最後從page_dir_activate函數返回，
		
	檢查p_thread->pgdir是不是NULL，如果不是NULL，表示下一棒為使用者執行緒，
	下一棒在執行時，如果被中斷，就會進入0特權等級，會到tss取得新的esp0作為使用者在核心態(特權等級為0)的堆疊位址，
	所以要進入update_tss_esp函數去更新tss中的tss.esp0，

/tss.c		
		update_tss_esp函數內，把tss.esp0更新為下一棒(為使用者)PCB的最頂端，
		當使用者因為被中斷而進入到0特權等級(核心態)時，會把 PCB所在的最頂端 作為 特權等級為0的 堆疊位址，
		離開update_tss_esp函數，
		
		###需要注意:
		###	TR內放GDT選擇子，指向TSS描述符號存於GDT的位置，
		###
		###	原始x86的設計是在切換工作時，從TSS描述符號內的數值進行一系列的檢查，
		###	檢查完後，把暫存器的數值存入TSS描述符號指向的TSS中，
		###	把新的選擇子載入TR，又進行一系列的檢查後，把新的選擇子指向的 TSS描述符號指向的 TSS內的 暫存器數值 載入 CPU的暫存器，
		###	再進行一系列檢查，
		###	然後把上一個TSS選擇子存於TSS的 "上一個TSS工作指標中"，
		###
		###	然而，因為要頻繁載入TR，所以上述方法被Linux棄用，
		###	Linux的方法為(也是本code的用法):
		###	TSS功能只剩下存使用者於特權等級為0時的堆疊底位置，該值存於TSS中的SS0和esp0中，
		### TSS只有唯一一個，執行緒在交棒時，會進入 page_dir_activate函數 更新TSS的SS0和esp0，
		###	x86 CPU有一個原生的特性，當 "目前的"工作 要從低特權到高特權時，
		###	會自動拿目前 TR內的選擇子指向的 TSS描述符號指向的 TSS內的 SS0和esp0 作為0特權等級的堆疊，
		###	我們在page_dir_activate函數內設置的SS0是0，所以0特權等級的堆疊位址為0+esp0=esp0，
		###	然後直接拿esp0的位置(在page_dir_activate函數內設置為 目前執行緒的PCB的 頂端)來push一系列的暫存器數值進去，
		
/process.c		
	離開process_activate函數，

接著會進入switch_to函數，在switch_to函數後段pop四個暫存器後，
pop eip，程式會跑到start_process函數，即進入到start_process函數，傳入的參數為filename，

/process.c
	在start_process內，把filename_賦予function(目前還沒有檔案系統，所以暫用filename_代替)，
	
	用running_thread()取得現在執行緒的基底虛擬位址，即struct task_struct*，把該值賦予cur，
	cur->self_kstack內存的堆疊起始位址現在應該指著這裡(即在switch_to函數內拿到的最一開始的堆疊地址):

##############################################################################################
##	struct thread_stack {                                          							##
##		uint32_t ebp;            <=== !!!cur->self_kstack!!!   <===esp                    	##
##		uint32_t ebx;                                              							##
##		uint32_t edi;                                              							##
##		uint32_t esi;                                              							##
##	                                                               							##
##		void (*eip) (thread_func* func, void* func_arg);           							##
##		void (*unused_retaddr);                                    							##
##		thread_func* function;	由Kernel_thread所调用的函数名，類型為void (*function)(void*)##
##		void* func_arg;    	  	由Kernel_thread所调用的函数所需的参数						##
##	};                                                              						##
##############################################################################################
				!!!thread_stack緊接在intr_stack的上面(低地址處)!!!
##############################################################################################
##	struct intr_stack {                                                           			##
##		uint32_t vec_no;	 <---低地址		kernel.S 宏VECTOR中push %1压入的中断号    		##
##		uint32_t edi;                                                                 		##
##		uint32_t esi;                                                                 		##
##		uint32_t ebp;                                                                 		##
##		uint32_t esp_dummy;	 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略		##
##		uint32_t ebx;                                                                 		##
##		uint32_t edx;                                                                 		##
##		uint32_t ecx;                                                                 		##
##		uint32_t eax;                                                                 		##
##		uint32_t gs;                                                                  		##
##		uint32_t fs;                                                                  		##
##		uint32_t es;                                                                  		##
##		uint32_t ds;                                                                  		##
##		                                                                              		##
##		以下由cpu从低特权级进入高特权级时压入                                         		##
##		uint32_t err_code;	err_code会被压入在eip之后                                 		##
##		void (*eip) (void);                                                           		##
##		uint32_t cs;                                                                  		##
##		uint32_t eflags;                                                              		##
##		void* esp;                                                                    		##
##		uint32_t ss; 	    <---高地址                                                		##
##	};                                                                            			##
##############################################################################################



	把cur->self_kstack加上sizeof(struct thread_stack)使cur->self_kstack現在指向這裡:

##############################################################################################
##	struct thread_stack {                                          							##
##		uint32_t ebp;      				<== esp         									##
##		uint32_t ebx;                                              							##
##		uint32_t edi;                                              							##
##		uint32_t esi;                                              							##
##	                                                               							##
##		void (*eip) (thread_func* func, void* func_arg);           							##
##		void (*unused_retaddr);                                    							##
##		thread_func* function;	由Kernel_thread所调用的函数名，類型為void (*function)(void*)##
##		void* func_arg;    	  	由Kernel_thread所调用的函数所需的参数						##
##	};                                                              						##
##############################################################################################
				!!!thread_stack緊接在intr_stack的上面(低地址處)!!!
##############################################################################################
##	struct intr_stack {                                                           			##
##		uint32_t vec_no; <---低地址  	<=== !!!cur->self_kstack!!! 						##
##		uint32_t edi;                                                                 		##
##		uint32_t esi;                                                                 		##
##		uint32_t ebp;                                                                 		##
##		uint32_t esp_dummy;	 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略		##
##		uint32_t ebx;                                                                 		##
##		uint32_t edx;                                                                 		##
##		uint32_t ecx;                                                                 		##
##		uint32_t eax;                                                                 		##
##		uint32_t gs;                                                                  		##
##		uint32_t fs;                                                                  		##
##		uint32_t es;                                                                  		##
##		uint32_t ds;                                                                  		##
##		                                                                              		##
##		以下由cpu从低特权级进入高特权级时压入                                         		##
##		uint32_t err_code;	err_code会被压入在eip之后                                 		##
##		void (*eip) (void);                                                           		##
##		uint32_t cs;                                                                  		##
##		uint32_t eflags;                                                              		##
##		void* esp;                                                                    		##
##		uint32_t ss;     <---高地址                                                			##
##	};                                                                            			##
##############################################################################################

	把cur->self_kstack賦予struct intr_stack* proc_stack，
	把edi esi ebp esp_dummy皆設為0，
	ebx edx ecx eax也都設為0，
	gs設為0，因為一般作業系統不允許使用者訪問顯示記憶體資源，設為0的話就會選到GDT的第0個段描述符號，以發生例外，
	ds es fs設為SELECTOR_U_DATA，
	eip在此才被賦予function，即賦予filename_，此為待執行的使用者處理程序的函數，沒有參數，
	cs賦予SELECTOR_U_CODE，
	eflags賦予(EFLAGS_IOPL_0 | EFLAGS_MBS | EFLAGS_IF_1)，
	
	然後要為使用者額外分配一個將來要使用的堆疊空間，使用者的堆疊底為0xc0000000，
	該位址為堆疊空間的最高地址處(堆疊是由高地址往低地址生長的)，而分頁的基底地址在低地址處，
	所以堆疊所在的分頁的虛擬基底位址為USER_STACK3_VADDR，該值定義在process.h，為(0xc0000000 - 0x1000)，
	
	進入get_a_page函數，傳入PF_USER(代表使用者)和USER_STACK3_VADDR(堆疊所在分頁的基底虛擬位址)，

/memory.c		
		get_a_page函數內會為這一個分頁的 基底虛擬位址 用palloc函數找一個物理的地址，
		用page_table_add函數把數值填入兩個表(皆是最原始的兩個表)後，回傳後得到USER_STACK3_VADDR(失敗會回傳NULL)，
		
/process.c
	現在已經為USER_STACK3_VADDR找到一個物理位址，兩個表也填完了，把USER_STACK3_VADDR加回PG_SIZE即使用者將來要用的的堆疊底
	把ss賦予SELECTOR_U_DATA，
	把proc_stack(被賦予cur->self_kstack)賦予gs後把此值給esp，這時候情況會變這樣:
	
##############################################################################################
##	struct thread_stack {                                          							##
##		uint32_t ebp;      				         											##
##		uint32_t ebx;                                              							##
##		uint32_t edi;                                              							##
##		uint32_t esi;                                              							##
##	                                                               							##
##		void (*eip) (thread_func* func, void* func_arg);           							##
##		void (*unused_retaddr);                                    							##
##		thread_func* function;	由Kernel_thread所调用的函数名，類型為void (*function)(void*)##
##		void* func_arg;    	  	由Kernel_thread所调用的函数所需的参数						##
##	};                                                              						##
##############################################################################################
				!!!thread_stack緊接在intr_stack的上面(低地址處)!!!
##############################################################################################
##	struct intr_stack {                                                           			##
##		uint32_t vec_no; <---低地址  	<=== cur->self_kstack 	<== !!!esp!!!				##
##		uint32_t edi;                                                                 		##
##		uint32_t esi;                                                                 		##
##		uint32_t ebp;                                                                 		##
##		uint32_t esp_dummy;	 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略		##
##		uint32_t ebx;                                                                 		##
##		uint32_t edx;                                                                 		##
##		uint32_t ecx;                                                                 		##
##		uint32_t eax;                                                                 		##
##		uint32_t gs;                                                                  		##
##		uint32_t fs;                                                                  		##
##		uint32_t es;                                                                  		##
##		uint32_t ds;                                                                  		##
##		                                                                              		##
##		以下由cpu从低特权级进入高特权级时压入                                         		##
##		uint32_t err_code;	err_code会被压入在eip之后                                 		##
##		void (*eip) (void);                                                           		##
##		uint32_t cs;                                                                  		##
##		uint32_t eflags;                                                              		##
##		void* esp;                                                                    		##
##		uint32_t ss;     <---高地址                                                			##
##	};                                                                            			##
##############################################################################################

	最後jmp intr_exit，即跳到kernel.S的intr_exit位置，
	
/kernel.S
從esp開始，把數值一個一個pop進CPU內的暫存器，最後iretd，即pop eip，
程式進入到function函數，開始使用者的函數。

###需要注意:
###	由於CPU不允許直接由高特權等級傳遞到低特權等級，所以用退中斷的偏門方式來騙過CPU，以此傳遞特權等級。
###	
###
###	目前為使用者處理程序就建了四種分頁:
###
###	1.使用者處理程序執行緒的PCB(在process_execute函數內分配，在物理地址位於核心池內，基底地址為"核心"虛擬地址，佔一分頁)、
###
###	2.放 使用者處理程序用的虛擬位址的 點陣圖的 分頁
###   (在process_execute函數內的create_user_vaddr_bitmap函數內分配，
###   物理地址位於核心池內，基底地址為"核心"虛擬地址，大小不只一個分頁，基底地址即第一個分頁的基底位址)，
###
###	3.使用者處理程序用的 分頁目錄表
###   (在process_execute函數內的create_page_dir函數內分配，
###   物理地址位於核心池內，基底地址為"核心"虛擬地址，佔一分頁，
###   因為不能直接讓使用者訪問到分頁目錄表，所以該表的物理地址位在 核心池 中)，
###
###	4.使用者處理程序的堆疊空間 用的分頁
###   (交棒後在switch_to函數內pop到start_process函數時，在start_process函數內分配，物理地址位於使用者池內，基底地址為"使用者"虛擬地址，佔一分頁)，
###	  C程式下的 使用者 記憶體分配的規則，由低地址到高地址依序是 程式碼段、初始化資料、未初始化資料、堆疊(包含指令行參數和環境變數)，
###	  使用者處理程序的堆疊空間是 C程式下的 使用者 記憶體分配 的 一部份，所以分配到的物理地址是在 使用者池 內。
###
### 以上1. 2. 3.分頁皆是交棒給使用者前就要配置好的，為 核心 替 使用者 "先"配置的分頁，填表皆是填在最原始的兩個表內，
###	4.是 使用者自己要用的，在交棒時，進入switch_to前，會先進入process_activate函數，把cr3更新為 新的分頁目錄表的基底物理位址，
### 所以填表是填在 新的分頁目錄表 裡，此 新的分頁目錄表 的高四分之一處 複製了 原本分頁目錄表 的內容，
### 新的分頁目錄表的低四分之三處是使用者用的，還沒填任何東西，所以會先 創一個新的分頁目錄表 ，該分頁目錄表位於 使用者核心池內，然後把數值填入新分頁目錄表。
###
###
###	虛擬地址很自由，可以連續，用多大都無所謂，
###	物理地址即 核心池 和 使用者池 各不到16MB，大多都不連續，
###	如果物理地址用完，導致palloc函數回傳NULL，表示已經沒有能用的物理空間了。
###
###
###	涉及到分配記憶體的函數，都要用PV包起來，
###	如果沒用PV包起來，假如A在點陣圖找到cnt個0的位置，
###	要把這些位置置1時，突然時間到把棒交出去給B了，
###	現在B也要分配記憶體，把上一棒在點陣圖找到cnt個0的位置都置1，
###	等到棒交回來時，A已經通過 在點陣圖找到cnt個0的位置 之檢查了，
###	也會把剛剛B在點陣圖的位置也置1，即A和B用到點陣圖的同一位置了，
### 如果該點陣圖是描述虛擬位址的，會共用到同一個虛擬位址，
###	如果該點陣圖是描述核心池或使用者池的，會共用到同一個物理地址(更嚴重)，
###	所以涉及到分配記憶體的函數，都要用PV包起來!
-----------------------------------------------------------------------------------------------


/第十二章


a/
/sys.c
添加syscall.c，內有 0~3個參數的系統調用的 巨集


/syscall-init.c
添加syscall-init.c


/kernel.S
新增0x80號中斷內容，內有syscall_init函數


/interrupt.c
把支援的中斷數變為0x81個
idt_desc_init函數添加 系統呼叫的中斷門描述符號 之內容


/thread.h
在thread.h的最上面新增，
然後在struct task_struct內新增pid_t pid，


/thread.c
分配pid鎖
添加allocate_pid函數以分配pid

在init_thread函數添加pthread->pid = allocate_pid()，
每當一個執行緒在 thread_start 函數內要進入 init_thread函數 ，
就會為pthread->pid分配一個標號，每個標號不能重複使用，

在thread_init函數新增lock_init(&pid_lock)


--------------------------------------------------------------------------------------------
統整:
/init.c
進入syscall_init函數，
	
/syscall-init.c(userprog資料夾)
	在 syscall_table[SYS_GETPID]內(SYS_GETPID是列舉的"編號") 放 syscall_table函數 ，

-------------------------------------
/thread.c
一個要被封裝的執行緒還在init_thread時，會pthread->pid = allocate_pid()來獲得每個執行緒專屬的pid的值，

-------------------------------------
/syscall.c(在lib/user資料夾)
當一個使用者要系統呼叫，會藉由巨集_syscall0(NUMBER)，把編號、參數先存入暫存器(gcc的內聯組語會自動保護暫存器)，
然後int 0x80，

/kernel.S
進入到syscall_handler，
call [syscall_table + eax*4]，目前只有syscall_table[0]有被賦予數值，
所以目前理論上只能用"編號"為0的系統呼叫，之後會擴充，
syscall_table[0]內放的是sys_getpid函數，會進入到sys_getpid函數，

/syscall-init.c
	進入到sys_getpid函數，
	回傳目前執行緒當初在封裝時 在init_thread函數內 得到的 pthread->pid，該回傳值一定會存在eax，

/kernel.S
把eax內的回傳值，放在pushad內eax數值的位置，這樣popad時會把eax的數值pop進去，
因為eax pop回來的結果會被改變，所以在系統呼叫前，要先"而外"保護好eax，
由於gcc的內聯組語會自動保護好暫存器，所以不用"刻意"再去寫code保護。

--------------------------------------------------------------------------------------------
/main.c
使用者在執行時，會進入getpid函數，

/syscall.c
	在getpid函數內，會用_syscall0(SYS_GETPID)之巨集進行系統呼叫，回傳retval的值。
--------------------------------------------------------------------------------------------


b/
/syscall.h
新增SYS_WRITE之列舉編號


c/
/stdio.c
新增stdio.c，內含printf

/print.S
把.roll_screen:的
	mov esi, 0xb80a0		; 第1行行首
	mov edi, 0xb8000		; 第0行行首
換成:
	mov esi, 0xc00b80a0		; 第1行行首
	mov edi, 0xc00b8000		; 第0行行首
否則使用者系統呼叫後在卷屏會PF例外
PF例外相關內容在11-56


d/
/memory.h
新增 struct mem_block 和 struct mem_block_desc，

/memory.c
新增struct arena結構，
block_desc_init、arena2block、block2arena、sys_malloc函數，

/thread.h
struct task_struct函數內新增struct mem_block_desc u_block_desc[DESC_CNT]，

/thread.c
process_execute函數內新增block_desc_init函數，
使用者的區塊描述符號陣列在process.c內送進memory.c的mem_init函數初始化，
核心的區塊描述符號陣列在memory.c內送進mem_init函數初始化，


f/
/memory.c
新增pfree、page_table_pte_remove、vaddr_remove函數，

h/
新增malloc和free到syscall.c

--------------------------------------------------------------------------------------------------------------------
統整:

<函數介紹>
sys_malloc函數主要是在做筆記照相的事，先確認你要申請的記憶體的size對應到的 區塊描述符號的 free_list 有沒有串列在上面
(核心只有唯一一個 區塊描述陣列 ，而每個使用者都有一個專屬的 區塊描述陣列 )，
沒有的話要先申請分頁，然後把一個一個串列掛在free_list裡面，

先判斷cur_thread是核心還是使用者，賦予PF、pool_size、mem_pool、descs對應的數值，
再看你申請的記憶體多大，如果大於1024，則計算你要申請的大小 + struct arena的大小 佔多少分頁，
餘數不足1分頁直接DIV_ROUND_UP一個分頁，然後返回跨過 arena 後的起始位址，

如果你申請的記憶體小於等於1024，則要看你申請的記憶體對應到哪個 區塊描述符號，
例如你現在是 malloc(66) ，66屬於16、32、64、"128"(選能塞得下66Byte的方案)，
若該方案對應到的 區段描述符號的 free_list 沒有被掛上任何的 串列，
	則申請一個新的分頁，把arena(即a)的資訊填在新申請的分頁最底下(佔12位元組)，
	然後用for迴圈一一求出每個串列的 基底虛擬位址(b) 並一個一個放入 剛對應到的 區段描述符號的 free_list 內，
若該方案對應到的 區段描述符號的 free_list 還有 串列 掛在上面，則跳過以上被縮排的動作，
然後從 free_list中 pop出一個 串列 ，用 elem2entry巨集 得到該串列的基底位址(b)，
接著用memset函數把 剛pop出的串列的 prev和next 洗掉，
然後把arena(即a)的cnt-1(好像沒有這個cnt也沒差? 因為用list_empty函數就知道free_list是不是空的了)，
最後返回 剛pop出的串列的 基底位址(b) 。	
以上請看筆記照相對照理解!!!


pfree函數作用跟palloc相反，目的在移除一個物理地址，方法為把 物理地址 對應到的 物理地址點陣圖位置 歸0，


page_table_pte_remove函數e為page_table_add的相反，目的是把 虛擬為址 對應到表的位置 清空，
方法為把存黑色箭頭位置的P位清0就可以了，這樣CPU就會覺得黑色箭頭已經不存在了，
CPU還會把用過的虛擬為址填入自己的TLB內，所以要也要清空TLB內 該虛擬位址 的內容，用invlpg指令即可，


vaddr_remove函數為vaddr_get的相反，目的在釋放連續pg_cnt個用過的 虛擬位址，
方法為用while迴圈把 虛擬位址點陣圖 對應到的 pg_cnt個位元清0。


mfree_page函數為malloc_page的相反，目的在釋放 以傳入的虛擬地址為起始的 pg_cnt個分頁，
方法為用addr_v2p函數先把把傳入的 虛擬地址 轉換成 物理地址，
然後判斷這個 物理地址 是在 核心池 還是 使用者池 來推測 欲釋放記憶體者是 核心 還是 使用者，
然後一一用pfree函數把對應到的物理地址移除，並用page_table_pte_remove函數把 虛擬為址 對應到表的位置 清空，
最後用vaddr_remove函數 釋放連續pg_cnt個用過的 虛擬位址。


sys_free函數為sys_malloc的反向，目的是把用完的 串列 重新塞回 free_list中，
若arena所屬的所有串列(b)全部都塞回去了，那要把arena所屬的分頁整個釋放掉，
方法為先判斷欲釋放的虛擬地址是屬於使用者還是核心，然後用虛擬地址回推b為何，
再用b回推arena(a)為何，然後用a回推要釋放的是大記憶體還是小記憶體，

如果要釋放的是大記憶體(大於1024Byte)，則直接把arena所屬的所有分頁釋放掉即可(b只剩回推a用)，

如果要釋放的是小記憶體(小於等於1024Byte)，則把b塞回free_list，然後a->cnt加1，
此時若arena所屬的所有串列(b)都塞回去了，即a->cnt == a->desc->blocks_per_arena，則要把arena所屬的分頁整個釋放掉，
用for迴圈把b一個一個從free_list remove掉，最後再釋放掉arena所屬的分頁，
請看筆記照相!!!
--------------------------------------------------------------------------------------------------------------------

/第十三章
創建1個新的硬碟，大小為80Mb，用fdisk為其分割，

/timer.c
新增sleep相關函數，


/thread.c
新增idle函數，
thread_init函數新增thread_start("idle", 10, idle, NULL)，
schedule函數新增thread_unblock(idle)，
新增thread_yield函數，此函數為讓出CPU，但此函數是把目前執行緒加入就緒隊列尾，而不是加入某個等待隊列，所以不需要有其他執行緒"特意"喚醒它，

###需要注意:
###	在thread_init函數內封裝了idle之執行緒，該執行緒會被放在就緒對列中，
###	當交棒到idle的時候，會直接進入thread_block函數把自己"直接"交棒出去，不把自己放入任何一個等待隊列，
###	等到在schedule函數內發現就緒隊列為空時，就會立刻用thread_unblock函數把idle放到就緒隊列，
###	然後交棒就會給到idle，然後idle接著就會執行後面的code，也就是asm volatile ("sti; hlt" : : : "memory")，
###	先開中斷再阻塞自己，如果不先開中斷，hlt後所有的外部中斷都不會有影響了，
###	自己CPU完全不接受任何指令，直到有一個外部中斷進來，
###	當外部中斷發生後，會先進入中斷處理常式，離開中斷處理常式後程式會回到進入中斷處理常式前的地方，也就是hlt指令的位置，繼續直行接下的code，
###	然後再迴圈一次，進入thread_block函數直接把自己交棒出去，不加入任何等待隊列...如此呈現一個循環。


/ide.c
新增ide.c，內有硬碟初始化的重要函數，
																																	 
                                                                                                                                     
/stdio-kernel.c                                                                                                                      
新增printk函數，kernel版的printf。                                                                                                   
                                                                                                                                     
                                                                                                                                     
--------------------------------------------------------------------------------------------------------------------                 
第十三章統整(以下請搭配mbr.S方便理解):                                                                                               
																																	/* 超级块 */
																															 ----->	struct super_block {
																															 |			uint32_t magic;		    	
																															 |			uint32_t sec_cnt;		    
																															 |			uint32_t inode_cnt;		    
																															 |			uint32_t part_lba_base;	    
/* ata通道结构 */                                                                                                            |      	               
struct ide_channel {  <--------------------------------------------------------                                              |      	uint32_t block_bitmap_lba;	
   char name[8];			                                                  |                                              |      	uint32_t block_bitmap_sects;
   uint16_t port_base;		                                                  |                                              |      	                            
   uint8_t irq_no;			                                                  |                                              |      	uint32_t inode_bitmap_lba;	
   struct lock lock;                                                          |                                              |      	uint32_t inode_bitmap_sects;
   bool expecting_intr;		                                                  |                                              |      
   struct semaphore disk_done;           /* 硬盘结构 */                       |                                              |      	uint32_t inode_table_lba;	
   struct disk devices[2];	-----------> struct disk { <---------------------------------------------------------------      |        	uint32_t inode_table_sects;
};                                          char name[8];			   		  |                                       |      |      
                                            struct ide_channel* my_channel;	---                                       |      |        	uint32_t data_start_lba;	
                                            uint8_t dev_no;			   		             /* 分区结构 */               |      |        	uint32_t root_inode_no;	
                                            struct partition prim_parts[4];	 ----------> struct partition {           |      |        	uint32_t dir_entry_size;	
                                            struct partition logic_parts[8];                uint32_t start_lba;		  |      |      
                                         };                                                 uint32_t sec_cnt;		  |      |      	uint8_t  pad[460];		    
                                                                                            struct disk* my_disk; -----		 |		} __attribute__ ((packed));
                                                                                            struct list_elem part_tag;	     |
                                                                                            char name[8];		 	 	     |                                                              	
                                                                                            struct super_block* sb;	----------
                                                                                            struct bitmap block_bitmap; ----------> struct bitmap {                	
                                                                                            struct bitmap inode_bitmap; ------- 		uint32_t btmp_bytes_len     	
                                                                                            struct list open_inodes;	      |     	uint8_t* bits;              	
                                                                                         };                                   |    	};                             	
/* 目录结构 */                                                                                                                |                         	
struct dir {                                      /* inode结构 */                                                             ---->	struct bitmap {                                                                         	
   struct inode* inode; ------------------------> struct inode {                                                                   		uint32_t btmp_bytes_len                                                              	 
   uint32_t dir_pos;	  // 记录在目录内的偏移      uint32_t i_no;			// inode编号                                           		uint8_t* bits;                                                                       	                                                      
   uint8_t dir_buf[512];  // 目录的数据缓存                                                                                     	};                                                                                      	
};                                                   uint32_t i_size;                                                                                                                         		
																																																
													 uint32_t i_open_cnts;	// 记录此文件被打开的次数                																			
                                                     bool write_deny;	    // 写文件不能并行,进程写文件前检查此标识                                                                          	
																																															
                                                     uint32_t i_sectors[13];    		                                                                                                      	
                                                     struct list_elem inode_tag;                                                                                                              	
                                                  };                                                                                                                                          	
																																																
																																																
																																																
引导扇区,mbr或ebr所在的扇区                                                                                                                                                                   
struct boot_sector {                                                                                                                                                                          
   uint8_t  other[446];                                         构建一个16字节大小的结构体,用来存分区表项                                                                                     
   struct   partition_table_entry partition_table[4]; --------> struct partition_table_entry {                                                                         
   uint16_t signature;                                             uint8_t  bootable;		 // 是否可引导	                                                                                   
} __attribute__ ((packed));                                        uint8_t  start_head;		 // 起始磁头号                                                                                     
                                                                   uint8_t  start_sec;		 // 起始扇区号                                                                                     
                                                                   uint8_t  start_chs;		 // 起始柱面号                                                                         
                                                                   uint8_t  fs_type;		 // 分区类型                                                                                      
                                                                   uint8_t  end_head;		 // 结束磁头号                                                                                    
                                                                   uint8_t  end_sec;		 // 结束扇区号
                                                                   uint8_t  end_chs;		 // 结束柱面号
																   
                                                                   更需要关注的是下面这两项
                                                                   uint32_t start_lba;		 // 本分区起始扇区的lba地址
                                                                   uint32_t sec_cnt;		 // 本分区的扇区数目
                                                                } __attribute__ ((packed));	 // 保证此结构是16字节大小

###需要注意:                                                                                         
###	struct boot_sector是從硬碟讀回來的 扇區的 一模一樣的內容，內有4個struct partition_table_entry，記錄了4個分區的資訊，
###	每進入partition_scan函數一次就malloc struct boot_sector大小的記憶體一次，退出partition_scan函數會立即被free掉，
###
###	hd->prim_parts[p_no] 和 hd->logic_parts[l_no] 的要瑱入的內容是:
###	從struct boot_sector(硬碟讀回來的 扇區 一模一樣的內容)得知的 分區資訊，
###	由於struct ide_channel channels[2]是全域變數，所以 "筆記" 會永久保存，
###
###	通道結構、硬碟結構、分區結構 均有一項"往回指"，原因是partition_scan函數每次掃瞄一顆硬碟，所以傳進partition_scan函數的是struct disk hd，
###	在partition_scan函數內會進入ide_read函數，ide_read函數會需要去struct ide_channel獲取uint16_t port_base(即0x1fX)，
###	有"往回指"才能藉由hd->my_channel->port_base去獲得。


/ide.c
ide_init函數內，
打印"ide_init start\n"，
先從記憶體0x475(bios會把硬碟數量存在這裡)獲取硬碟的數量，然後賦予hd_cnt，
打印"   ide_init hd_cnt:%d\n"，
檢查hd_cnt是不是大於0，
初始化partition_list，此為分區隊列，將來會放part_tag，
計算有幾個通道，一個通道上可以有兩顆硬碟，用DIV_ROUND_UP(hd_cnt, 2)計算，結果賦予channel_cnt，
接著struct ide_channel* channel，此為指向通道結構的指標，
把 通道編號(channel_no) 和 硬碟編號(dev_no) 初始化為0，

進入while迴圈，每個迴圈處理一個通道(因為只有兩顆硬碟、一通道，所以while迴圈只會迴圈一次)，
把&channels[0]賦予channel，因為只有兩個硬碟，所以通道只有一個，即通道結構只會有一個，即channels[0]， <====非常重要!!!
把channels[0]的地址賦予channel(指向通道結構的指標)，
把ide0 sprintf到channel->name，
channel->port_base = 0x1f0 ==> 設定起始端口號，
channel->irq_no	= 0x20 + 14 ==> 該通道的 外部中斷的 線路 接在8259a的倒數第二個接腳，
channel->expecting_intr初始化為false，
用lock_init函初始化channel->lock，
進入sema_init，把 channel->disk_done->value 設為0，
						   ^~~~~~~~~
						   struct semaphore* psema
把硬碟的中斷處理常式(intr_hd_handler)用register_handler註冊，中斷編號為channel->irq_no，

進入"內while迴圈"，因為有兩顆硬碟，會循環兩次，
賦予hd為&channel->devices[0]，現在hd表示第0顆硬碟
設置第0顆硬碟的通道(hd->my_channel)為channel，											<======重要!!!
第0顆硬碟的編號(hd->dev_no)為0，
sprintf該硬碟的名字(hd->name)為sda <=== sd('a'+ 0*2 + 0)，
進入identify_disk函數，傳入該硬碟的結構(hd)，目的在獲得參數訊息，並打印出來，

	identify_disk函數內，
	先char id_info[512]設置buf，
	進入select_disk函數，傳入硬碟的結構(hd)，
	
		select_disk函數內，把reg_device 設為 BIT_DEV_MBS | BIT_DEV_LBA ，第7和第5固定為1，第6位為1代表LBA模式，
		如果hd是從碟，還要把reg_device的第4位設成1，目前hd是主碟，所以第4位保持為0，
		out出去，dx為reg_dev(channel)，巨集轉化為channel->port_base + 6，即1f6，al為reg_device，為1110_0000，
		離開select_disk函數，
		
	進入cmd_out函數，傳入 hd->my_channel 和 CMD_IDENTIFY(0xec，為identify指令) ，
		
		cmd_out函數內，把channel->expecting_intr設為true，準備阻塞，因為阻塞要靠中斷喚醒，所以要先開中斷，
		out出去，dx為reg_cmd(channel)，巨集轉化為reg_status(channel)，再轉化為channel->port_base + 7，即0x1f7，
		離開cmd_out函數，
	
	進入sema_down函數，傳入&hd->my_channel->disk_done，
											^~~~~~~~~
                                            struct semaphore* psema

/syn.c
		在sema_down函數內，因為channel->disk_done->value在sema_init函數被初始化為0了，所以進入sema_down函數後會直接進入while迴圈，
		把自己加入等待隊列，再進入thread_block函數，把cur_thread->status設為TASK_BLOCKED後交棒出去，

###需要注意:
### 在ide_init中，每個通道、每個硬碟都是"按照順序"處理的，所以channel->disk_done->waiters上面同時只會掛一個執行緒。


/ide.c		
**當硬碟準備好後，會產生外部中斷，程式進入到intr_hd_handler之中斷處理常式，檢查中斷號是不是0x2e或0x2f，因為兩個觸發中斷的通道只設兩個，
**把irq_no減掉0x2e(如果等於0，表示irq_no是0x2e，代表第0個通道來的中斷，否則irq_no是0x2f，代表第1個通道來的中斷)，
**把irq_no減掉0x2e的結果賦予ch_no，目前結果是0，
**把channels[ch_no](channels[0])賦予struct ide_channel* channel，表示剛剛out出去要等待中斷回來的是channels[0]，
**再檢查一次channel->irq_no是不是等於irq_no做確認，
**
**再用if檢查channel->expecting_intr是不是true，之前要進入sema_down之前，有進入cmd_out函數把channel->expecting_intr設成true，
**如果現在channel->expecting_intr是true的話，表示out出去的 channel->expecting_intr的 channel 是 channels[0]，
**可以確定說out出去時"正在"設置的通道與中斷傳回來的結果一致，channel->expecting_intr只是在添加保險而已，可有可無，
**
**把channel->expecting_intr歸回false，然後進入sema_up函數，傳入channel->disk_done，把等待隊列上的最前面的執行緒放回就緒隊列，
**																	    ^~~~~~~~~
**		                                                                struct semaphore* psema
**
**然後in硬碟狀態回來，dx是0x1f7，讓"該"硬碟知道此次中斷已被處理，可以繼續執行新的讀寫，


	處理硬碟的執行緒被交棒回來後，程式會回到identify_disk，接著用if檢查busy_wait(hd)，要進入busy_wait函數，
	
		busy_wait函數內，把hd->my_channel賦予struct ide_channel* channel，即賦予channels[0]，
		把time_limit 設為 30 * 1000 ，即30000毫秒，然後進入while迴圈，每次迴圈都減10毫秒，即每10毫秒都檢查一次，
		inb數值回來，dx是0x1f7，回傳結果會存於al，然後存入data，data作為返回值返回，
		把返回值 和 0x80(10000000)作and，如果第7位為1，表示硬碟忙，
		**因為硬碟最多會處理30秒，所以為了不浪費時間，最好是讓出CPU，
		會進入else的mtime_sleep函數，睡10毫秒，傳入10，

/timer.c		
			mtime_sleep函數內(mil_seconds_per_intr被設置為1000 / IRQ0_FREQUENCY，即1000 / 100，表示1次中斷要10毫秒)，
			現在傳入的參數m_seconds為10，DIV_ROUND_UP(m_seconds, mil_seconds_per_intr)表示有幾個10毫秒，即要被中斷幾次，
			因為被除數是10毫秒，所以要被中斷1次，檢查次數是不是大於0後，進入ticks_to_sleep函數，傳入sleep_ticks，即傳入1，
			
				ticks_to_sleep函數內，把ticks賦予start_tick，即賦予1，
				ticks是全局變數，每次時脈中斷都會+1，如果ticks - start_tick < sleep_ticks，表示目前中斷次數不足，要進入thread_yield函數，

/thread.c			
					thread_yield函數內，用running_thread獲得現在執行緒PCB的基底位址，賦予struct task_struct* cur，
					關中斷，因為要對鏈結串列操作，檢查現在的執行緒是不是沒在就緒隊列，然後把當前執行緒加入就緒隊列尾，
					把cur->status設為TASK_READY，讓schedule函數"以為"是時間到了，所以把當前執行緒放入就緒隊列尾，然後交棒出去，
					
					交棒回來後，回到thread_yield函數，恢復關中斷前狀態後返回，
					
				回到ticks_to_sleep函數，只要時脈中斷一次ticks就會+1，看看現在ticks - start_tick是不是已經 >= sleep_ticks了，
				如果沒有，就會再迴圈一次，再進入thread_yield函數，
				如果有，就不再進入迴圈，並從ticks_to_sleep函數返回，
				
			從mtime_sleep函數返回，

/ide.c		
		回到busy_wait函數，再進入一次迴圈，再把time_limit減10，
		用if看看經過mtime_sleep(10)後硬碟是否準備好了，如果還是沒準備好，則再進入else的mtime_sleep函數一次，
		如果準備好了，就再inb一次回來，dx是0x1f7，回來的結果與BIT_STAT_DRQ(0x8，1000)作and，即第4位為1表示，表示準備好數據傳輸，回傳and完的結果，
		如果30秒內，硬碟都還沒有準備好(根據手冊幾乎不可能發生)，busy_wait會回傳false，
		
	回到identify_disk函數，如果busy_wait(hd)回傳的結果是false，要顯示錯誤訊息，true的話就繼續，
	接著進入read_from_sector函數，傳入的參數有現在的hd結構、id_info[512]之buffer的地址id_info、數字1，代表讀取1個扇區，
	
		read_from_sector函數內，先uint32_t size_in_byte，要把扇區數轉化成位元組總數後給它，
		然後用if看看sec_cnt是不是等於0，如果是0，表示是用256"故意溢位"傳進函數內的，所以要256 * 512後給size_in_byte，
		現在sec_cnt是1，是真的傳1進來，直接sec_cnt * 512給size_in_byte就好，
		接著insw連續size_in_byte / 2個數據進來，因為insw讀進來的單位是"字"，也就是16位元，所以要除以2，
		insw全部讀完後從read_from_sector函數返回，
		
	回到identify_disk函數，先char buf[64]，
	然後設uint8_t sn_start = 10 * 2, sn_len = 20, md_start = 27 * 2, md_len = 40，
	10和27是字偏移量，單位是"字"，所以要乘以2轉化成位元組，20和40是長度，單位是位元組，不用再換算，
	把CMD_IDENTIFY(0xec)之identify指令用cmd_out函數out出去後，read_from_sector回來的參數訊息都是以"字"為單位，且是大端，所以要換成小端，
	因此要進入swap_pairs_bytes函數，傳入&id_info[sn_start](硬碟序號的位址，偏移量為10字、20位元組)，目標緩衝區buf(地址)，和sn_len(硬碟序號長度為20位元組)，
		
		swap_pairs_bytes函數內，進入for迴圈，把dst內的所有元素從大端變成小端後(每兩位元組一一對調)，最後在buf的最末端補上'\0'後返回，
		
	回到identify_disk函數，printk硬碟名稱和序號後，用memset把buf全部重新歸0，
	接著再進入swap_pairs_bytes函數一次，這次的目標是硬碟型號，長度為40位元組，
	回來了以後printk硬碟型號，
	最後從id_info[60 * 2]獲得硬碟的 可供使用者使用的磁區數 ，把該值賦予sectors，
	然後printk磁區數和換算成位元組的組數，
	從identify_disk函數返回，
	
回到ide_init函數，用if判斷現在的硬碟是不是60M那顆，
現在正處理這顆硬碟，因為60M這硬碟是原生硬碟，沒有檔案系統和分區，所以不掃描分區，直接跳過，
接著把p_no和l_no歸0，因為如果有進入partition_scan函數內會用到這兩個值，
然後dev_no++，處理下一顆硬碟，再進入"內while"迴圈一次，
這次再到if判斷式時，由於現在是處80M這顆，所以會進入partition_scan函數，傳入硬碟結構和扇區號(lba)，掃描硬碟上的分區，
	
	partition_scan函數內，因為如果掃到擴展分區要遞迴，堆棧會疊很高，所以用sys_malloc申請struct boot_sector的空間，每次遞迴一次就再多申請一個，
	進入ide_read函數，傳入硬碟結構、扇區號、buf、要讀的扇區數，
	
		ide_read函數內，檢查扇區號有沒有超過最大值，再檢查扇區數有沒有大於0，
		然後進入PV區，
		接著用select_disk函數選擇硬碟，定義 每次操作的扇區數(secs_op) 和 已完成的扇區數(secs_done，目前完成數為0) ，
		接著進入while迴圈，如果已完成的扇區數小於欲讀的扇區數(sec_cnt)就要一直迴圈，
		因為硬體的設計為1次最多就只能讀256個扇區，如果(secs_done + 256) <= sec_cnt，表示欲讀的扇區數(sec_cnt)有256個以上，所以secs_op先給256，
		若欲讀的扇區數(sec_cnt)沒有256個以上，直接給sec_cnt - secs_done到secs_op就好，secs_op為每次操作的扇區數，
		進入select_sector函數，傳入硬碟結構(hd)、扇區號(lba + secs_done)、欲讀的扇區數(secs_op)，
		
			select_sector函數內，檢查扇區號(lba)有沒有超過最大值，賦予struct ide_channel* channel為hd->my_channel，即賦予channels[0]，
			outb出去，寫入"要讀的扇區數"，dx是0x1f2，al為1，
			outb lba出去，分4次，最後一次因為lba的內容跟device的內容重合，所以要先把device重新填寫再outb出去，
			outb 4次後返回，
		
		回到ide_read函數，目前已經寫入要讀的扇區數和初始扇區號(lba)了，接著要讀取硬碟傳回來的數據，
		所以要進入cmd_out函數，傳入hd->my_channel(channels[1])、讀取指令CMD_READ_SECTOR(0x20)，	
		回來後再用busy_wait檢查硬碟在30秒內，有沒有準備好，
		接著進入read_from_sector函數，直接把數據從硬碟讀出，
		要傳入硬碟的結構(hd)，
		要傳入的buffer是buf + secs_done * 512，secs_done是 "已操作完"的扇區數 ，一個扇區佔512位元組，新數據要從buffer的buf + secs_done * 512的這個位址寫入，
		要傳入的 "要讀取的"扇區數 是 secs_op，
		讀完傳回來後，要讀取的扇區數(secs_op)就變成已讀取的扇區數(secs_done)，把secs_opsecs_done加入secs_done，
		最後解鎖，然後從ide_read返回
		
	回到partition_scan函數，定義part_idx並先初始化為0，
	struct boot_sector的 struct   partition_table_entry partition_table(p) 有4個 "記錄"，
	要用part_idx分別為4個記錄之 struct   partition_table_entry partition_table(p) 作處理，
	要處理4次，進入while後迴圈4次(看筆記照相!!!)，
	進入partition_scan時傳進來的ext_lba是0，表示現在要處理的是主分區，主分區內有4個記錄，要進入while迴圈一一處理，
	現在在處理第0個分區，ext_lba_base和ext_lba都一定為0，用p->fs_type判斷第0個分區的第0個記錄是不是指向擴展分區，
	
	==>如果指向的是擴展分區，因為是第0個分區，ext_lba_base為0，直接把p->start_lba賦予ext_lba_base，
	然後再進入partition_scan函數遞迴，傳入的 要掃描的 起始扇區號是p->start_lba，
	若遞迴到的下一個partition_scan函數內的p->fs_type依然表示此記錄指向擴展分區，由於現在掃描的起始分區已經不是0了，
	所以ext_lba_base != 0，直接再遞迴到下一個partition_scan函數，傳入的 掃描起始扇區號是p->start_lba + ext_lba_base，
	
	==>如果p->fs_type表示記錄指向的不為擴展分區，那表示這個記錄指的不是EBR，而是 "普通的" 分區了，因此不用再遞迴，
	若此時ext_lba為0，表示第1次進入partition_scan函數，此時在處理的是主分區內的記錄，
	一個主分區內的記錄不是指向主分區就是就是擴充分區，一個主分區內的記錄最多就 4個，
	賦予hd->prim_parts[p_no].start_lba為下一個 "普通的" 分區的起始扇區號，p_no為主分區的編號，主分區內最多就只有4個記錄，
	賦予hd->prim_parts[p_no].sec_cnt為下一個 "普通的" 分區 所佔用的扇區數，
	賦予hd->prim_parts[p_no].my_disk為現在這顆硬碟，即賦予hd，
	把hd->prim_parts[p_no].part_tag加入partition_list之鏈結串列，                                 						 <==============================重要!!!
	sprintf 硬碟中的 分區的 名字到 hd->prim_parts[p_no].name，分區的命名方式為硬碟名+主分區編號，
	然後p_no+1，檢查有沒有小於4，因為主分區內的分區最多就4個，從0開始算，//
	若此時ext_lba不為0，表示現在處理的分區已經不是主分區了，而是在EBR內，所有在EBR內分區最多就處理8個，
	所以若l_no >= 8，就直接返回，//
	處理完1個分區後就p+1，繼續處理下一個分區，一個分區要處理4個分區
	全處理完以後釋放struct boot_sector* bs所申請的記憶體，然後返回，
	
回到ide_init函數，至此已經scan完硬碟內所有的分區內的分區了，把p_no和l_no歸0，dev_no+1繼續處理下一顆硬碟，
如果所有的硬碟都處理完了，直接離開"內while"迴圈，
printk "\n   all partition info\n"後，直接進入list_traversal函數，打印所有"分區"的訊息，
需要注意的是，傳入list_traversal函數內的參數之 partition_info函數 最後都返回false，目的只是遍歷所有partition_list的元素，
最後printk "ide_init done\n"，至此所有硬碟初始化結束。

###需要注意:
###	和identify_disk函數相比，ide_read函數多了select_sector函數，要寫入待讀入的扇區數和起始扇區號，
###
###	ide_read和ide_write的cmd_out之前可說是完全一樣，之後開始順序會不同，
###	ide_read會先把數據從硬碟放入緩衝區上，再從緩衝區把數據放入記憶體，
###	而ide_write，會先從記憶體把數據放入緩衝區內，再把數據放入硬碟內，
###	兩者順序剛好相反，
###	關連到 記憶體和緩衝區之間的 操作 進行前 要先進入busy_wait函數等最多30秒，
###	在busy_wait函數內確定 !(inb(reg_status(channel)) & BIT_STAT_BSY 成立後，再把數據從緩衝區放到記憶體或從記憶體放到緩衝區，
###	關連到 緩衝區和硬碟內之間的 操作，要進入sema_down函數，把當前執行緒放到hd->my_channel->disk_done->waiters上，
###	等到操作完畢，會發出硬碟的外部中斷，進入中斷處理常式，然後進入sema_up函數，把hd->my_channel->disk_done->waiters上的執行緒放回就緒隊列。


-----------------------------------------------------------------------------------------------------------------------------------------------
第十四章


新增檔案系統，包含fs.c、file.c、inode.c、dir.c，

struct task_struct新增int32_t fd_table[MAX_FILES_OPEN_PER_PROC]，此為檔案描述符號陣列，
新增cwd_inode_nr，此為處理程序所在的工作目錄的編號，

init_thread函數新增pthread->fd_table[0]=0、pthread->fd_table[1]=1、pthread->fd_table[2]=2，pthread->fd_table剩下的全設置成-1，
0是標準輸入、1是標準輸出、2是標準錯誤，
新增pthread->cwd_inode_nr = 0，此步驟為把跟目錄作為預設路徑，

修改sys_write函數，新增檔案寫入的功能，當傳進來的fd是標準輸出(=1)，則跟之前一樣進行普通的輸出，把buf內容輸出到螢幕上，
如果fd != 1，則進入file_write進行檔案的寫入，


###需要注意:
###	目錄=資料夾，目錄算是一種另類的"檔案"，
###
###	inode可以理解為對某一檔案 點滑鼠右鍵->內容 後 看到的內容，inode內包含i_sectors，
###	把inode從硬碟讀到記憶體內的行為為inode_open，如果已經open，則記錄open次數就好，
###
###	inode內的i_sectors所指向的 塊內的 內容 可以理解為 對該檔案點滑鼠兩下後看到的結果，
###	對目錄(資料夾)點兩下的話可以看到一個資料夾內的很多的檔案(目錄算一種另類的檔案)，
###	對普通檔案點兩下的話可以看到檔案內的實際文字內容，
###	
###	由於i_sectors位於inode內，所以要看一個檔案內的內容要先操作inode，
###	操作目錄(資料夾)的inode前要先把inode掛到struct dir上，
###	操作普通檔案的inode前要先把inode掛到struct file上，
###	把inode掛在struct dir或struct file的動作視為"打開(open)"該檔案，			<================================非常重要!!!
###
###	struct file file_table[MAX_FILE_OPEN]定義在file.c內，記錄目前已經被打開的檔案，
###	int32_t fd_table[MAX_FILES_OPEN_PER_PROC]定義在thread.c內，記錄所有已經被打開的檔案中，是被該執行緒打開的檔案。



<函數介紹>

/fs.c
---------------------------------------------------------------------------------------------------------------------
=====>partition_format函數目的在某一 分區 內 填入最基本的 初始資料，<=====

-----格式化分區-----
把所有的數據一一算出來，
這些數據都是分區內的資訊，比如分區內的某某區域的起始扇區和占用扇區數，
包括sb.block_bitmap_sects、sb.inode_bitmap_sects、sb.inode_table_sects 等，

-----超級塊初始化-----
把 struct super_block sb 內 前面算的數值都填進去，
這些數值要永久記錄在硬碟中，目前先記錄在記憶體低端1MB的struct super_block sb，

----1 將超級塊寫入本分區中的1扇區-----
把&sb寫入硬碟內 本分區的 1扇區(0扇區是作業系統啟動塊)，超級塊占用整個第1扇區，
比較sb.block_bitmap_sects、sb.inode_bitmap_sects、sb.inode_table_sects的大小，
用最大的size送入sys_malloc申請一個buf，該buf要重複使用，要確保要用的人的數據都放得進去，
所以要用最大的size去申請，

----2 將塊點陣圖初始化並寫入sb.block_bitmap_lba-----
先用block_bitmap_bit_len / 8得到 塊點陣圖 的最後面 落在第幾位元組上(從0開始算)，該值為block_bitmap_last_byte，
再用block_bitmap_bit_len % 8得到 塊點陣圖 的最後面 在位元組內的 第幾位元上，該值為block_bitmap_last_bit，
最後用SECTOR_SIZE - (block_bitmap_last_byte % SECTOR_SIZE)算出， 塊點陣圖 的最後面 所在的位元組 到 扇區結束還剩下多少 位元組，
(塊點陣圖 的最後面 所在的位元組 也算一個)，該值為last_size，
以上三者請看筆記照相!

接著要把 塊點陣圖 最後面的 超出點陣圖不足1位元組的部分 全部置1，分兩步驟，
	/第1步驟
	先將塊點陣圖最後一個位元組 到 扇區結束 所有的位元組都置1，這個區間的大小為，last_size，
	方法為memset(&buf[block_bitmap_last_byte], 0xff, last_size)，
	/第2步驟
	剛剛在第1步驟把 塊點陣圖 的最後面 所在的位元組 全部先設成1了，現在要把該位元組內 前面的部分 被1覆蓋掉的部分全重新置0，
	方法為用while (bit_idx < block_bitmap_last_bit)把覆蓋掉的部分重新置0，原本該位元組內該為1的數量為 block_bitmap_last_bit 個，

最後ide_write塊點陣圖到硬碟上，

----3 將inode點陣圖初始化並寫入sb.inode_bitmap_lba-----
先用memset(buf, 0, buf_size)把剛剛用的buf清0，
因為現在要直接為根目錄分配一個inode，所以把inode點陣圖的第0位置1，剩下的位數對應到的inode還未被分配，所以保持在0，
因為當初設定inode提供數量為4096個，一個inode對應inode點陣圖的一個位元，所以inode點陣圖剛好會填滿1個扇區，
所以不用像塊點陣圖一樣處理最後1扇區剩餘的部分
最後ide_write把inode點陣圖到硬碟上，

----4 將inode數組初始化並寫入sb.inode_table_lba-----
先用memset(buf, 0, buf_size)把剛剛用的buf清0，然後再struct inode* i，其基底位址等於buf，
根目錄最初始會有.和..，所以i->i_size為bitmap_sync，即sb.dir_entry_size * 2，
根目錄所屬的inode為0，

把i->i_sectors[0]指向sb.data_start_lba，即指向空閒塊區域內最開始的塊，
##需要注意:
##	根目錄內的內容(目錄項)寫在i->i_sectors[0]所指的塊中，
##	i->i_sectors所指的其中一個塊內可以有很多的資料夾，
##	根目錄內目前就只設置.和.. 兩個 "在視窗看不見"的資料夾，所以只設置i->i_sectors[0]這一個就夠了，

最後ide_write把inode數組寫到硬碟上，

----5 將根目錄初始化並寫入sb.data_start_lbaa-----
現在要設置i->i_sectors[0]所指的塊內的 兩個 "在視窗看不見"的資料夾(.和..)的內容， 
先用memset(buf, 0, buf_size)把剛剛用的buf清0，然後再struct dir_entry* p_de，其基底位址等於buf，

先初始化當前目錄(.)，
用memcpy設定名字為.，
p_de->i_no = 0為0，即指向根目錄自己的inode，
p_de->f_type為FT_DIRECTORY，表示p_de指向的inode被分配給"目錄類"的檔案，
p_de++，接著要設置".."，當前目錄的p_de後面緊跟著父目錄的p_de，

先初始化當前目錄的父目錄，即"上一頁"目錄(..)，
用memcpy設定名字為.，
p_de->i_no = 0為0，即指向根目錄自己的inode，
p_de->f_type為FT_DIRECTORY，表示p_de指向的inode被分配給"目錄類"的檔案，

最後ide_write把根目錄的inode指向的 塊的內容 寫到硬碟上，
因為.和..的p_de都在 空閒塊區域內最開始的 "1個"塊內，只要寫入1個塊(1個扇區的大小就夠了)，

printk 空閒塊區域內最開始的扇區號 和 "扇區名字" format done\n 後，釋放buf。


---------------------------------------------------------------------------------------------------------------------
=====>mount_partition函數目的在於找到名字為int arg的分區，如果找到會將該分區內的超級塊和兩個點陣圖從硬碟讀到記憶體內，該函數會被list_traversal函數呼叫<=====
先把arg賦予part_name，
再藉由elem2entry把掛在struct list partition_list上的其中一個part_tag(在ide.c的partition_scan函數內被加入到struct list partition_list內)轉化為struct partition* part，

比對part->name是否等於part_name，
如果相等，則cur_part = part，struct disk* hd = cur_part->my_disk，
如果不同，則直接返回false，list_traversal函數會繼續傳下一個struct list_elem* pelem到mount_partition函數內，
然後sys_malloc一個扇區的大小，其地址賦予struct super_block* sb_buf，
接著sys_malloc一個struct super_block的大小，其地址賦予cur_part->sb，並檢查記憶體申請有沒有成功，

接下來開始把超級塊和兩個點陣圖從硬碟讀到記憶體內，即掛到位於記憶體內的struct partition內部，

1 首先讀取超級區塊，把sb_buf清0後(sys_malloc內會自動清0，可有可無?)，把start_lba+1(超級塊的所在處)的整個扇區讀到sb_buf內，
然後再把sb_buf內的超級塊大小的內容複製到cur_part->sb內
(因為ide_read最小的單位為1個扇區，所以要先讀一整個扇區，再複製一個超級塊大小的內容到cur_part->sb內)，

2 接著讀取塊點陣圖，
先sys_malloc大小等於一個塊點陣圖的記憶體，檢查申請是否成功後，把地址賦予cur_part->block_bitmap.bits，
cur_part->block_bitmap.btmp_bytes_len要被賦予塊點陣圖的長度，單位為byte，要從超級塊內獲得塊點陣圖占用的扇區數 乘以 扇區內位元組的大小，
所以cur_part->block_bitmap.btmp_bytes_len要被賦予sb_buf->block_bitmap_sects * SECTOR_SIZE，
由於塊點陣圖大小超過1個扇區，且最後不足1扇區的部分也用1填滿了，
所以不需要像超級塊那樣還要再切小塊一點，直接ide_read到cur_part->block_bitmap.bits上，

3 最後讀取inode點陣圖，
一樣也先sys_malloc大小等於一個inode點陣圖的記憶體，檢查申請是否成功後，把地址賦予cur_part->inode_bitmap.bits，
cur_part->inode_bitmap.btmp_bytes_len要被賦予inode點陣圖的長度，單位為byte，要從超級塊內獲得inode點陣圖占用的扇區數 乘以 扇區內位元組的大小，
所以cur_part->inode_bitmap.btmp_bytes_len要被賦予sb_buf->inode_bitmap_sects * SECTOR_SIZE，
由於inode點陣圖大小剛好等於1個扇區，
所以也不需要像超級塊那樣還要再切小塊一點，直接ide_read到cur_part->inode_bitmap.bits上，

初始化雙向鏈結串列cur_part->open_inodes，因為剛剛已經把inode點陣圖掛到記憶體內了，
表示即將把struct inode從硬碟讀出來，讀出來的inode會被放入記憶體內的cur_part->open_inodes上，
所以現在先初始化雙向鏈結串列cur_part->open_inodes，

最後printk掛載完成之文字，並返回true。


---------------------------------------------------------------------------------------------------------------------
=====>path_parse函數的目的為把路徑的最上層路徑"名稱"拔出來並存入 傳進函數內的char* name_store，並回傳"被拔頭的路徑"<=====


---------------------------------------------------------------------------------------------------------------------
=====>path_depth_cnt函數目的在計算路徑的深度，透過不斷的調用path_parse函數把路徑頭一一拔掉，每調用一次depth就加1，
直到進入path_parse後存入char* name_store name的值為NULL為止，回傳depth<=====


---------------------------------------------------------------------------------------------------------------------
=====>search_file函數目的在於確定某路徑上的所有檔案(資料夾算一種"特殊的"檔案)是否真的在硬碟上(找不到會return -1)，
並把路徑的最後一個檔案的父目錄記錄在struct path_search_record內的struct dir* parent_dir，
並且把最後一個檔案的類型記錄在enum file_types file_type，並把已經搜尋的路徑填入char searched_path[MAX_PATH_LEN]，
並回傳最後一個檔案的inode_no<=====

詳解請看筆記照相!!!


=====>sys_open函數的目的在"建立"或"開啟"某個檔案，
需檢查傳入的flag，假如路徑上沒找到且flag不是要建立檔案，要回傳-1；
假如flag是要建立檔案，但建立的檔案已經存在，也要回傳-1；
成功"建立"或"開啟"某個檔案則回傳該檔案的fd_table[X]的X值<=====

先檢查傳進來的路徑的最後一個字是不是'/'，此時不該為'/'，
然後檢查flags是不是小於等於7，因為一個檔案只有8種讀寫狀態，所以flags不應該大於7，

設置struct path_search_record searched_record，用memset把searched_record內全部清0(添保險)，
把pathname送入path_depth_cnt函數內計算pathname的長度，

進入search_file函數，傳入路徑和&searched_record，
若路徑上確實有檔案在，search_file函數會回傳該檔案的inode_no，
若路徑上沒有檔案在或者是路徑中的某個資料夾不存在，search_file函數會回傳-1，

search_file函數若有找到東西，會把找到的東西的類型記錄在searched_record.file_type內，
因為sys_open函數可以用來開啟檔案，但不能開啟目錄(開啟目錄要用sys_opendir函數)，
所以若searched_record.file_type為FT_DIRECTORY，sys_open函數要回傳-1，

若pathname_depth != path_searched_depth，表示沒有找完全部的路徑，意即路徑的中間某個資料夾不存在，sys_open函數要回傳-1，

假如現在不是要創建檔案，而是要開啟某個檔案，則該檔案一定要真實存在，
若現在不是要創建檔案!(flags & O_CREAT)，且用search_file函數找不到要開啟的檔案(!found)，則sys_open函數要回傳-1，

若現在是要創建檔案(flags & O_CREAT)，但search_file函數卻找到要開啟的檔案(found)，
表示你要創的檔案在資料夾內(父目錄內)已經有一個同名的檔案了，sys_open函數要回傳-1，

目前已經通過三項檢查，現在可以正式開始建立檔案或開啟檔案的程序了，
若現在是要創建檔案，則進入file_create函數，file_create完後用dir_close函數把檔案所在的資料夾(父目錄)關閉，
否則進入file_open函數，因為是"開啟"檔案，所以被開啟的檔案所在的資料夾(目錄)不用關， <---*?
最後回傳該檔案的fd_table[X]的X值。


---------------------------------------------------------------------------------------------------------------------
=====>local2global函數目的在於回傳fd_table[X]值(X為傳入的參數)，即回傳檔案編號<=====


---------------------------------------------------------------------------------------------------------------------
=====>sys_close函數目的在於"關閉"某個檔案，為sys_open函數的反向，由於傳入sys_close函數的是檔案的X值，不是路徑，
因為要關閉的檔案一定有經過sys_open開啟，所以該檔案的路徑上的目錄(資料夾)一定真的存在硬碟上，因此不用特別經過路徑檢查，
由於該函數的功能只有一種，不像sys_open函數有"建立"或"開啟"檔案之兩種功能，所以不用"特別"去考慮兩種狀況，
所以sys_close函數相較於sys_open函數會簡單很多<=====

先進入local2global函數並傳入X值，回傳fd_table[X]值(檔案編號)，把該值賦予_fd，
然後進入file_close函數，傳入&file_table[_fd](定義為:struct file file_table[X])，成功回傳true，該值賦予ret，
然後把running_thread()->fd_table[fd]重置為-1，
回傳ret。


---------------------------------------------------------------------------------------------------------------------
=====>sys_lseek函數目的在於設置檔案內的操作位置，即設置fd->pos的值，有3種設置方式(whence)，成功後回傳fd->pos的值，
進入file_read函數前，需要設置 開始讀取的位置 ，即設置所謂的 操作位置<=====

方式為把傳入的X值進入fd_local2gglobal函數轉換成file_table[X]值，該值賦予_fd，
然後把&file_table[_fd]賦予pf，file_table的型別為struct file file_table，

	===>如果whence是SEEK_SET，直接把offset賦予new_pos，
	
	===>如果whence是SEEK_CUR，把 offset加上fd_pos後 賦予new_pos，此時offset可正可負，

	===>如果whence是SEEK_END，把 offset加上file_size後 賦予new_pos，此時offset只能為負值，
	
最後把new_pos賦予pf->fd_pos，然後回傳pf->fd_pos值。


---------------------------------------------------------------------------------------------------------------------
=====>filesys_init函數目的為初始化檔案系統，需要做3件事:
1.進入while迴圈，用partition_format初始化各分區的元資訊，包括超級塊、各個點陣圖。
 .進入list_traversal函數內，傳入分區名字"sdb1"，在其內遍歷呼叫mount_partition函數，
2 把分區sdb1的超級塊和兩個點陣圖掛載到記憶體內
3.進入open_root_dir開啟根目錄
4.把file_table[X](extern在file.h內)所有的file_table[X].fd_inode置為NULL
<=====


---------------------------------------------------------------------------------------------------------------------
=====>sys_unlink函數的目的在刪除某個普通檔案，為sys_open函數內(定義在file.c中)的 "跟file_create函數有關的部分"的 反向<=====

*驗證傳進來的路徑的最後一個字是不是'/'，此時不該為'/'(該步驟在書上被忽略)，

進入search_file函數，傳入路徑和&search_record，
因為現在是要刪除"已存在"的普通檔案，所以search_file函數回傳的結果一定要不等於-1，否則sys_unlink函數回傳-1，
因為要刪除的是"普通檔案"，所以search_file函數內記錄在search_record.file_type一定不能是"目錄"，否則sys_unlink函數回傳-1，
回想平常在使用電腦的情況，當你現在正打開一個檔案時，該檔案不能被刪除，
所以要檢查準備要刪除的檔案是不是在file_table內，如果是，則sys_unlink函數回傳-1，

通過3個檢查後，現在可以正式刪除檔案了，

先用sys_malloc申請一個公用buffer，名字為io_buf，大小為1024位元組，因為inode可能有跨越扇區的情況，要讀取兩個扇區，

然後依file_create函數的 倒退順序 完成檔案的刪除步驟，file_create函數內原本順序如下:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
1.建立檔案，要有屬於它的inode，對其按右鍵點內容可以看到其對檔案的描述內容，
  所以要新增一個inode，這導致inode_bitmap被更新，inode_bitmap的改變要同步到硬碟上，且新增的inode也要寫入硬碟永久保存，
2.新建立的檔案必放在資料夾內的某一處，點開資料夾就會看到它，
  所以父目錄(資料夾)的inode->i_sectors所指的塊內要多一個dir_entry，這會導致父目錄(資料夾)inode->i_size會增加一個dir_entry的大小，
3.如果2.沒有任何一個塊有空間可以放新的dir_entry，需要申請一個新的block，
  這導致block_bitmap需要被更新(這更新的操作會在sync_dir_entry函數內完成，不需要在filr_creat函數內做)，
  且新的block的扇區號要填入inode->i_sectors[X]中，2.和3.的操作導致父目錄的inode被改變
4.以上操作如果某步發生失敗，需要回復以前已成功的操作
5.inode_bitmap、block_bitmap、父目錄的inode以及新增檔案的inode要同步到硬碟
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

根據2.和3.，需要把父目錄內欲被刪除的檔案的目錄項(dir_entry)從硬碟上移除，因此進入delete_dir_entry函數，
在其內若塊上所有的目錄項都清掉了，也要把該塊釋放掉，這會涉及到block_bitmap的改變，
block_bitmap把需要被釋放的塊對應到的位置0後，需要被更新(同步)到硬碟上，在delete_dir_entry函數內會同時完成，

根據1.需要把欲刪除檔案的inode給釋放掉，但當初file_create的時候還沒有用file_write把內容寫入檔案，
現在要刪除檔案，檔案內可能已經包含已被寫入的內容(包括 存放寫入內容的 塊)，
所以要進入inode_release函數把被寫入的內容全部清掉，

	inode_release函數內 會把 存放寫入內容的 塊 對應到的block_bitmap的位 置0，
	也會順便直接把inode對應到的inode_bitmap的位給置0，並同步到硬碟上，所以回到sys_unlink函數後就不用再做了，
	
回到sys_unlink函數後，至此公用buffer用罄，所以sys_free(io_buf)，
用dir_close函數把父目錄關閉，回傳0。


---------------------------------------------------------------------------------------------------------------------
=====>sys_mkdir函數的目的為建立目錄，為sys_open函數內(定義在file.c中)的 "跟file_create函數有關的部分"的 類似版，
回想平常用電腦時在電腦裡建立一個資料夾的過程，可以得知需要以下步驟:

~~~~~~~~~~~~~~~~~~~~~~~~~~~以下類似於file_create函數的部分~~~~~~~~~~~~~~~~~~~~~~~~~~~
1.建立資料夾，要有屬於它的inode，對其按右鍵點內容可以看到其對資料夾的描述內容，
  所以要新增一個inode，這導致inode_bitmap被更新，inode_bitmap的改變要同步到硬碟上，且新增的inode也要寫入硬碟永久保存，
2.新建立的資料夾 必放在 父資料夾內的 某一處，點開資料夾就會看到它，
  所以父目錄(資料夾)的inode->i_sectors所指的塊內要多一個dir_entry，這會導致父目錄(資料夾)inode->i_size會增加一個dir_entry的大小，
3.如果2.沒有任何一個塊有空間可以放新的dir_entry，需要申請一個新的block，
  這導致block_bitmap需要被更新(這更新的操作會在sync_dir_entry函數內完成，不需要在filr_creat函數內做)，
  且新的block的扇區號要填入inode->i_sectors[X]中，2.和3.的操作導致父目錄的inode被改變
4.以上操作如果某步發生失敗，需要回復以前已成功的操作
5.inode_bitmap、block_bitmap、父目錄的inode以及新增的資料夾的inode要同步到硬碟

~~~~~~~~~~~~~~~~~~~~~~~~~~~以下類似於sys_open函數內涉及到file_create函數的部分~~~~~~~~~~~~~~~~~~~~~~~~~~~
6.不能創建名字相同的資料夾，例如說你要在/a/b/c內創立一個名字為d的資料夾，那把/a/b/c/d送進search_file函數內應該要找不到，

~~~~~~~~~~~~~~~~~~~~~~~~~~~以下是sys_mkdir函數特別需要多做的部分~~~~~~~~~~~~~~~~~~~~~~~~~~~
7.新目錄中要建立"."和".."兩個目錄項，分別表示 當前資料夾 和 上一頁資料夾

<=====

先用sys_malloc申請一個公用buffer，名字為io_buf，大小為1024位元組，因為inode可能有跨越扇區的情況，要讀取兩個扇區，

根據6.，進入search_file函數，傳入路徑和&search_record，
因為現在是在"建立"目錄，所以search_file函數應該要回傳-1，且要找到全部的路徑，

根據1.，進入inode_bitmap_alloc函數內為inode分配一個inode，其函數內會把inode_bitmap對應到的位置1，然後回傳inod_no，
接著用sys_malloc一個inode大小的記憶體(這記憶體是inode掛到RAM內會用到的，因為現在是創新的inode，可視為"另類的"開啟inode)，如果失敗要回退，

因為inode是新創的，所以要初始化，進入到inode_init內，把inode的最初數值都填進去，

根據7.，新目錄中要建立"."和".."兩個目錄項，需要申請一個塊來擺這兩個目錄項
(因為"."和".."是要填入第一個塊最開始的兩個位置，所以不用刻意進入sync_dir_entry函數去找一個地方填目錄項，簡單處理就好)，
先進入block_bitmap_alloc函數為"."分配一個塊，如果失敗要回退，
然後把新分配的扇區號填入new_dir_inode.i_sectors[0]，
再進入bitmap_sync函數把block_bitmap同步到硬碟上，
接著要把"."和".."兩個目錄項寫入塊內，
先用memset把io_buff全部清0(添保險)，然後把void* io_buf強制轉換成struct dir_entry* p_de，
--->把"."用memcpy填入p_de->filename，
--->把inode_no填入p_de->i_no，
	這個inode_no是要新創建的目錄用的inode的編號，在此填入這個是要讓新創建的目錄的new_dir_inode.i_sectors[0]指的塊的 內部的 目錄項 指向自己，
	inode_no待會也會用creat_dir_entry函數和sync_dir_entry函數填入父目錄的inode->i_sectors所指的塊內，
--->把FT_DIRECTORY填入p_de->f_type，"."算 目錄 類，
接著p_de加1，
--->把".."用memcpy填入p_de->filename，
--->把parent_dir->inode->i_no填入p_de->i_no，parent_dir是search_file函數後記錄在search_record內的父目錄，
--->把FT_DIRECTORY填入p_de->f_type，".."算 目錄 類，
至此已完成兩個目錄項的填寫，用ide_write把兩個目錄項所在的塊填入硬碟，

根據2.，父目錄(資料夾)的inode->i_sectors所指的塊內要多一個dir_entry，
所以先struct dir_entry new_dir_entry，然後進入creat_dir_entry函數，初始化new_dir_entry，
然後進入sync_dir_entry函數，在父目錄(parent_dir)內的 inode(父目錄本身的inode，不是新創的)內的 i_sectors[X]所指向的塊內 找一個可以放new_dir_entry的位置，
如果失敗，會回傳false，然後要回退，

根據3.，父目錄的inode有被改變，所以要進入inode_sync函數更新父目錄的inode，
根據1.，新增的inode也要寫入硬碟永久保存，所以要進入inode_sync函數ide_write新檔案的inode，
根據1.，因為新增一個inode，所以導致inode_bitmap被更新，要同步到硬碟上，因此進入bitmap_sync函數更新inode_bitmap，

由於為新檔案新增一個新的inode，這是"另類的"開啟新檔案的inode，所以要把new_file_inode->inode_tag放入cur_part->open_inodes上，
並且把new_file_inode->i_open_cnts等於1，

至此公用buffer用罄，所以sys_free(io_buf)，

用dir_close函數把父目錄關閉(在file_create時，這個步驟是返回到sys_open函數後才做)，回傳0，

如果以上某一步失敗，則goto rollback的地方，回退上一步後，sys_free(io_buf)，並返回-1。


---------------------------------------------------------------------------------------------------------------------
=====>sys_readdir函數目的在讀取一個目錄項，該函數檢查傳進來的dir是不是為NULL，然後進入dir_read函數，sys_readdir函數回傳dir_read函數回傳的目錄項<=====


---------------------------------------------------------------------------------------------------------------------
=====>sys_rewinddir函數目的在把dir_pos歸0<=====


---------------------------------------------------------------------------------------------------------------------
=====>sys_rmdir函數目的在刪除某個目錄，為sys_mkdir函數前半的部分的反向，類似sys_unlink函數的前半部分，
sys_rmdir函數會完成 類似sys_unlink函數的 file_search的部分完成，剩下的部分會進入dir_remove函數做處理<=====

*驗證傳進來的路徑的最後一個字是不是'/'，此時不該為'/'(該步驟在書上被忽略)，

進入search_file函數，傳入路徑和&search_record，
因為現在是要刪除"已存在"的目錄，所以search_file函數回傳的結果一定要不等於-1，否則sys_rmdir函數回傳-1，
因為要刪除的是"目錄"，所以search_file函數內記錄在search_record.file_type一定要是"目錄"，否則sys_rmdir函數回傳-1，
目錄允許在打開的時候刪除(向來都是如此，可以用自己的電腦測試)，所以不用特別檢查該目錄是不是已經開啟了，
因為sys_rmdir函數只允許刪除空目錄，所以用dir_is_empty函數測試欲刪除目錄是否為空，否則sys_rmdir函數回傳-1，

通過3個檢查後，現在可以正式刪除檔案了，

進入dir_remove函數，若返回0表示目錄刪除成功，

由於有進入search_file函數，該函數會在開啟searched_record.parent_dir的情況下返回，
所以回到sys_rmdir函數後要多做dor_close(searched_record.parent_dir)的動作，

若dir_remove函數返回0，則sys_rmdir函數返回0。


---------------------------------------------------------------------------------------------------------------------
=====>get_parent_dir_inode_nr函數目的在獲得父目錄的inode編號，
該函數會傳進child_inode_nr，藉由".."來獲得父目錄的inode編號<=====

打開child_inode_nr，把傳回的 被sys_malloc的inode的記憶體 賦予child_dir_inode，
把child_dir_inode>i_sectors[0]賦予block_lba，
檢查block_lba >= cur_part->sb->data_start_lba有沒有成立，
關閉child_inode_nr，

用ide_read把block_lba號的扇區(塊)ide_read到io_buf內，
把io_buf的型別強制轉化為struct dir_entry，賦予struct dir_entry* dir_e，
".."位於的目錄項位於dir_e[1]之位置，
所以檢查dir_e[1].i_no是不是<4096 且 dir_e[1].f_type是不是==FI_DIRECTORY，
回傳dir_e[1].i_no。


---------------------------------------------------------------------------------------------------------------------
=====>get_child_dir_name函數目的在於在inode編號為p_inode_nr的目錄內尋找inode編號為c_inode_nr的子目錄的名字<=====

把編號為p_inode_nr的inode打開，獲得父目錄的inode號，把該值賦予struct inode* parent_dir_inode，
藉由parent_dir_inode->sectors[X]把扇區號填入all_blocks中，若有間接塊，則要把間接塊表讀到all_blocks，
把parent_dir_inode關閉，

把io_bu強制轉化為struct dir_entry*後，把該值賦予struct dir_entry* dir_e，
把cur_part->sb->dir_entry_size賦予unit32_t dir_entry_size，該值為一個目錄項的大小，
把 dir_entry_size / 512 賦予unit32_t dir_entrys_per_sec，該值為一個扇區內有多少個目錄項，

開始用兩層while迴圈尋找硬碟內有沒有inode編號為c_inode_nr的目錄項，
外while迴圈尋找不為0的all_blocks[X]不為0的，然後進內while迴圈尋找all_blocks[X]指的塊內inode號為c_inode_nr的目錄項，
若找到的話，把"/"和"子目錄的名字"接入path內，回傳0，
若都沒找到，回傳-1。


---------------------------------------------------------------------------------------------------------------------
=====>sys_getcwd函數目的是將目前工作的絕對路徑傳入char* buf，例如現在是在c目錄下工作，則進入函數後，回傳的buf要被填入/a/b/c，
char* buf和unit32_t size(傳進來的buf的大小)<=====

先檢查傳進來的buf是否為NULL，
然後用sys_malloc申請一個扇區大小的記憶體，把記憶體的地址賦予void* io_buf，若申請失敗則回傳NULL，

藉由running_thread函數把目前執行緒的基底位址給int32_t cur_thread，
把parent_inode_nr初始值先設為0，
把cur_thread->cwd_inode_nr(目前工作的目錄的inode編號)賦予int32_t child_inode_nr，
檢查child_inode_nr是不是在inode的編號範圍內(0~4095)

若child_inode_nr為0，表示目前的工作路徑是根目錄，直接把"/0"填入buf並回傳，

用memset把buf內全歸0，
設置char full_path_reverse[MAX_PATH_LEN]，將來要放入"反轉的路徑"，
因為絕對路徑是由下往上構建的，所以填入full_path_reverse內的會是"反轉的路徑"，如填入"/c/b/a"，將來要反轉並填入buf內，

進入while迴圈，開始由下往上構建絕對路徑，
	先進入get_parent_dir_inode_nr函數內，傳入child_inode_nr(最先被賦予cur_thread->cwd_inode_nr)，
	會回傳父目錄的inode編號，把該編號賦予parent_inode_nr，
	
	進入get_child_dir_name函數，傳入剛剛獲得的parent_inode_nr，
	因為parent_inode_nr是藉由child_inode_nr傳進get_parent_dir_inode_nr函數內得到的，
	所以正常情況下一定能在inode編號為parent_inode_nr的目錄內找到inode編號為child_inode_nr的子目錄項，然後把子目錄的名字接入full_path_reverse內，
	若找不到，get_child_dir_name函數會回傳-1，接著sys_getcwd函數回傳NULL，
	
	以上是"第一輪"的絕對路徑的構建，接著把child_inode_nr更新成parent_inode_nr，繼續下一迴圈(輪)的構建，直到child_inode_nr為0(根目錄)為止，
	
現在絕對路徑的構建已經完畢，但是是反過來的(如:/c/b/a)，該路徑目前填在full_path_reverse，
先檢查full_path_reverse有沒有超過傳進來的buf的大小，
然後開始把full_path_reverse內填的路徑反轉並接入buf內，
作法為進入while迴圈，
	先用strrchr把 /c/b/a 的 /a 析出來並賦予last_slash(型別為char*)，
	用strlen得到buf現在的長度，
	用strcpy把last_slash(目前為/c)接到buf+len之處(*也可以採用strcat?)，現在buf內的內容為 /a ，
	把*last_slash置為0，即把 /c/b/a 變成 /c/b0a，進入下一迴圈，
	
	先用strrchr把 /c/b/a 的 /b0a 析出來並賦予last_slash(型別為char*)，
	用strlen得到buf現在的長度，
	用strcpy把last_slash(目前為/b0a)接到buf+len之處(*也可以採用strcat?)，
	因為strcpy會把'0'視為要複製的字串的 終點 ，所以只會把 /b 複製到buf內，現在buf內的內容為 /a/b ，
	把*last_slash置為0，即把 /c/b0a 變成 /c0b0a，進入下一迴圈，
	
	用同樣的方式把 /c 複製到buf內，使buf內的內容為 /a/b/c ，
	
用sys_free把io_buf釋放掉，回傳buf。


---------------------------------------------------------------------------------------------------------------------
=====>sys_chdir函數目的為把running_thread()->cwd_inode_nr設為某個資料夾做為操作資料夾，
例如:傳入的path為/a/b/c，則目標是要把/c的inode_no賦予running_thread()->cwd_inode_nr，/c一定要是目錄，
chdir是change directory的縮寫<=====

設置ret，初始值為-1，
設置searched_record，用memset把searched_record內全歸0，

進入search_file函數，獲得path內的最後一個目錄的inode_no(如獲得/c的inode_no)，
檢查searched_record.file_type，若類型為 目錄 ，則把獲得的inode_no賦予running_thread()->cwd_inode_nr，把ret設為0，
若類型為 非目錄(普通檔案) ，把ret保持為-1，
若回傳的inode_no為-1，表示search_file函數內沒找到/c，把ret保持為-1，

因為有進入search_file函數，所以要用dir_close函數把searched_record.parent_dir給關掉，
回傳ret。


---------------------------------------------------------------------------------------------------------------------
=====>sys_stat函數目的為獲得檔案的各項屬性，並把各項屬性存入傳入的struct stat* buf內，
例如:傳入的path為/a/b/c，則目標是獲得/c的各項屬性<=====

設置ret，初始值為-1，
設置searched_record，用memset把searched_record內全歸0，

進入search_file函數，獲得path內的最後一個目錄的inode_no(如獲得/c的inode_no)，
用inode_open函數打開編號為inode_no的inode，把回傳的inode地址賦予struct inode* obj_inode，
把obj_inode->size賦予buf->st_size，
把編號為inode_no的inode關閉(由此可知，把inode打開的目的只是獲得檔案的大小而已)，

把searched_record.file_type賦予buf->st_filetype，此為檔案的類型
把inode_no賦予buf->st_ino，此為該檔案的所屬inode號，

把ret設為0，若search_file函數回傳-1，表示沒找到目標檔案，維持ret-1，

因為有進入search_file函數，所以要用dir_close函數把searched_record.parent_dir給關掉，

回傳ret。


##########################################################################################################################################################
/inode.c
-----inode.c內先定義struct inode_position-----

=====>inode_locate函數目的在於藉由傳入的inode_no推測該編號所屬的inode位在哪一扇區、扇區內的偏移量為何、該inode有沒有跨越扇區，
然後把這三個資訊填入struct inode_position內=====

inode_no * inode_size可以得知inode_no號的inode相對於inode_table_lba有多少位元組的偏移量，即該inode的基底位址在第幾位元組，
off_size / 512可以得知該inode的基底位址在第幾扇區，該值賦予off_sec，
off_size % 512可以得知該inode的基底位址在扇區內的偏移量(基底位址距離扇區的起始點有多少位元組)，該值賦予off_size_in_sec，
藉由512減掉off_size_in_sec的值為left_in_sec，即inode_no號的inode的基底位址距離扇區結束點還剩下多少位元組，
如果left_in_sec小於一個inode的大小，表示該inode_no號的inode有跨越扇區，需要把inode_pos->two_sec設成true，否則設成false。


---------------------------------------------------------------------------------------------------------------------
=====>inode_sync函數目的在於把某一inode寫到硬碟裡永久保存，這個動作叫做"同步"!
該動作需要先把該inode所在的扇區ide_read出來，把inode填進去後，再把inode所在的扇區ide_write到硬碟，
所以需要藉由inode_locate函數得知該inode所在的扇區(知道要ide_read哪個扇區)、
得知該inode在扇區內的偏移量(知道要把inode填到ide_read出來扇區的哪裡)、
得知該inode有沒有跨越扇區(知道是否要ide_read兩個扇區)，
以上三個資訊都會藉由inode_locate函數把資訊記錄到struct inode_position內<=====

藉由inode_locate函數得知欲同步到硬碟的inode的所在扇區號、扇區內偏移量、是否跨越扇區，
由於inode->inode_tag、inode->i_open_cnts、inode->write_deny的用途為 在記憶體內做記錄，
同步回硬碟時三者都應該要為初始值，但現在有 不想傷害到inode在記憶體內已經作的 記錄，
唯一的方法就是再struct inode pure_inode，然後用memcpy把inode的內容"複製"過去，只要把"複製品"作修改並同步到硬碟，就不會傷到"inode本尊"了，
所以現在把struct inode pure_inode內的pure_inode.i_open_cnts歸0、pure_inode.write_deny重置為false、pure_inode.inode_tag.prev和pure_inode.inode_tag.next重置為NULL，

接著準備把"複製的"inode同步到硬碟，
把inode所在的扇區(struct inode_position內的sec_lba)ide_read出來，如果inode跨扇區(藉由struct inode_position內的two_sec判斷)要讀兩個扇區，
然後把"複製的"inode用memcpy填入扇區內該inode所屬的位置，即填在扇區內偏移量處(struct inode_position內的off_size)，
最後把inode所在的扇區ide_write回去，如果inode跨扇區要寫回兩個扇區。


---------------------------------------------------------------------------------------------------------------------
=====>inode_open函數目的在打開某個inode<=====

先在struct partition內的struct list open_inodes之鏈結串列尋找inode_no號的inode，
	==>如果找到，則struct inode內的uint32_t i_open_cnts加1，
	==>如果找不到，則要先sys_malloc一個記憶體，然後把該inode從硬碟上讀到被sys_malloc的記憶體內，
	接著還要把inode.inode_tag加入struct partition內的struct list open_inodes之鏈結串列上，並使struct inode內的uint32_t i_open_cnts等於1，
	inode_open函數最後還要回傳該inode被sys_malloc的位址。

###需要注意:
###	由於記憶體內的inode要能被核心和記憶體共用，所以要sys_malloc"核心"物理記憶體池內的記憶體，
###	使用者可以透過系統呼叫進入核心態使用該inode。

可以理解為:
把inode讀到RAM內的動作叫"open"，如果已經被open，則不用重複再open，直接把open次數(uint32_t i_open_cnts)加1，
更詳細的分析請看筆記照相。


---------------------------------------------------------------------------------------------------------------------
=====>inode_close函數目的在關閉某個inode，為inode_open函數的反向<=====

先把struct inode內的uint32_t i_open_cnts減1，
	==>如果減為0，則把inode.inode_tag從struct partition內的struct list open_inodes之鏈結串列上list_remove掉，
	然後再sys_free該inode被分配的記憶體。
	
###需要注意:
###	由於記憶體內的inode要能被核心和記憶體共用，所以要sys_free"核心"物理記憶體池內的記憶體，
###
### inode_close函數內的動作要進入到PV區，因為假如i_open_cnts現在只剩下1，
###	如果這時進入inode_close函數後的一剎那突然因為時間到被換走，
###	下一棒也進入inode_close函數，--inode->i_open_cnts後變成0，
###	這樣交棒回來後也--inode->i_open_cnts，這樣會把i_open_cnts減成負的，
###	所以inode_close函數內的動作要進入到PV區。

可以理解為:
把inode從RAM移除的動作叫"close"，如果被open N次，則要重複關閉N次才算是"真"移除。


---------------------------------------------------------------------------------------------------------------------
=====>inode_delete函數目的在於把某一inode從硬碟清除，為inode_sync函數的反向，
該動作需要先把該inode所在的扇區ide_read出來，用memset把inode所在的位置清0後，再把inode所在的扇區ide_write到硬碟，
所以需要藉由inode_locate函數得知該inode所在的扇區(知道要ide_read哪個扇區)、
得知該inode在扇區內的偏移量(知道要把inode填到ide_read出來扇區的哪裡)、
得知該inode有沒有跨越扇區(知道是否要ide_read兩個扇區)，
以上三個資訊都會藉由inode_locate函數把資訊記錄到struct inode_position內<=====

藉由inode_locate函數得知欲同步到硬碟的inode的所在扇區號、扇區內偏移量、是否跨越扇區，

###需要注意:
###	在inode_sync函數有一個步驟:
###
###	---由於inode->inode_tag、inode->i_open_cnts、inode->write_deny的用途為 在記憶體內做記錄，
###	---同步回硬碟時三者都應該要為初始值，但現在有 不想傷害到inode在記憶體內已經作的 記錄，
###	---唯一的方法就是再struct inode pure_inode，然後用memcpy把inode的內容"複製"過去，只要把"複製品"作修改並同步到硬碟，就不會傷到"inode本尊"了。
###
###	然而，因為現在都要delete了，
###	inode_delete函數會直接用memset把inode整個清0，即記憶體內的inode都整個清0了，也不需要特別去保存記憶體內inode的數值，
###	所以在inode_delete函數內會去掉以上步驟!

現在直接用memset把inode整個清0，
然後把inode所在的扇區ide_write回去，如果inode跨扇區要寫回兩個扇區。


---------------------------------------------------------------------------------------------------------------------
=====>inode_release函數目的在把inode->sector所指的所有塊(包含 直接塊 和 間接塊)都清0，
在file_write函數內寫資料時，會為要寫的資料分配新的扇區，現在準備要刪除檔案，也就是檔案內所有的內容都要清掉<=====

只有在正要操作檔案的狀態下，才會進入file_open函數內 藉由inode_open函數 把inode掛到file_table上，
也就是說現在要關閉某inode，該inode不一定會被掛到file_table上，
所以要關閉的inode，就要把inode打開，先進inode_open函數，打開inode一次，

把直接塊的扇區號填入all_blocks內，如果有間接塊，也要把間接塊號填入all_blocks內，
把間接塊表所在的扇區的block_bitmap的位用bitmap_set設為0，然後用bitmap_sync函數同步，

接著進入while迴圈，把all_blocks內所有的扇區號對應的塊用bitmap_set設為0，然後用bitmap_sync函數同步，

由於inode.i_sectors內所對應的塊全部都清0了，所以在此乾脆把inode整個清掉，
把該inode對應到的inode_bitmap的位用bitmap_set設為0，然後用bitmap_sync函數同步，
接著進入inode_delete函數，把硬碟裡的該inode清除
(該動作其實沒有必要，因為只要把inode對應到的inode_bitmap的為設為0，就可以視為把該inode從硬碟上清除了)，

最後進入inode_close函數，把該inode關閉一次。


##########################################################################################################################################################
/file.c
---------------------------------------------------------------------------------------------------------------------
=====>get_free_slot_in_global函數目的在尋找一個可用的檔案"編號"，
0~2號分別是標準輸入、標準輸出、標準錯誤，所以從第3號開始找<=====


---------------------------------------------------------------------------------------------------------------------
=====>pcb_fd_install函數目的在於在 struct thread 內找到一個空閒的fd_table(fd_table[X]=-1)，然後把檔案"編號"賦予fd_table[X]，回傳X值<=====


---------------------------------------------------------------------------------------------------------------------
=====>inode_bitmap_alloc目的在從inode點陣圖找一個空閒位，把該點陣圖的空閒位置1後，回傳該位對應到的扇區的扇區號<=====


---------------------------------------------------------------------------------------------------------------------
=====>block_bitmap_alloc目的在從塊點陣圖找一個空閒位，把該點陣圖的空閒位置1後，回傳該位對應到的扇區的扇區號<=====


---------------------------------------------------------------------------------------------------------------------
=====>bitmap_sync函數目的在於把記憶體(掛在struct partition內，有塊bitmap和inode bitmap兩種)上的bitmap同步到硬碟上，
如果因為新增或刪除了要使用的塊或inode導致bitmap內容有所改變，這個改變要永久存放在硬碟裡，
方式為把bitmap中第bit_idx位元所在的扇區整個ide_write到硬碟上<=====

bit_idx / 4096為該位元(bit_idx)所在的扇區偏移量，該值為off_sec，
該值加上硬碟內的bitmap基底扇區號 會等於 要ide_write進去的扇區號，
會在switch判斷是要同步 塊點陣圖 還是 inode點陣圖 決定 "硬碟內的" bitmap基底"扇區號" 要用 part->sb->inode_bitmap_lba 還是 part->sb->block_bitmap_lba

off_sec * BLOCK_SIZE為該位元所在的 扇區的"基底位置"的 偏移量 為多少"位元組"，
該值加上硬碟內的bitmap基底位址 可以得知 要從bitmap內的哪一位元組開始ide_wrie "一個扇區大小" 到硬碟裡，
會在switch判斷是要同步 塊點陣圖 還是 inode點陣圖 決定 "記憶內的" bitmap基底"位址(單位為byte)" 要用 part->sb->block_bitmap_bits還是part->sb->inode_bitmap_bits，

最後ide_write bit_idx位元所在的整個扇區到硬碟上。


---------------------------------------------------------------------------------------------------------------------
=====>file_create函數目的為建立檔案，回想平常用電腦時在電腦裡建立一個記事本的過程，可以得知需要以下步驟:
1.建立檔案，要有屬於它的inode，對其按右鍵點內容可以看到其對檔案的描述內容，
  所以要新增一個inode，這導致inode_bitmap被更新，inode_bitmap的改變要同步到硬碟上，且新增的inode也要寫入硬碟永久保存，
2.新建立的檔案必放在資料夾內的某一處，點開資料夾就會看到它，
  所以父目錄(資料夾)的inode->i_sectors所指的塊內要多一個dir_entry，這會導致父目錄(資料夾)inode->i_size會增加一個dir_entry的大小，
3.如果2.沒有任何一個塊有空間可以放新的dir_entry，需要申請一個新的block，
  這導致block_bitmap需要被更新(這更新的操作會在sync_dir_entry函數內完成，不需要在filr_creat函數內做)，
  且新的block的扇區號要填入inode->i_sectors[X]中，2.和3.的操作導致父目錄的inode被改變
4.以上操作如果某步發生失敗，需要回復以前已成功的操作
5.inode_bitmap、block_bitmap、父目錄的inode以及新增檔案的inode要同步到硬碟
<=====

先用sys_malloc申請一個公用buffer，名字為io_buf，大小為1024位元組，因為inode可能有跨越扇區的情況，要讀取兩個扇區，

根據1.，進入inode_bitmap_alloc函數內為inode分配一個inode，其函數內會把inode_bitmap對應到的位置1，然後回傳inode_no，
接著用sys_malloc一個inode大小的記憶體(這記憶體是inode掛到RAM內會用到的，因為現在是創新的inode，可視為"另類的"開啟inode)，如果失敗要回退，

因為inode是新創的，所以要初始化，進入到inode_init內，把inode的最初數值都填進去，

進入get_free_slot_in_global函數內獲得新檔案的"編號"，該值賦予fd_idx，失敗要回退，

根據2.，父目錄(資料夾)的inode->i_sectors所指的塊內要多一個dir_entry，
所以先struct dir_entry new_dir_entry，然後進入creat_dir_entry函數，初始化new_dir_entry，
然後進入sync_dir_entry函數，在父目錄(parent_dir)內的 inode(父目錄本身的inode，不是新創的)內的 i_sectors[X]所指向的塊內 找一個可以放new_dir_entry的位置，
如果失敗，會回傳false，然後要回退，

根據3.，父目錄的inode有被改變，所以要進入inode_sync函數更新父目錄的inode，
根據1.，新增的inode也要寫入硬碟永久保存，所以要進入inode_sync函數ide_write新檔案的inode，
根據1.，因為新增一個inode，所以導致inode_bitmap被更新，要同步到硬碟上，因此進入bitmap_sync函數更新inode_bitmap，

由於為新檔案新增一個新的inode，這是"另類的"開啟新檔案的inode，所以要把new_file_inode->inode_tag放入cur_part->open_inodes上，
並且把new_file_inode->i_open_cnts等於1，

至此公用buffer用罄，所以sys_free(io_buf)，

進入pcb_fd_install函數，在當前執行緒內內找到一個空閒的fd_table(fd_table[X]=-1)，然後把檔案"編號"賦予fd_table[X]，回傳X值，
回到file_create函數後返回X值，

如果以上某一步失敗，則goto rollback的地方，回退上一步後，sys_free(io_buf)，並返回-1。


---------------------------------------------------------------------------------------------------------------------
=====>file_open函數目的為開啟inode_no對應的檔案，基本構造跟dir_open函數類似<=====

先用get_free_slot_in_global獲得檔案的"編號"，

然後把被傳進來的inode_no號的inode掛到file_table[X].fd_inode上，並把file_table[fd_idx].fd_pos置0，此兩個步驟與dir_open函數相同，

接著file_table[X].fd_flag = flag，flag為傳入的參數，表示開啟該檔案的"目的"，是要 讀 還是要 讀與寫 等等，

如果現在的目的有 寫 的成分(O_WRONLY或O_RDWR)，要先判斷write_deny是不是 不允許寫入，
	==>如果不是 不允許寫入，即!(*write_deny)，則把*write_deny置為true，
	上述操作要關中斷，因為假如程式通過if(!(*write_deny))的檢查後的一剎那，突然目前的執行緒(A)因為時間到而被交棒出去，
	如果下一執行緒(B)也要開啟相同的檔案，則會通過if(!(*write_deny))之檢查，並把*write_deny置為true表示占用，
	此時若交棒回A，A因為已經通過if(!(*write_deny))之檢查了，會以為目前沒人占用欲開啟的檔案，這樣就不對，
	所以上述操作要關中斷，
	接著進入pcb_fd_install函數，
	接著進入pcb_fd_install函數，在當前執行緒內找到一個空閒的fd_table(fd_table[X]=-1)，然後把檔案"編號"賦予fd_table[X]，回傳X值
	==>如果是 不允許寫入，要回傳-1。


---------------------------------------------------------------------------------------------------------------------
=====>file_write函數目的為把const void* buf中的unit32_t count個位元組的檔案寫入struct file* file中，
方式為藉由 file->fd_inode->i_size 計算出file內已寫入的資料佔用了多少扇區(a，從1開始算)，
然後藉由 file->fd_inode->i_size+count 計算寫入新資料後的 總"資料" 佔用了多少扇區(b，從1開始算)，
有沒有超出 剛讀出的扇區的剩餘沒寫的部分，
如果(b)-(a)大於0，表示將來把新資料寫進硬碟後會超出 原本已寫入的資料的 所在的扇區的 剩餘的還沒被寫的部分，
而(b)-(a)表示還要再分配多少扇區才有辦法把要寫的資料裝進去，分配扇區需要考慮有無間接塊的狀況，
為了簡化處理方式，如果將來寫入資料不會動用到間接塊，只要將 "要寫入新資料的扇區(會接觸到的扇區)" 的扇區號 填入all_blocks即可，即填會造成影響的塊的扇區號到all_blocks，
如果將來寫入資料會動用到間接塊，那 間接塊的部分 要直接ide_read間接塊表到all_blocks+12，因為ide_read一次一定要讀1個扇區的大小，故直接讀全部的間接塊扇區號進來，
扇區分配完畢後開始寫入資料，分多次寫入，
從file內原本已寫入的 "資料尾" 開始，每次寫入不超過一個扇區的"尾"<=====

先看看未來把新資料寫入後總資料長度(file->fd_inode->i_size + count)有沒有超過512*140=71680位元組，
然後sys_malloc一個扇區大小的記憶體，名字為io_buf
(將來會把欲寫入資料的扇區ide_read到io_buf，然後把欲寫入的資料memcpy到io_buf內，再把該io_buf ide_write回去)，

再sys_malloc給all_blocks用的記憶體，大小為扇區大小+48(有12個直接塊所在扇區號，扇區號的型別為"整數"，12*4=48位元組)，

再來定義一系列變數，包括把傳入的const void* buf強制轉換成const uint8_t* src、
已寫入的資料的大小(bytes_written)、未寫入的資料的大小(size_left，該值等於count)、
扇區內已有資料的偏移量(sec_off_bytes)、扇區內扣掉"已有資料的偏移量"後 剩下的偏移量(sec_left_bytes)、
每次寫入的資料大小(chunk_size)、間接塊表所在扇區號(indirect_block_table) 等變數，

接著用if(file->fd_inode->i_sectors[0])判斷file判斷現在對file是不是有史以來第一次寫入，
如果是，表示有 "大小為0" 的已寫入的資料(隱形的已寫入的資料) 寫在第0個扇區 ，但該扇區連 被分配 都沒有，
需要進入block_bitmap_alloc函數特別為 "大小為0的"已寫入的資料(隱形的已寫入的資料) 分配一個扇區，
再把被分配的扇區號賦予file->fd_inode->i_sectors[0]，然後進入bitmap_sync函數同步block_bitmap

計算出file內已寫入的 "資料尾(包含最後 大小為0 的隱形資料)" 在第幾號扇區，方式為file->fd_inode->i_size / BLOCK_SIZE，
該值為從0算的值，該值+1後變成從1算的值，把該值賦予file_has_used_blocks，為目前檔案已經占用的扇區數(a，從1開始算)，

計算出file內寫入新資料後的 總"資料尾(包含最後 大小為0 的隱形資料)" 在第幾號扇區，方式為(file->fd_inode->i_size+count) / BLOCK_SIZE，
該值為從0算的值，該值+1後變成從1算的值，把該值賦予file_will_use_blocks，為寫入新資料後的 總"資料" 佔用了多少扇區數(b，從1開始算)，

###需要注意:
###	因為每個檔案內資料都有尾端的"0位元組大小(隱形)的資料尾"，等於多了1位元組，
###	所以不能用file->fd_pos / BLOCK_SIZE算資料尾(包含最後 大小為0 的隱形資料)" 在第幾號扇區，
###	而用file->fd_inode->i_size / BLOCK_SIZE算資料尾。

	==>如果(b)-(a)等於0，表示將來把新資料寫進硬碟後 "不會" 超出 原本已寫入的資料的 所在的扇區的 剩餘的還沒被寫的部分，
		
		===>如果已寫入的扇區 所在的扇區是直接塊，
		那直接把 file->fd_inode->i_sectors[file_has_used_blocks-1] 賦予 all_blocks[file_has_used_blocks-1] ，
		即把會造成影響的塊的扇區號到all_blocks，由於 將來把新資料寫進硬碟後 "不會" 超出 原本已寫入的資料的 所在的扇區的 剩餘的還沒被寫的部分，
		所以只要填入 原本已寫入的 資料"尾" 所在的扇區號就夠了，
		===>如果已寫入的扇區 所在的扇區是間接塊，那要直接ide_read間接塊表到all_blocks+12，
		因為ide_read一次一定要讀1個扇區的大小，故直接讀全部的間接塊扇區號進來，這所有的間接塊扇區號中一定包含 原本已寫入的 資料"尾" 所在的扇區號，
	
	==>如果(b)-(a)大於0，表示將來把新資料寫進硬碟後 "會" 超出 原本已寫入的資料的 所在的扇區的 剩餘的還沒被寫的部分，分成三種情況
		
		==>第一種，如果 原本已寫入的資料 皆只在 直接塊 的範圍內，且寫入新資料後，"總"資料 "不會" 涉及到間接塊，
		先做 與(b)-(a)等於0時 相同的事情 ，即把 原本已寫入的 資料"尾" 所在的扇區號 先填入all_blocks，
		然後進入while迴圈，為 超出原本已填入資料所在的扇區 的欲填入資料 一一分配扇區，
		作法一樣是進入block_bitmap_alloc函數，然後把回傳的扇區號填入all_blocks[X]及file->fd_inode->i_sectors[X]，再進入bitmap_sync函數進行同步，
		
		==>第二種，如果 原本已寫入的資料 皆只在 直接塊 的範圍內，但寫入新資料後，"總"資料 "會" 涉及到間接塊，
		先做 與(b)-(a)等於0時 相同的事情 ，即把 原本已寫入的 資料"尾" 所在的扇區號 先填入all_blocks，
		然後比第一種情況多做一件事情:為間接塊表分配一個塊，
		做法一樣是進入block_bitmap_alloc函數，然後把回傳的扇區號填入 indirect_block_table 及 file->fd_inode->i_sectors[12] ，
		再進入bitmap_sync函數進行同步(*不知為何書上忽略此步驟)，
		然後繼續做與第一種情況相同的事情，但要多考慮間接塊的情況，
		進入while迴圈，為 超出原本已填入資料所在的扇區 的欲填入資料 一一分配塊，
			==>如果現在分配的塊還在 直接塊 的範圍，
			作法一樣是進入block_bitmap_alloc函數，然後把回傳的扇區號填入all_blocks[X]及file->fd_inode->i_sectors[X]，再進入bitmap_sync函數進行同步，
			==>如果現在分配的塊進入到了 間接塊 的範圍，
			作法還是一樣是進入block_bitmap_alloc函數，但只要把回傳的扇區號填入all_blocks[X]，再進入bitmap_sync函數進行同步，
		離開迴圈後，把all_blocks+12開始的512位元組
		(扇區號用"整數形別"儲存，所以140-12=128個間皆塊的扇區號佔用了128*4=512位元組)
		一口氣ide_write到硬碟的indirect_block_table之扇區(間接塊表所在扇區)，
		該行為與 第一種情況的 把扇區號填入file->fd_inode->i_sectors[X] 之行為 相互對應，
		
		==>第三種，如果 原本已寫入的資料一開始就涉及到 間接塊 的範圍，
		先做 與(b)-(a)等於0時 相同的事情 ，即把 原本已寫入的 資料"尾" 所在的扇區號 先填入all_blocks，
		該扇區號目前填在硬碟上的間接塊表內，需要藉由ide_read獲得，但由於ide_read一次一定要讀取 "一整個扇區" ，
		所以直接把間接塊表(位置寫在file->fd_inode->i_sectors[12])一口氣ide_read到all_blocks+12內，此時all_blocks[12~140]內一定包含 原本已寫入的 資料"尾" 所在的扇區號 ，
		接下來進入while迴圈，直接做 第二種的 "如果現在分配的塊進入到了 間接塊 的範圍" 之一樣的事情，
		進入block_bitmap_alloc函數，但只要把回傳的扇區號填入all_blocks[X]，再進入bitmap_sync函數進行同步，
		離開迴圈後，做 第二種 一樣的事情 ，把all_blocks+12開始的512位元組
		(扇區號用"整數形別"儲存，所以140-12=128個間皆塊的扇區號佔用了128*4=512位元組)
		一口氣ide_write到硬碟的indirect_block_table之扇區(間接塊表所在扇區)，
		該行為與 第一種情況的 把扇區號填入file->fd_inode->i_sectors[X] 之行為 相互對應，
	
##EX:
##	假如 已寫入的資料 有511個位元組，file->fd_inode->i_size / BLOCK_SIZE = 511 / 512 = 0，
##	已寫入的 資料尾 在第0個扇區，0+1=1變成從1開始算的值，把該值賦予file_has_used_blocks(a)，
##
##	而如果把新資料寫進去後 總共會有512個位元組，(file->fd_inode->i_size+count) / BLOCK_SIZE = 512 / 512 = 1，
##	所以寫入新資料後 總資料的 資料尾 會在第1個扇區(所謂的 "資料尾" 包含最後 大小為0 的隱形資料)，
##	1+1=2變成從開始1算的值，把該值賦予file_will_use_blocks(b)，
##
##	(b)-(a)=1，表示會為寫完新資料的 總資料尾(包含最後 大小為0 的隱形資料)分配一個扇區，
##	此動作與 
##	"用if(file->fd_inode->i_sectors[0])判斷現在對file是不是有史以來第一次寫入，
##	是的話先特別為 大小為0的 已寫入的資料(隱形的已寫入的資料) 分配一個扇區"
##	相對應，
##
##	因為每個檔案內資料都有尾端的"0位元組大小(隱形)的資料尾"，等於多了1位元組，
##	所以不能用file->fd_pos / BLOCK_SIZE算資料尾(包含最後 大小為0 的隱形資料)" 在第幾號扇區，
##	而用file->fd_inode->i_size / BLOCK_SIZE算資料尾。
	
至此，所有欲寫入資料所需要的塊皆分配完成，下面開始正式寫入資料，

把first_write_block先置為true，
把file->fd_pos 設為 file->fd_inode->i_size - 1，此為 "正在操作"的位置 在檔案內的 偏移量，

然後進入while迴圈，

file->fd_inode->i_size / BLOCK_SIZE 為 現在要寫入的為第幾個扇區
(從0開始算，包含有尾端的"0位元組大小(隱形)的資料尾"，所以不用file->fd_pos / BLOCK_SIZE去算)，該值賦予sec_idx，
把all_blocks[sec_idx]賦予sec_lba，為現在要寫入的扇區號，
file->fd_inode->i_size % BLOCK_SIZE，為現在要寫入的 開始位置 在扇區內的哪裡，該值賦予sec_off_bytes，
BLOCK_SIZE-sec_off_bytes賦予sec_left_bytes，為 現在要寫的扇區內 還剩下多少位元組可以寫，

現在判斷 準備要寫入的資料大小為何(chunk_size)，每次寫入的資料不能超過 要寫入的扇區尾，
如果size_left<sec_left_bytes，表示目前所有剩餘的要寫的資料量 不會 超過 要寫入的扇區尾 ，chunk_size為size_left，
否則 目前所有剩餘的要寫的資料量 會 超過 要寫入的扇區尾 ，chunk_size只能為sec_left_bytes，

	==>如果現在 first_write_block=true ，表示目前是 "第一批" 寫入新資料，新資料要接在已寫入資料(舊資料)的尾端，
	ide_read目前要寫入的扇區到io_buf，然後把first_write_block置為false，
	==>如果現在 first_write_block=false，表示目前不是 "第一批" 寫入新資料，
	不需要為了 要寫入資料的扇區內的 0位元組(隱形的)的已寫入資料 特別ide_read扇區出來，
	所以可以省略 ide_read目前要寫入的扇區到io_buf 之步驟，

用memcpy把chunk_size大小的資料從src複製到io_buf+sec_off_bytes，進行寫入資料的動作，再把目前寫入的扇區ide_write回去，

現在這一批資料寫入完成，進入下一迴圈前要更新一些參數，
把src(傳入的const void* buf會強制轉換成const uint8_t* src)加上chunk_size，即設置src內下一次要開始寫到io_buf + sec_off的位置，
把file->fd_inode->i_size加上剛寫進去的資料大小，即加上chunk_size，
把file->fd_pos也加上剛寫進去的資料大小(chunk_size)，即設置下一次的 "操作"的位置 在檔案內的 偏移量，
把bytes_written也加上剛寫進去的資料大小，即加上chunk_size，
剩餘的待寫資料大小(size_left)減掉剛寫進去的資料大小(chunk_size)，

現在離開while迴圈了，因為file->fd_inode->i_size有更新，所以要進入inode_sync函數把file->fd_inode同步過去，

釋放all_blocks和io_buf，

最後回傳已寫的資料大小(bytes_written)。
	
	
---------------------------------------------------------------------------------------------------------------------
=====>file_read函數目的為從struct file* file把unit32_t count個位元組的檔案寫入const void* buf，為file_write函數的反向，
由於要讀取檔案 "已經寫在"硬碟內了 ，不需要再做分配扇區的動作，因此程式量相較於file_write函數少了大約一半，
再進入file_read函數前，file->fd_pos會被設定在要讀的起始位置<=====

先定義一系列變數，包括把傳入的void* buf強制轉換成uint8_t* buf_dst、
把count賦予size、把size賦予size_left、

(file_write函數是把這步驟挪到sys_malloc io_buf和all_blocks之後做)，

接著檢查要讀取的資料大小是否超過已寫入的資料大小，

然後sys_malloc一個扇區大小的記憶體，名字為io_buf
(將來會把欲寫入資料的扇區ide_read到io_buf，然後把欲寫入的資料memcpy到io_buf內，再把該io_buf ide_write回去)，

再sys_malloc給all_blocks用的記憶體，大小為扇區大小+48(有12個直接塊所在扇區號，扇區號的型別為"整數"，12*4=48位元組)，

~~~~~接著跳過file_write函數分配扇區的部分~~~~~

計算要讀取的資料 開始位置 在第幾號扇區，方式為file->fd_pos / BLOCK_SIZE
(由於file_read不用特別為 "0位元組的資料尾" 分配一個扇區，所以不考慮資料尾的狀況，可以直接用file->fd_pos / BLOCK_SIZE)，
該值為從0算的值，把該值賦予block_read_start_start_idx(a)，

計算要讀取的資料 結束位置 在第幾號扇區，方式為(file->fd_pos+size) / BLOCK_SIZE
(由於file_read不用特別為 "0位元組的資料尾" 分配一個扇區，所以不考慮資料尾的狀況，可以直接用(file->fd_pos+size) / BLOCK_SIZE)，
該值為從0算的值，把該值賦予block_read_start_end_idx(b)，

~~~~~由於讀取扇區需要從all_blocks獲得扇區號，這步驟在file_write函數內是緊接續在分配完扇區之後，
所以file_read函數要特別補做把
"要讀取的直接塊扇區號(會接觸的直接塊扇區號) 填入all_blocks、把間接塊表ide_read到all_blocks+12(ide_read一次最少只能讀一整個扇區)"
之步驟~~~~~

(*書上多了藉由(b)-(a)是否等於0區分只讀一個扇區還是要讀入多扇區，
但應該沒有必要，因為file_write函數內會特別做這樣的區分是要特別為 "超出最開始的 扇區"尾" 的資料" 做扇區分配，
而file_read函數 要讀的最開始的扇區 與 接下來要讀的扇區 沒什麼不同，不會特別去分配心扇區，
所以不用特別去做 (b)-(a) 之區分，也就是 if(add_blocks == 0) 這一部分的code可以不寫，直接寫else部分的code就可以了)

	===>第一種情況，如果 要讀的起始扇區(block_read_start_start_idx) 與 要讀的最後一個扇區(block_read_start_end_idx) 皆為直接塊，
	直接進while迴圈把要用的直接塊扇區號填入all_blocks，
	===>第二種情況，如果 要讀的起始扇區(block_read_start_start_idx)為直接塊，而要讀的最後一個扇區(block_read_start_end_idx)為間接塊，
	表示要讀取的資料跨越直接塊和間接塊，
	先進while迴圈把要用的直接塊扇區號填入all_blocks，
	然後ide_read整個間接塊表到all_blocks+12(ide_read一次最少只能讀一整個扇區)，
	===>第三種情況，如果 要讀的起始扇區(block_read_start_start_idx) 與 要讀的最後一個扇區(block_read_start_end_idx) 皆為間接塊，
	直接ide_read整個間接塊表到all_blocks+12(ide_read一次最少只能讀一整個扇區)，

至此，所有欲讀取資料所需要的扇區號皆填到了all_blocks，下面開始正式讀取資料，

然後進入while迴圈，

file->fd_pos / BLOCK_SIZE 為 現在要讀的起始位置在第幾個扇區
(由於file_read不用特別為 "0位元組的資料尾" 分配一個扇區，所以不考慮資料尾的狀況，可以直接用file->fd_pos / BLOCK_SIZE)，
把all_blocks[sec_idx]賦予sec_lba，為現在要讀的起始扇區號，
file->fd_pos % BLOCK_SIZE，為現在要讀的 開始位置 在扇區內的哪裡，該值賦予sec_off_bytes，
BLOCK_SIZE-sec_off_bytes賦予sec_left_bytes，為 現在要讀的位置距離扇區尾還有多少位元組遠，

現在判斷 準備要讀取的資料大小為何(chunk_size)，每次讀取的資料不能超過 要讀取的扇區尾，
如果size_left<sec_left_bytes，表示目前所有剩餘的要讀的資料量 不會 超過 要讀取的扇區尾 ，chunk_size為size_left，
否則 目前所有剩餘的要讀的資料量 會 超過 要讀取的扇區尾 ，chunk_size只能為sec_left_bytes，

~~~~~因為file_read永遠都是 讀 的動作，所以不用特別考慮first_write_block是否等於true的狀況，即不用考慮目前是不是 "第一批" 寫入新資料~~~~~

把目前要讀的扇區ide_read出來，

用memcpy把chunk_size大小的資料從io_buf+sec_off_bytes複製到buf_dst，進行讀取資料的動作，

現在這一批資料讀取完成，進入下一迴圈前要更新一些參數，
把buf_dst(傳入的void* buf會強制轉換成uint8_t* buf_dst)加上chunk_size，即設置buf_dst內下一次要開始寫到io_buf + sec_off的位置，
(因為只是讀取資料，所以不改變file->fd_inode->i_size)，
把file->fd_pos也加上剛才讀取的資料大小(chunk_size)，即設置下一次的 "操作"的位置 在檔案內的 偏移量，
把bytes_read也加上剛才讀取的資料大小，即加上chunk_size，
剩餘的待寫資料大小(size_left)減掉剛才讀取的資料大小(chunk_size)，

現在離開while迴圈了，因為file->fd_inode->i_size有更新，所以要進入inode_sync函數把file->fd_inode同步過去，

釋放all_blocks和io_buf，

最後回傳已讀的資料大小(bytes_read)。


---------------------------------------------------------------------------------------------------------------------
=====>file_close函數的目的為關閉檔案，基本構造跟dir_close函數類似<=====
先把file->fd_inode->write_deny = false，解除占用，讓其他執行緒也可以用此檔案，


先inode_close，與dir_close函數相同，
接著file->fd_inode=NULL，該步驟類似dir_close的free(dir)，
&file_table[X]傳入file_close函數內會轉化成file，把file_table[X]的fd_inode置為NULL，可當作是"釋放掉"file->fd_inode上的記錄。


##########################################################################################################################################################
/dir.c
---------------------------------------------------------------------------------------------------------------------
=====>open_root_dir函數的目的在於把根目錄被分配到的inode掛到struct dir root_dir的root_dir.inode上，並把uint32_t dir_pos置0，
由於struct dir root_dir是定義在dir.c的全域變數，所以不用再特別回傳struct dir root_dir<=====


---------------------------------------------------------------------------------------------------------------------
=====>dir_open函數的目的在於把被傳進來的inode_no號的inode掛到struct dir *pdir的pdir->inode上，並把uint32_t dir_pos置0，
由於struct dir *pdir為在dir_open函數內被sys_malloc後的記憶體位址，所以要回傳struct dir *pdir<=====


---------------------------------------------------------------------------------------------------------------------
=====>search_dir_entry函數的詳解請看筆記照相!!!<=====


---------------------------------------------------------------------------------------------------------------------
=====>dir_close函數目的在關閉一個目錄，
回想dir_open函數做的事情，先sys_malloc一個struct dir(根目錄不用sys_malloc，直接用全域的struct dir root_dir)，
然後把一個目錄所屬的inode打開，再將其被sys_malloc的地址賦予struct dir內的struct inode*，再回傳struct dir的地址，
這樣的動作可以理解成一個struct dir"被開啟了"，

因此，dir_close的動作就是dir_open的反向，
把inode關閉，然後直接用free撤掉struct dir，這樣等於是struct dir內的數值也全都消失了，
由於根目錄(root_dir)是全域變數，不能關閉，所以dir_close函數如果發現傳進來的struct dir*是&root_dir，會直接不做處理並返回<=====


---------------------------------------------------------------------------------------------------------------------
=====>creat_dir_entry函數為初始化目錄項(p_de)，要為目錄項(p_de)填入其所指向的inode號(inode_no)、所指向的檔案名稱、所指向的檔案類型<=====


---------------------------------------------------------------------------------------------------------------------
=====>sync_dir_entry函數目的在父目錄(parent_dir)內的 inode內的 i_sectors[X]所指向的塊內 找一個可以放某一目錄項(p_de)的位置，
把目錄項(p_de)ide_write該位置，成功回傳true<=====

首先要把i_sectors[X]所指向的所有塊的扇區號統整到all_blocks中，
如果i_sectors[12]不為0，表示有間接塊，要把i_sectors[12]指向的扇區號的內容從硬碟ide_read到 "all_blocks內[12]起跳" 的位置(*不知為何書上忽略此步驟)，

再struct dir_entry* dir_e = (struct dir_entry*)io_buf，
io_buf是傳進來的buffer，讓程式可以沿用上個函數的buffer，可以不必再sys_malloc一個buffer以節省空間，
但是由於io_buf是共用的buffer，不知道目前正要使用的函數要採用的buffer的單位長，所以傳進來的io_buf型別是(void*)，
把io_buf的型別強制轉換後賦予dir_e，

然後用 外while迴圈 把all_blocks從[0]到[140]開始檢查，

	==>如果all_blocks[X]不為0，表示該all_blocks[X]指向的塊有被分配，開始進入 內while迴圈 ，
	檢查all_blocks[X]指向的塊內有沒有可以給p_de的空位，方法為把all_blocks[X]指向的塊ide_read到io_buf，
	然後在io_buf內每次dir_entry_idx+1作檢查，
		==>如果發現(dir_e+die_entry_idx)->f_type等於FT_UNKNOWN
		(FT_UNKNOWN等於0，硬體最開始沒有寫入的狀態都會是0，硬體是真實結構，不像verilog那樣有不穩定態，所以剛開始一定都會是0)，
		表示已經找到可以放p_de的空位，用memcpy把p_de複製到dir_e + dir_entry_idx處，複製的大小為dir_entry_size
		(不能用io_buf + dir_entry_idx，因為io_buf的型別是void*，沒有單位長)，
		然後ide_write 放p_de的塊到all_blocks[X]所指的扇區內，
		最後把dir_inode->i_size加上一個dir_entry_size的大小，並返回true，
		==>如果該all_blocks[X]內沒有任何一個可以放p_de的位置，則會跳出 內while迴圈 ，並進入下一輪的 外while迴圈，
	
	==>如果all_blocks[X]為0，表示該all_blocks[X]指向的塊連被分配都沒有，
	--所以要進入block_bitmap_alloc函數找一個 空閒塊 並把對應到的block_bitmap的位 置1，block_bitmap_alloc函數回傳的空閒塊扇區號賦予block_lba，
	--因為block_bitmap被改變，所以要進入bitmap_sync函數把block_bitmap內數值更新到硬碟上
	--(由此可知，在一般情況下，block_bitmap_alloc和bitmap_sync應該成對出現)，
		==>如果X小於12，則把找到的 空閒塊的 扇區號(block_lba) 填入 all_blocks[X] 和 struct inode內的i_sectors[X]，		<----
		==>如果X等於12，意即目前的狀況為all_blocks[12]等於0，
		表示all_blocks[0~11]指向的塊都沒空間給p_de了，現在要去間接塊找空間，
		但是all_blocks[12]等於0，意思是現在連 間接塊表 都沒有，
		所以還要再找一個 空閒塊 ，
		--現在先把 在"--"時 進入block_bitmap_alloc函數後 回傳的空閒塊扇區號(block_lba)作為 間接塊表的塊的 扇區號 "直接"填入 struct inode內的i_sectors[12]，
		++然後再進入block_bitmap_alloc函數再找一個空閒塊，並把對應到的block_bitmap的位 置1，
		++block_bitmap_alloc函數回傳的空閒塊扇區號賦予block_lba，該block_lba變為新的block_lba，
		++並用bitmap_sync函數把block_bitmap同步到硬碟，
		這個空閒塊要作為 間接塊 ，間接塊的扇區號除了要填入all_blocks[X]內(X目前應12)，還要填入硬碟內的間接塊表內，
		因此先all_blocks[12]=block_lba，再用ide_write把 all_blocks[12~139] 填入 struct inode的i_sectors[12]所指的扇區(all_blocks[X]的型別為uint32_t)，		<----
		
		==>如果大於12，意即目前的狀況為all_blocks[12]不等於0，表示間接塊表的塊已被分配，
		因此不需要再為間接塊表alloc一個塊，但間接塊的扇區號除了要填入all_blocks[X]內(X目前應大於12)，還要填入硬碟內的間接塊表內，
		直接先all_blocks[X]=block_lba(X>12)，再用ide_write把 all_blocks[12~139] 填入 struct inode的i_sectors[12]所指的扇區(all_blocks[X]的型別為uint32_t)，		<----

用memcpy把p_de複製到dir_e + dir_entry_idx處，複製的大小為dir_entry_size
(不能用io_buf + dir_entry_idx，因為io_buf的型別是void*，沒有單位長)，
然後ide_write "放p_de的塊" 到 all_blocks[X]所指的扇區內，
最後把dir_inode->i_size加上一個dir_entry_size的大小，並返回true。


---------------------------------------------------------------------------------------------------------------------
=====>delete_dir_entry函數目的在父目錄(parent_dir)內的 inode內的 i_sectors[X]所指向的塊內 尋找編號為inode_no的目錄項(p_de)，把該目錄項從硬碟上移除，
如果該塊只剩下一個目錄項，把該目錄項移除後也要順勢把該塊給回收掉(有"."和".."的那個目錄項不用回收)，
成功回傳true，為sync_dir_entry函數的反向<=====

首先要把i_sectors[X]所指向的所有塊的扇區號統整到all_blocks中，
如果i_sectors[12]不為0，表示有間接塊，要把i_sectors[12]指向的扇區號的內容從硬碟ide_read到 "all_blocks內[12]起跳(all_blocks+12)" 的位置，

再struct dir_entry* dir_e = (struct dir_entry*)io_buf，
io_buf是傳進來的buffer，讓程式可以沿用上個函數的buffer，可以不必再sys_malloc一個buffer以節省空間，
但是由於io_buf是共用的buffer，不知道目前正要使用的函數要採用的buffer的單位長，所以傳進來的io_buf型別是(void*)，
把io_buf的型別強制轉換後賦予dir_e，

然後用 外while迴圈 把all_blocks從[0]到[140]開始檢查，
	
	先把is_dir_first_block初始化為false，每進入一次外迴圈都要初始化一次，
	
	==>如果all_blocks[X]為0，表示該all_blocks[X]指向的塊連被分配都沒有，
	因此沒有尋找的必要，直接continue到下一迴圈，

	若all_blocks[X]不為0，表示該all_blocks[X]指向的塊有被分配，開始進入 內while迴圈 ，
	檢查all_blocks[X]指向的塊內有沒有inode編號為inode_no的目錄項，方法為把all_blocks[X]指向的塊ide_read到io_buf，
	然後在io_buf內每次dir_entry_idx+1作檢查，
	
		==>如果發現(dir_e+die_entry_idx)->f_type不等於FT_UNKNOWN
		(FT_UNKNOWN等於0，硬體最開始沒有寫入的狀態都會是0，硬體是真實結構，不像verilog那樣有不穩定態，所以剛開始一定都會是0)，
			
			==>如果(dir_e+die_entry_idx)->filename是"."，
			表示這是inode->i_sectors[0]所指向的塊，即該目錄所使用的第一個塊，內含有"."和".."，
			該塊因為有兩個固定的內容，所以未來不能釋放掉，先把is_dir_first設為true，
			
			==>如果(dir_e+die_entry_idx)->filename是"."或".."以外的名字，
			表示現在掃到的是一個普通的目錄項，先把dir_entry_cnt+1，
				
				==>如果(dir_e+die_entry_idx)->i_no等於inode_no，表示找到欲移除的目錄項，
				把dir_e+dir_entry_idx賦予dir_entry_found，
				
	==>如果dir_entry_found == NULL，
	表示該塊沒有找到欲移除的目錄項，直接continue到下一迴圈，
	
	現在開始要移除目錄項，
	
		==>如果該目錄項所在的塊只剩它一個目錄項、且該塊是不含"."和".."的 非最初塊，則也要順勢把該塊也移除，
		把該塊對應到的block_bitmap的位用bitmap_set給置0，然後用bitmap_sync函數同步，
		
			==>如果block_idx小於12，則只要把dir_inode->i_sectors[block_idx]給置0即可，
			
			==>如果block_idx大於等於12，則除了要把間接塊表內對應到的block_idx置0，還要檢查間接塊表內是不是只剩它一個塊，
			先初始化indirect_blocks為0，然後進入while迴圈內，逐一檢查all_blocks[12~139]的每一個內容，
			若all_blocks[X]不等於0，則indirect_blocks+1，
			
				==>如果indirect_blocks的結果大於1，表示間接塊表內不只它一個塊，
				直接把all_blocks[X]置為0，並把all_blocks+12的部分ide_write到dir_inode->i_sectors[12]所指向的塊內，
				
				==>如果indirect_blocks的結果為1，表示間接塊表內只剩它一個塊，
				直接把間接塊表用到的塊 對應到的block_bitmap的位 用bitmap_set給置0，然後用bitmap_sync函數同步，
				並把dir_inode->i_sectors[12]給置0，
		
		==>如果該目錄項所在的塊不只有它一個目錄項時，直接用memset把該塊
		用memset把dir_e + dir_entry_idx處全部清0，大小為dir_entry_size
		(不能用io_buf + dir_entry_idx，因為io_buf的型別是void*，沒有單位長)，
		然後ide_write "放欲刪除的目錄項的塊" 到 all_blocks[X]所指的扇區內，

最後把dir_inode->i_size減掉一個dir_entry_size的大小，然後用inode_sync函數同步dir_inode
(在sync_dir_entry函數時該同步inode的步驟是留到 回file_create函數時 才做)，最後返回true，
	
若外while迴圈都沒有找到欲移除的目錄項，返回false。


---------------------------------------------------------------------------------------------------------------------
=====>sys_opendir函數目的在打開目錄，回傳被打開的struct dir*，類似於sys_open之關聯到file_open的部分，
在此函數name是完整路徑名字<=====

先檢查傳進來的路徑的最後一個字是不是'/'，此時不該為'/'(*不知此步驟為何被書上忽略)，

檢查是不是根目錄，如果是，則直接回傳&root_dir，

進入search_file函數，傳入路徑(name)和&searched_record，
因為現在是在"開啟"目錄，所以search_file函數應該要回傳欲開啟目錄的inode_no表示該目錄真的存在，
若沒找到，search_file函數會返回-1，所以sys_opendir函數也返回-1，
若有找到，但是searched_record.file_type為FT_REGULAR，表示你正要開啟的東西確實存在，但是是普通檔案，sys_opendir函數只能開啟目錄，所以回傳-1，
若有找到，且searched_record.file_type為FT_DIRECTORY，表示你正要開啟的東西確實存在，而且是目錄，直接進dir_open函數把目錄開啟，然後把回傳的struct dir*給ret，
把父目錄用dir_close關閉後，回傳ret。


---------------------------------------------------------------------------------------------------------------------
=====>dir_read函數目的在於讀取一個目錄項，為file_read函數的類似版，因為目錄不像普通檔案，目錄內的目錄項可以不按連續分配，
假如你分配第一到第三個資料夾的"圖示"給父資料夾，你現在點開父資料夾會看到三個資料夾的圖示，
若你現在把第二個資料夾刪除，第二個資料夾的圖示就會不見，造成第一個資料夾和第三個資料夾之間形成一個"空洞"，也就是形成一個不連續的現象，
解決的方法就是每次讀一個目錄項的位置時檢查該位置的(dir_e + dir_entry_idx)->f_type是不是FT_UNKNOWN，
	如果不是FT_UNKNOWN，表示現在讀的位置不是空洞，dir->dir_pos加上一個"數字"(書上採用的數字是dir_entry_size)，
	直接回傳dir_e+dir_entry_idx，
	下次再讀的時候，若cur_dir_entry_pos < dir->dir_pos，表示之前讀的目錄項已經讀過了，需要把cur_dir_entry_pos加上一個數字，
	然後dir_entry_idx+1(dir_entry_idx是從0開始的)並continue到下一迴圈，然後掃描下一個放目錄項的位置，
	直到cur_dir_entry_pos等於dir->dir_pos，表示該目錄項沒被讀過，直接回傳dir_e+dir_entry_idx，


可以這樣理解:
dir->dir_pos是已讀出的目錄項數(每次遞增是加一個數字)，cur_dir_entry_pos是目前讀到的目錄項數，
兩個數都是從0開始加，每進入dir_read函數cur_dir_entry_pos都會歸0，
假如該目錄內(資料夾內)有兩個目錄項(圖示)，dir_inode->i_size為2個目錄項的大小，現在要把這兩個目錄項讀出來，
第一次進入到dir_read函數時，dir->dir_pos為0個目錄項大小，
把cur_dir_entry_pos歸0後，開始進行掃描，
若掃描到一個目錄項，假如cur_dir_entry_pos等於dir->dir_pos(像現在cur_dir_entry_pos和dir->dir_pos就一樣為0)，
表示現在讀到的第一個目錄項還沒被讀過，可以準備回傳該目錄項，把dir->dir_pos加上一個數字後再回傳，

目前dir->dir_pos為1個目錄項的大小，

下一次再進入到dir_read函數後，把cur_dir_entry_pos歸0，開始進行掃描，
若掃描到一個目錄項，現在cur_dir_entry_pos已經小於dir->dir_pos了，
意即現在讀到的第一個目錄項已經被被讀過了，把cur_dir_entry_pos加上一個數字，然後繼續掃描，
直到再掃到一個目錄項，現在cur_dir_entry_pos已經等於dir->dir_pos了，
表示現在讀到的第二個目錄項還沒被讀過，可以準備回傳該目錄項，把dir->dir_pos加上一個數字後再回傳，

目前dir->dir_pos為2個目錄項的大小，

下一次再進入到dir_read函數後，把cur_dir_entry_pos歸0，開始進行掃描，
因為現在dir->dir_pos已經等於dir_inode->i_size了，皆為2個目錄項的大小，
會被if (dir->dir_pos >= dir_inode->i_size)擋下，所以會直接回傳NULL
<=====

把dir->dir_buf的型別轉換成struct dir_entry*後 賦予 struct dir_entry* dir_e
(dir->dir_buf的大小為512位元組，定義在dir.h的struct dir內，
dir_read函數跟file_read函數不一樣的地方在於，file_read函數內會特別sys_malloc一個要ide_read要放讀進來的資料的的buffer，
而dir_read函數的buffer會先把buffer定義在dir.h的struct dir內，不用特別在dir_read函數內sys_malloc一個buffer)，

把block_idx和dir_entry_idx先置0，

把扇區號填入all_blocks中，若有間接塊，則要把間接塊表讀到all_blocks+12中，

把cur_dir_entry_pos歸0，
cur_part->sb->dir_entry_size為一個目錄項的大小，把該值賦予dir_entry_size，
SECTOR_SIZE / dir_entry_size為一個塊(扇區)內有多少個目錄項，把該值賦予dir_entrys_per_sec

進入外while迴圈，開始把扇區讀到dir_e，
	
	==>如果dir->dir_pos >= dir_inode->i_size，
	表示 已經讀出的目錄項的總大小 已經達到 目錄內所有的目錄項加起來總大小(dir_inode->i_size)，
	直接回傳NULL，
	
	==>如果all_blocks[block_idx]等於0，表示all_blocks[block_idx]沒有指向任何塊，把block_idx加1後，直接continue到下一外迴圈，
	程式運行到這邊，表示all_blocks[block_idx]不等於0，用memset把dir_e全歸0，把all_blocks[block_idx]指向的塊讀到dir_e內，

進入內while迴圈，開始掃描塊內的每個放目錄項的位置，

	==>如果(dir_e + dir_entry_idx)->f_type不等於0，即不等於FT_UNKNOWN，表示該位置存在一個目錄項，
		
		==>如果cur_dir_entry_pos小於dir->dir_pos，表示目前讀到的目錄項已經被讀過了，
		直接把dir_entrys_per_sec加上一個目錄項的大小，再dir_entry_idx加1(dir_entry_idx每掃描一個目錄項的 位置 都要加1)，
		然後continue到下一內while迴圈，
		
	程式運行到這邊，表示cur_dir_entry_pos等於dir->dir_pos，用ASSERT檢查cur_dir_entry_pos是不是真的等於dir->dir_pos，
	把dir->dir_pos加上d一個目錄項的大小後，回傳dir_e + dir_entry_idx，
			
程式運行到這邊，表示(dir_e + dir_entry_idx)->f_type等於0(為FT_UNKNOWN)，
直接dir_entry_idx加上一個目錄項大小(dir_entry_idx每掃描一個目錄項的 位置 都要加1)，繼續下一內while迴圈，
	
程式運行到這邊，表示已脫離內while迴圈，意即塊內的每個放目錄項的位置都已經掃描完，把block_idx加1後，進入下一外while迴圈，

(*這裡書上多寫了一個return NULL，好像只是添保險用的?
因為假如所有的目錄項都已經被讀出，應該會先被 if (dir->dir_pos >= dir_inode->i_size))給擋下，
程式正常情況不會運行到這裡)。


---------------------------------------------------------------------------------------------------------------------
=====>dir_is_empty函數的目的在檢查該目錄是否為空，若一個目錄為"空"，表示該目錄內只有"."和".."兩個目錄項，
所以可以藉由判斷dir_inode->i_size是否只有等於2來確定該目錄是某為空<=====


---------------------------------------------------------------------------------------------------------------------
=====>dir_remove函數的目的在刪除某個目錄，為sys_mkdir函數後半的部分的反向，類似sys_unlink函數的後半部分，
dir_remove函數相較於sys_unlink函數，少做了file_search的部分，file_search的部分會在把dir_remove函數包起來的sys_rmdir函數完成<=====

因為inode->i_sectors[0]指的塊含有"."和".."兩個目錄項，所以inode->i_sectors[0]一定不為0，
所以從inode->i_sectors[1]到inode->i_sectors[13]用ASSERT檢查是否等於0，

先用sys_malloc申請一個公用buffer，名字為io_buf，大小為1024位元組，因為inode可能有跨越扇區的情況，要讀取兩個扇區，

然後依sys_mkdir函數的 倒退順序 完成檔案的刪除步驟，sys_mkdir函數內原本順序如下:
~~~~~~~~~~~~~~~~~~~~~~~~~~~以下類似於file_create函數的部分~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
1.建立資料夾，要有屬於它的inode，對其按右鍵點內容可以看到其對資料夾的描述內容，
  所以要新增一個inode，這導致inode_bitmap被更新，inode_bitmap的改變要同步到硬碟上，且新增的inode也要寫入硬碟永久保存，
2.新建立的資料夾 必放在 父資料夾內的 某一處，點開資料夾就會看到它，
  所以父目錄(資料夾)的inode->i_sectors所指的塊內要多一個dir_entry，這會導致父目錄(資料夾)inode->i_size會增加一個dir_entry的大小，
3.如果2.沒有任何一個塊有空間可以放新的dir_entry，需要申請一個新的block，
  這導致block_bitmap需要被更新(這更新的操作會在sync_dir_entry函數內完成，不需要在filr_creat函數內做)，
  且新的block的扇區號要填入inode->i_sectors[X]中，2.和3.的操作導致父目錄的inode被改變
4.以上操作如果某步發生失敗，需要回復以前已成功的操作
5.inode_bitmap、block_bitmap、父目錄的inode以及新增的資料夾的inode要同步到硬碟

~~~~~~~~~~~~~~~~~~~~~~~~~~~以下類似於sys_open函數內涉及到file_create函數的部分~~~~~~~~~~~~~~~~~~~~~~~~~~~
6.不能創建名字相同的資料夾，例如說你要在/a/b/c內創立一個名字為d的資料夾，那把/a/b/c/d送進search_file函數內應該要找不到，

~~~~~~~~~~~~~~~~~~~~~~~~~~~以下是sys_mkdir函數特別需要多做的部分~~~~~~~~~~~~~~~~~~~~~~~~~~~
7.新目錄中要建立"."和".."兩個目錄項，分別表示 當前資料夾 和 上一頁資料夾

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

根據2.和3.，需要把父目錄內欲被刪除的 子目錄的目錄項(dir_entry) 從硬碟上移除，因此進入delete_dir_entry函數，
在其內若塊上所有的目錄項都清掉了，也要把該塊釋放掉，這會涉及到block_bitmap的改變，
block_bitmap把需要被釋放的塊對應到的位置0後，需要被更新(同步)到硬碟上，在delete_dir_entry函數內會同時完成，

根據1.需要把欲刪除目錄的inode給釋放掉，但當初sys_mkdir的時候還沒有用sync_dir_entry把 目錄項 填入 目錄 內，
現在要刪除目錄，目錄內可能已經包含 存放的目錄項，
所以要進入inode_release函數把 存放目錄項的 塊全部清掉，

	inode_release函數內 會把 存放寫入內容的 塊 對應到的block_bitmap的位 置0，
	也會順便直接把inode對應到的inode_bitmap的位給置0，並同步到硬碟上，所以回到dir_remove函數後就不用再做了，
	
回到dir_remove函數後，至此公用buffer用罄，所以sys_free(io_buf)，回傳0。


-----------------------------------------------------------------------------------------------------------------------------------------------
第十五章

新增fork、shell、使用者程序載入、wait和exit、管線


<fork統整>

/thread.c
在thread_init函數內先創建init程序，

/main.c
系統呼叫fork，進入sys_fork函數，

/fork.c
	sys_fork函數內，藉由running_thread函數獲得當前執行緒，把當前執行緒基底位址賦予parent_thread，
	進入get_kernel_pages函數，傳入的參數為1，即從核心的物理內存池申請1個分頁，
	獲得新分頁的虛擬位址，把該位址賦予child_thread，由此可見，新分頁的虛擬位址會拿來作為子程序的thread，
	若失敗，sys_fork函數回傳-1，
	
	進入intr_get_status函數(定義在interrupt.c內)，獲得目前的中斷狀態，
	檢查目前中斷是否關閉，因為sys_fork為系統呼叫，也就是會進入到80號中斷，
	CPU在進入中斷後會自動關閉中斷，所以目前的中斷狀態應該要為"關閉"，
	同時還要檢查parent_thread->pgdir是不是不為NULL，parent_thread被賦予目前執行緒基底位址，
	只有使用者會系統呼叫，所以目前執行緒應該為使用者執行緒，parent_thread->pgdir不該為NULL，
	
	進入copy_process函數，傳入父和子處理程序，
	
		copy_process函數內，現在要把父程序複製給子程序，回想創建父程序時建的四種分頁:
		
		###為使用者處理程序就建了四種分頁:
		###
		###	1.使用者處理程序執行緒的PCB(在process_execute函數內分配，在物理地址位於核心池內，基底地址為"核心"虛擬地址，佔一分頁)、
		###
		###	2.放 使用者處理程序用的虛擬位址的 點陣圖的 分頁
		###   (在process_execute函數內的create_user_vaddr_bitmap函數內分配，
		###   物理地址位於核心池內，基底地址為"核心"虛擬地址，大小不只一個分頁，基底地址即第一個分頁的基底位址)，
		###
		###	3.使用者處理程序用的 分頁目錄表
		###   (在process_execute函數內的create_page_dir函數內分配，
		###   物理地址位於核心池內，基底地址為"核心"虛擬地址，佔一分頁，
		###   因為不能直接讓使用者訪問到分頁目錄表，所以該表的物理地址位在 核心池 中)，
		###
		###	4.使用者處理程序的堆疊空間 用的分頁
		###   (交棒後在switch_to函數內pop到start_process函數時，在start_process函數內分配，物理地址位於使用者池內，基底地址為"使用者"虛擬地址，佔一分頁)，
		###	  C程式下的 使用者 記憶體分配的規則，由低地址到高地址依序是 程式碼段、初始化資料、未初始化資料、堆疊(包含指令行參數和環境變數)，
		###	  使用者處理程序的堆疊空間是 C程式下的 使用者 記憶體分配 的 一部份，所以分配到的物理地址是在 使用者池 內。
		
		以上四種分頁也要為子程序分配，下面一一來做，

		先用get_kernel_pages函數從核心的物理內存池再申請1個分頁，該分頁會作為父處理程序的空間資料複製到子處理程序的中轉，
		為什麼要中轉，待會會知道，
		獲得新分頁的虛擬位址，把該位址賦予buf_page，若失敗，copy_process函數回傳-1，
		
		進入copy_pcb_vaddrbitmap_stack0函數，一樣傳入父和子程序，要在該函數內將父處理程序的PCB以及虛擬為址點陣圖複製給子處理程序，
		
			copy_pcb_vaddrbitmap_stack0函數內，
			=>根據1.，直接把父處理程序所在的基底位址用memecpy把一分頁大小的記憶體複製到子執行緒的基底位址，即把父程序用的PCB和堆疊都複製到子程序內，
		
			進入fork_pid函數，該函數把thread.c的內的allocate_pid函數包起來，
			因為allocate_pid函數是靜態函數，不能被外部的其他.c檔呼叫，所以用再包一層，變成非靜態的函數，
				
				allocate_pid函數內，進入PV區，用bitmap_scan在pid_pool.pid_bitmap內
				
			把獲得的pid編號給child_thread->pid，
			
			現在開始微調child_thread內的數據，
			>>因為子程序是剛創建的，還沒"花時間"執行過，所以把child_thread->elapsed_ticks歸零，
			>>把child_thread->status設為TASK_READY，等下會放入等待隊列，
			>>把child_thread->ticks設為child_thread->priority，即把時間片加滿，
			>>子處理程序有爸爸了，所以把child_thread->parent_thread賦予parent_thread->pid (parent_thread是傳進來的另一個參數) ，
			>>因為子處理程序是 "獨立" 於父處理程序 "新"創建 的處理程序，不應該與等待隊列和所有對列(all_list)有藕斷絲連，
			  所以要把child_thread->general_tag.prev和child_thread->general_tag.next都設為NULL，
			  child_thread->all_list_tag.prev和child_thread->all_list_tag.next也要都設為NULL，
			>>進入block_desc_init函數，傳入child_thread->u_block_desc，child_thread->u_block_desc是個陣列，內有malloc要用的記憶體描述符號(mem_block_desc)，
			  描述每一種大小的記憶體可以在一個分頁內被分配多少個(desc_array[X].blocks_per_arena)、能用的記憶體的鏈結串列(desc_array[desc_idx].free_list)，
			  父程序在創建時u_block_desc已經被初始化了，而desc_array[X].blocks_per_arena和desc_array[X].block_size都是固定的值，
			  所以現在把child_thread->u_block_desc送進block_desc_init函數主要是進行list_init(&desc_array[X].free_list)，
			  也就是把 掛還能用的記憶體的 desc_array[X].free_list 全都初始化，讓頭和尾互指，
			  也就是把desc_array[X].free_list上還掛的記憶體全部都拔掉，回到最初始的狀態，
			  因為父程序的desc_array[X].free_list和子程序的desc_array[X].free_list已經是不同的鏈結串列了，
			  若子程序要使用記憶體，需要 "重新" 申請一個頁大小的記憶體並切成小塊加入 子程序的desc_array[X].free_list 中，
			
			=>根據2.，接著要複製父程序的虛擬位址點陣圖，所以要 先有放被被複製的虛擬點陣圖的位置!!!
			首先要計算虛擬點陣圖需要多大的記憶體，
			0xc0000000-USER_VADDR_START為能用的虛擬記憶體的大小，虛擬記憶體大小/PG_SIZE為 能用的虛擬記憶體的大小 所佔的頁數，
			一頁對應到點陣圖的一個位，8個位為點陣圖的一個size的大小，所以把 能用的虛擬記憶體的大小 所佔的頁數 除以8，所獲的值為點陣圖的總大小，
			接著要計算該點陣圖佔多少頁，用DIV_ROUND_UP把點陣圖的總大小/PG_SIZE，得到的值為該點陣圖所佔的頁數，不滿一頁的也算一頁，該值為bitmap_pg_cnt，
			進入get_kernel_pages函數，傳入bitmap_pg_cnt，獲得子程序放虛擬記憶體點陣圖的基底位址，把該值賦予vaddr_btmap
			(目前以上配置虛擬位址點陣圖的步驟 與 在父程序時 進入create_user_vaddr_bitmap函數內做的事情相同，接下來開始會不同)，
			現在child_thread->userprog_vaddr.vaddr_bitmap.bits還指著父程序的虛擬為址點陣圖的基底位址，
			趁這個機會用memcpy把child_thread->userprog_vaddr.vaddr_bitmap.bits開始的 bitmap_pg_cnt * PG_SIZE 的記憶體複製到vaddr_btmap處，
			接著才把vaddr_btmap賦予child_thread->userprog_vaddr.vaddr_bitmap.bits，
			
			接著檢查child_thread->name的名字長度有沒有小於11，因為接下來要把child_thread->name多加"_fork"進去，名字總長度不能超過16，
			用strcat把child_thread->name多加"_fork"進去，如父程序的child_thread->name為KIM，則子程序的child_thread->name為KIM_fork，
			
			從copy_pcb_vaddrbitmap_stack0函數返回，回傳0，
			
		回到copy_process函數，若copy_pcb_vaddrbitmap_stack0函數回傳-1，則copy_process函數回傳-1，
		
		根據3，進入create_page_dir函數內為子程序分配專用的分頁目錄表，失敗的話copy_process函數回傳-1，
		成功的話把獲得的分頁目錄表的地址給childred_thread->pgdir，
		
		進入copy_body_stack3函數，傳入父和子程序 以及 buf_page(中轉用的)，
		
			copy_body_stack3函數內，因為create_page_dir函數只填分頁目錄表的後四分之一處，也就是只填核心使用的部分，
			現在要把父程序的第一個表(分頁目錄表)的 前四分之三處 所有被填入表的內容都填到 子程序的分頁目錄表內，第二個表(分頁表)的內容也要填
			除了填表，還要把 表內對應到的分頁內的內容 都複製給子程序，
			
			把parent_thread->userprog_vaddr.vaddr_bitmap.bits賦予vaddr_btmp，
			把parent_thread->userprog_vaddr.vaddr_bitmap.btmp_bytes_len賦予btmp_bytes_len，
			把parent_thread->userprog_vaddr.vaddr_start賦予vaddr_start，
			
			把idx_byte(點陣圖一個size的大小佔8位元，用 外while 搜尋點陣圖用)、idx_bit(在點陣圖的一個size內用 內while 搜尋用)都初始化為0，
			把prog_vaddr也初始化為0(*好像沒必要)，
			
			開始搜尋父程序的虛擬位址點陣圖，先進入外while迴圈，若搜到的父虛擬位址點陣圖的某個size內至少有一位不為0，則進入內while迴圈，
			在內while迴圈內找出為1的位，計算該位對應到的虛擬為址，算法為先 idx_byte*8 + idx_bit ，該值表示該位在點陣圖中是第幾位(從0開始算)，
			把該值*PG_SIZE再加上vaddr_start(在創建父程序時被賦予USER_VADDR_START)即可獲得父虛擬位址點陣圖該位對應到的 虛擬為址 ，
			把該值賦予prog_vaddr，
			
			現在開始要把 父程序的分業目錄表內的 前四分之三處 映射到的分頁內的內容 都複製給子程序
			趁現在cr3暫存器填的還是 父程序的分頁目錄表的基底位址時 ，
			用memcpy把 父程序的虛擬位址點陣圖為1的位 對應到的虛擬為址 開始的PG_SIZE大小複製到 中轉用的buf_page，
			進入page_dir_active函數，傳入child_thread，把cr3暫存器內填的內容切換成 子程序的分頁目錄表的基底位址，
			這個時候剛藉由 父程序的虛擬位址點陣圖 換算出來的虛擬為址(prog_vaddr)雖然沒變，
			但是cr3填的分頁目錄表的地址已經改變了，所以prog_vaddr對應到的實體位址會改變，
			
			現在要設法製造一個 從 "父程序的分頁目錄表內的 前四分之三處 映射到的分頁" 內 複製出的內容的 放置的地方，
			因此進入get_a_page_without_opaddrbitmap函數，傳入prog_vaddr，
			get_a_page_without_opaddrbitmap函數內做的事情 和 get_a_page的後半部一樣，
			get_a_page函數會為你把傳進來的 虛擬位址對應到的 虛擬位址點陣圖的位 置1，
			不過 子程序的虛擬位址點陣圖的內容 前面已經從 父程序的虛擬位址點陣圖 複製過去了，
			所以這裡呼叫get_a_page_without_opaddrbitmap函數，在函數內會做get_a_page函數下半部的事情，
			即忽略把 虛擬位址點陣圖的位 置1 的步驟，然後為傳進來的虛擬位址找一個分頁的物理地址，然後填兩個表，
			
			現在cr3填的分頁目錄表的地址已經改變了，所以prog_vaddr會對應到的 子程序的 實體位址，
			用memcpy把中轉用的buf_page內暫存的內容都複製到prog_vaddr內，
			由此可知 把 表內對應到的分頁內的內容 所採用的方法為 先 複製到中轉用的buf_page，
			然後把prog_vaddr切換成子程序的模式後，再 複製到prog_vaddr，
			中轉用的buf_page的用在此，
			
			進入page_dir_activate函數，把cr3切回父程序的分頁目錄表的位址，
			因為未來會要釋放用父程序申請的buf_page之記憶體，所以cr3要切回來，
			
			繼續下一內while迴圈繼續搜尋，內while迴圈搜尋完則繼續下一外while迴圈，搜尋完後從copy_body_stack3函數返回，
			
		回到copy_process函數，根據4.，要為子程序分配專屬的堆疊，所以進入到build_child_stack函數內，
		
			build_child_stack函數內，把child_thread的基底位址 加上PG_SIZE後 減掉intr_stack的大小，然後把該值賦予intr_0_stack，
			現在intr_0_stack指向這裡:
			
			##############################################################################################
			##	struct thread_stack {                                          							##
			##		uint32_t ebp;							         									##
			##		uint32_t ebx;                                              							##
			##		uint32_t edi;                                              							##
			##		uint32_t esi;                                              							##
			##	                                                               							##
			##		void (*eip) (thread_func* func, void* func_arg);           							##
			##		void (*unused_retaddr);                                    							##
			##		thread_func* function;	由Kernel_thread所调用的函数名，類型為void (*function)(void*)##
			##		void* func_arg;    	  	由Kernel_thread所调用的函数所需的参数						##
			##	};                                                              						##
			##############################################################################################
							!!!thread_stack緊接在intr_stack的上面(低地址處)!!!
			##############################################################################################
			##	struct intr_stack {                                                           			##
			##		uint32_t vec_no; <---低地址  	<=== !!!intr_0_stack!!! 							##
			##		uint32_t edi;                                                                 		##
			##		uint32_t esi;                                                                 		##
			##		uint32_t ebp;                                                                 		##
			##		uint32_t esp_dummy;	 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略		##
			##		uint32_t ebx;                                                                 		##
			##		uint32_t edx;                                                                 		##
			##		uint32_t ecx;                                                                 		##
			##		uint32_t eax;                                                                 		##
			##		uint32_t gs;                                                                  		##
			##		uint32_t fs;                                                                  		##
			##		uint32_t es;                                                                  		##
			##		uint32_t ds;                                                                  		##
			##		                                                                              		##
			##		以下由cpu从低特权级进入高特权级时压入                                         		##
			##		uint32_t err_code;	err_code会被压入在eip之后                                 		##
			##		void (*eip) (void);                                                           		##
			##		uint32_t cs;                                                                  		##
			##		uint32_t eflags;                                                              		##
			##		void* esp;                                                                    		##
			##		uint32_t ss;     <---高地址                                                			##
			##	};                                                                            			##
			##############################################################################################
			
			把intr_0_stack->eax設為0，到時候把子程序掛到就緒隊列後，若交棒給子程序，
			因為此時子程序是第一次執行，所以藉由intr_exit退到子程序的函數時，會pop "struct intr_stack"內 所有的內容到暫存器，
			此時intr_0_stack->eax內的0就會變成fork函數的回傳值，回傳值0代表是"子程序"，
			
			通常交棒給 沒執行過的子處理程序 ，會在switch_to pop四個暫存器值後，pop eip進入到start_process函數，設定struct intr_stack內的暫存器數值，
			不過在"根據1."的時候，已經把父程序用的PCB和 "堆疊" 都複製到子程序內了，
			等於是只要改掉回傳值intr_0_stack->eax就行了，無須進入到start_process函數內，
			所以在此把struct thread_stack的部分改寫，
			把 intr_0_stack-1之地址 設為ret_addr_in_thread_stack，
			把 intr_0_stack-2之地址 設為esi_ptr_in_thread_stack，
			把 intr_0_stack-3之地址 設為edi_ptr_in_thread_stack，
			把 intr_0_stack-4之地址 設為ebx_ptr_in_thread_stack，
			把 intr_0_stack-5之地址 設為ebp_ptr_in_thread_stack，
			使目前狀況變成這樣:
			
			##############################################################################################
			##		ebp_ptr_in_thread_stack																##
			##		ebx_ptr_in_thread_stack																##
			##		edi_ptr_in_thread_stack																##
			##		esi_ptr_in_thread_stack																##
			##		ret_addr_in_thread_stack															##
			##############################################################################################
			##############################################################################################
			##	struct intr_stack {                                                           			##
			##		uint32_t vec_no; <---低地址  	<=== !!!intr_0_stack!!! 							##
			##		uint32_t edi;                                                                 		##
			##		uint32_t esi;                                                                 		##
			##		uint32_t ebp;                                                                 		##
			##		uint32_t esp_dummy;	 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略		##
			##		uint32_t ebx;                                                                 		##
			##		uint32_t edx;                                                                 		##
			##		uint32_t ecx;                                                                 		##
			##		uint32_t eax;                                                                 		##
			##		uint32_t gs;                                                                  		##
			##		uint32_t fs;                                                                  		##
			##		uint32_t es;                                                                  		##
			##		uint32_t ds;                                                                  		##
			##		                                                                              		##
			##		以下由cpu从低特权级进入高特权级时压入                                         		##
			##		uint32_t err_code;	err_code会被压入在eip之后                                 		##
			##		void (*eip) (void);                                                           		##
			##		uint32_t cs;                                                                  		##
			##		uint32_t eflags;                                                              		##
			##		void* esp;                                                                    		##
			##		uint32_t ss;     <---高地址                                                			##
			##	};                                                                            			##
			##############################################################################################
			
			然後把*ret_addr_in_thread_stack設為intr_exit，
			這樣到時候switch_to函數的最後會pop此數值後，會 "直接" 進入kernel.S的intr_exit，跳過進入start_process函數的步驟，
			把*ebp_ptr_in_thread_stack、*ebx_ptr_in_thread_stack、*edi_ptr_in_thread_stack、*esi_ptr_in_thread_stack都設為0，
			此步驟其實只是為了讓thread_stack更加清晰而已，可有可無，因為到時候進入intr_exit後會進行一系列的pop把暫存器的值都覆蓋，
			
			最後把child_thread->self_kstack設為ebp_ptr_in_thread_stack，使目前狀況變成這樣:
			
			##############################################################################################
			##		ebp_ptr_in_thread_stack = 0	   <===!!!child_thread->self_kstack!!!					##
			##		ebx_ptr_in_thread_stack = 0															##
			##		edi_ptr_in_thread_stack = 0															##
			##		esi_ptr_in_thread_stack = 0															##
			##		ret_addr_in_thread_stack = intr_exit												##
			##############################################################################################
			##############################################################################################
			##	struct intr_stack {                                                           			##
			##		uint32_t vec_no; <---低地址  	<===intr_0_stack									##
			##		uint32_t edi;                                                                 		##
			##		uint32_t esi;                                                                 		##
			##		uint32_t ebp;                                                                 		##
			##		uint32_t esp_dummy;	 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略		##
			##		uint32_t ebx;                                                                 		##
			##		uint32_t edx;                                                                 		##
			##		uint32_t ecx;                                                                 		##
			##		uint32_t eax;                                                                 		##
			##		uint32_t gs;                                                                  		##
			##		uint32_t fs;                                                                  		##
			##		uint32_t es;                                                                  		##
			##		uint32_t ds;                                                                  		##
			##		                                                                              		##
			##		以下由cpu从低特权级进入高特权级时压入                                         		##
			##		uint32_t err_code;	err_code会被压入在eip之后                                 		##
			##		void (*eip) (void);                                                           		##
			##		uint32_t cs;                                                                  		##
			##		uint32_t eflags;                                                              		##
			##		void* esp;                                                                    		##
			##		uint32_t ss;     <---高地址                                                			##
			##	};                                                                            			##
			##############################################################################################
			
			到時候交棒給第一次執行的子程序時，switch_to的最後會從child_thread->self_kstack開始四個暫存器後，
			會ret(=pop eip)，此時被pop的數值為ret_addr_in_thread_stack = intr_exit，
			所以程式會直接進入到intr_exit，並再從struct intr_stack pop一系列暫存器的數值，
			由於除了intr_0_stack->eax有改成0外，其他struct intr_stack內的內容都是從父程序複製過來的，
			所以intr_stack內的內容除了intr_0_stack->eax外都跟父函數一模一樣，
			包括要回傳到的地址void (*eip) (void)以及 esp、ss 都跟父函數一模一樣，
			所以交棒給為執行過的子程序後，最後能夠返回到 父程序呼叫fork的地方的 後面，
			
			從build_child_stack函數返回，回傳0，
			
		回到copy_process函數，
		父程序的thread->fd_table內紀錄的是目前已經開啟的檔案，現在父程序用的PCB已經複製一份給子程序了，
		等於是thread->fd_table內的內容都被複製一份，也就是thread->fd_table內所有的檔案又被開啟了一次，
		所以現在要進入到update_inode_open_cnts函數內，把thread->fd_table內所有已被開啟的檔案都再開啟一次，
		
			update_inode_open_cnts函數內，把所有 不為-1的fd_table[X](X要從3開始) 對應到的file_table[Y].fd_inode->i_open_cnts加1 (Y等於fd_table[X]) ，
			
		回到copy_process函數，現在1.~4.全部都複製完畢，所以中轉用的buf_page已經用完了，用mfree_page釋放掉，
		最後返回0，
			
	回到sys_fork函數，檢查回傳值是否不為-1，若為-1，sys_fork函數會回傳-1，
	
	檢查就緒隊列，現在就緒隊列內不應該看到子程序，然後把子程序加入就緒隊列，
	檢查所有隊列，現在所有隊列內不應該看到子程序，然後把子程序加入所有隊列，
	
	從copy_process函數返回，回傳child_thread->pid，因為fork是系統呼叫(80號中斷)，
	所以回傳值會存入eax暫存器中，然後進入intr_exit，從中斷返回，
	
/main.c
回到main函數，因為父程序用fork系統呼叫(80號中斷)後，會先藉由tss把esp切換到核心的堆疊去，
因為有特權級變化，所以CPU會push使用者區域的SS和esp等一系列的暫存器，接著進入中斷處理常式，push一系列的暫存器，
然後父程序又把堆疊複製給子程序，所以子程序跟父程序會有一模一樣的堆疊，包括SS和esp，除了intr_stack->eax(回傳值)有被特意改成0，
所以交棒給子程序後，返回的地方會跟父程序一樣，但回傳值不一樣，
因此回到main函數後父子會在if(ret_pid)的地方分叉，


<execv統整>
參考以下:
###為使用者處理程序就建了四種分頁:
###
###	1.使用者處理程序執行緒的PCB(在process_execute函數內分配，在物理地址位於核心池內，基底地址為"核心"虛擬地址，佔一分頁)、
###
###	2.放 使用者處理程序用的虛擬位址的 點陣圖的 分頁
###   (在process_execute函數內的create_user_vaddr_bitmap函數內分配，
###   物理地址位於核心池內，基底地址為"核心"虛擬地址，大小不只一個分頁，基底地址即第一個分頁的基底位址)，
###
###	3.使用者處理程序用的 分頁目錄表
###   (在process_execute函數內的create_page_dir函數內分配，
###   物理地址位於核心池內，基底地址為"核心"虛擬地址，佔一分頁，
###   因為不能直接讓使用者訪問到分頁目錄表，所以該表的物理地址位在 核心池 中)，
###
###	4.使用者處理程序的堆疊空間 用的分頁
###   (交棒後在switch_to函數內pop到start_process函數時，在start_process函數內分配，物理地址位於使用者池內，基底地址為"使用者"虛擬地址，佔一分頁)，
###	  C程式下的 使用者 記憶體分配的規則，由低地址到高地址依序是 程式碼段、初始化資料、未初始化資料、堆疊(包含指令行參數和環境變數)，
###	  使用者處理程序的堆疊空間是 C程式下的 使用者 記憶體分配 的 一部份，所以分配到的物理地址是在 使用者池 內。

現在分析假如目前在根目錄，若把"cat"應用程式寫入硬碟，然後把終端機清頻後，輸入 "  ./cat   ../../kimweng01.txt    " 的結果:
																			   ^~	  ^~~                   ^~~~
																			   空二格 空三格                空四格
							
/main.c
先printf"I'am kernel\n"，然後進入init_all函數，
	

/thread.c
	在init_all函數內的thread_init函數內創建init程序，
	開啟中斷的步驟是init_all函數內的ide_init()和filesys_init()之前做，
	因為這兩個init都需要用到中斷，
	
/main.c
回到main函數，

接下來要把cat應用程式從hd60M那顆硬碟載到/cat內(此時該步驟類似於把應用程式從play商店載到電腦裡的某個路徑)，
先把cat應用程式的大小賦予file_size(編譯後編譯器就會顯示大小)，
再把file_size向上取整除以512可以得到cat應用程式需要占用的扇區數，把該值賦予sec_cnt，
sys_malloc file_size大小的記憶體，把獲得的記憶體虛擬地址給prog_buf，
先把cat應用程式從hd60M ide_read sec_cnt個扇區大小 到prog_buf內，
在根目錄創建cat "資料夾" ，即/cat為應用程式被載入的路徑，
所以進入sys_open函數，傳入的路徑為/cat、flag為O_CREAT|O_RDWR，

	sys_open函數內會先檢查路徑為/cat的資料夾存不存在，理論上現在應該不存在，
	然後接著會檢查傳入的flag對應到O_CREAT的位不是是1，是的話就用file_create函數創建在根目錄的cat資料夾，
	
回到main函數，
把file_create函數傳回的檔案的X值給fd，
確定fd不為-1後，用sys_write函數把prog_buf內已被ide_read的cat應用程式寫入X值為fd的檔案中，失敗的話顯示"file write error!\n"，

用cls_screen清屏，然後用console_put_str印出"[XXXXX@localhost /]"，

進入thread_exit函數，該函數通常是父程序把運行完的子程序占用的資源消除用的，
在此由於main執行緒已經能做的都做完了，且main是最開始運行的程序，不是init的子程序，
所以在此直接呼叫thread_exit函數把main執行緒占用的資源測底消除，
傳入當前執行緒以及true表示消除完要立即交棒給下一程序(因為當前執行緒的資源被消除就不能再執行了，否則會出問題)，

/thread.c
	thread_exit函數內，
	因為thread_exit函數內可能會進入到schedule函數，會涉及到鏈結串列的改變，所以在此先關中斷，
	把當前執行緒的ststus設為TASK_DIED，
	
	一般都是父程序檢測已經掛住的子程序後呼叫thread_exit函數把子程序徹底殺掉，
	子程序通常都是呼叫thread_block把自己的狀態設為TASK_HANGING並把自己block住，也就是在執行狀態把自己block住，
	但有時候會呼叫thread_exit函數把一個還在就緒隊列的程序殺掉，
	所以在此判斷要殺掉的程序是不是在就緒隊列中，是的話要把該程序從就緒隊列remove掉，
	
	根據1.，若要殺掉的程序是使用者處理程序，則要把其PCB所用的分頁用mfree回收掉，
	
	把要殺掉的程序程序從所有隊列(all_list)移除，
	
	要殺掉的程序要歸還pid，所以進入release_pid函數，傳入要殺掉的程序的pid，
	
		release_pid函數內，進入PV區，把pid號換算成 該號對應到pod_pool.pid_bitmap內的"第幾位"
		(pid不一定會從0開始算，像目前採用的方案就是從1開始算，而pid_bitmap是從0開始算，所以要換算)，
		用bitmap_set把對應到到的位置0，
		(*把bitmap對應到的位清0應該不用進入PV區，因為沒有bitmap_scan到一半突然被交棒導致兩個程序申請到bitmap同一位的狀況?)
		
	回到thread_exit函數，若傳進來的need_scchedule是true，表示殺完程序要立即交給下一棒，
	因為目前是殺掉main自己，把自己殺掉後自己已經不能再執行了，所以要"立即"交棒，
	所以進入schedule函數，把自己交給下一棒，
-------------------------------------------------------------------------------------------

/main.c
由於目前只創建main和init兩個程序，所以main自殺後，一定會交棒給init程序，因此進入到init函數，

用fork複製程序，
-->父程序會用while(1)不斷系統呼叫wait函數，
	
	sys_wait函數內，
	把當前執行緒(程序)賦予parent_thread，然後進入while(1)不斷迴圈，
	不斷的用list_traversal遍歷所有隊列(all_list)內有沒有狀態已經是TASK_HANGING的程序(子程序)，
	若有找到，則立刻把所找的執行緒(程序)的tag賦予struct list_elem* child_elem，
	
	==>如果child_elem的最終結果不為NULL，表示所有隊列內已經有子程序執行完被掛住了，
	把child_elem轉換成執行緒(程序)的基底位址並賦予child_thread，
	把child_thread->pid賦予child_pid，
	進入thread_exit函數，傳入child_pid和false，把掛住的子程序徹底殺掉，
	但因為現在是父程序呼叫thread_exit函數把子程序殺掉，不是自殺，
	殺掉子程序後父程序還可以繼續執行，所以傳入false，表示把目標程序殺掉後父程序繼續執行而不交棒，
	殺掉完子程序後thread_exit函數會回傳殺掉的子程序的pid，把該值賦予child_pid，
	最後回傳child_pid，
	
	現在由於在init fork出來的子程序還沒執行完，所以目前不會進入if(child_elem != NULL)，
	在此用list_traversal檢查all_list內是不是有子程序，理論上父程序會fork出子程序後才呼叫wait，
	所以理論上現在all_list內應該要有子程序，若沒有表示出錯，回傳-1，
	父程序用thread_block把自己block住，狀態設定為TASK_WAITING，等到子程序把自己喚醒，
	
	=====假如某一子程序結束運行，會把孫程序的父親都改成init，這樣孫程序執行完就會喚醒init，init就會在sys_wait函數內繼續執行
	由於thread_block位於while迴圈的底部，所以會直接進入下一迴圈把其中一個子程序(孤兒)殺掉，
	然後回到init函數，進入下一while迴圈，然後再呼叫一次wait，再把下一個子程序(孤兒)殺掉，如此往復循環=====
	
	
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-->子程序會呼叫my_shell函數，
	
/shell.c
	my_shell函數內，
	把cwd_cache[0]設為'/'，接著要進入while(1)，因為要"隨時都能輸入指令"，
	然後用print_prompt顯示"[rabbit@localhost %s]$ "，其中%s為'/'，是剛設定的內容，
	表示要現在"在根目錄輸入指令"，所以print_prompt()後會顯示"[rabbit@localhost /]$ "，
	
	把final_path用memset全清0，final_path要擺的是路徑的最終結果，
	把cmd_line用memset全清0，cmd_line要擺的是輸入的指令，
	
	呼叫readline函數，開始把從鍵盤輸入的指令從ioqueue讀到cmd_line，
	傳入目的地址為cmd_line，傳入的 可讀取大小為 MAX_PATH_LEN ，表示可讀最大長度，
	
		readline函數內，檢查目的地的地址(cmd_line傳進來變為buf)是否不為NULL 且 可讀取大小(count)是否大於0，
		把buf給char* pos，buf的值不會動，pos待會會++或--，
		
		進入"大while迴圈"，不斷的用read標準輸入(從"ioqueue"讀入)到pos，此pos等於cmd_line，
		read函數內會呼叫ioq_getchar，若ioqueue是空的，則目前程序會被阻塞，直到敲下鍵盤(外部中斷)為止，
		每次讀一字元，期間pos不斷++，直到pos - buf的值等於count為止，
		然後每次檢查現在讀進來的字元(*pos)為何，
		==>如果是"確認鍵"，則putchar('\n')後，直接return，
		==>如果是'\b'，則要檢查cmd_line[0] != '\b'，避免"刪除過頭"，再putchar('\b')，
		==>如果是"清屏"，先把*pos = 0，為要重新輸出到螢幕的buf(cmd_line)設置斷點，
		然後呼叫clear函數清屏，接著print_prompt，再printf("%s", buf)，把buf(cmd_line)重新再輸入一遍，
		==>如果是"清掉輸入"，則進入while迴圈，不斷putchar('\b')並pos--，直到buf等於pos為止，
		舉例，假設輸入KIM，則現在pos會指向這裡:KIM
												  ^pos
		現在要清掉輸入，所以不斷putchar('\b')並pos--，直到:
														   ^pos
		現在已經全部清完，而此時buf等於pos，由此可知，清掉輸入的while迴圈直到buf等於pos就停止，
		==>如果是其他字元，直接putchar(*pos)，然後pos++，
		
		若輸入的字數超過最大量則會脫離"大while迴圈"，
		並輸出:printf("readline: can`t find enter_key in the cmd_line, max num of char is 128\n")，
		
	若輸入的是"確認鍵"，則會回到my_shell函數，
	若cmd_line[0] == 0，表示只輸入一個確認鍵，則什麼也不做繼續下一迴圈，
	若剛剛的輸入有'|'，表示多重管道操作，在此不是，所以程式跑到else，                        <======================如果是管道操作的話分析在下!!!
	
	現在開始填argc和argv，先把argc初始化為-1，
	然後進入cmd_parse函數，傳入cmd_line、argv和' '，要告訴cmd_parse函數要以空白鍵為分割符號，
	
		cmd_parse函數內，檢查cmd_str(cmd_line傳入變成的)是否為NULL，
		把arg_idx初始化為0，此為argv[X]的X，
		用while迴圈把argv[X]內的元素都初始化為NULL，
		把cmd_str賦予char* next，此next待會會++，而cmd_str則是不動，
		把int32_t argc初始化為0，
		
		現在開始解析輸入，
		"  ./cat   ../../kimweng01.txt    "，next目前的位置:  
		 ^
						 next
		進入外while迴圈，先用一個內while把輸入的指令的前面的空格給去除，迴圈期間next不斷++，直到變成這樣:
		"  ./cat   ../../kimweng01.txt    "，
		   ^
           next
		目前*next不為0，所以不會進入if (*next == 0)，
		把next賦予argv[argc]，即把"./cat   ../../kim···"的起始地址給argv[argc]，此時argc=0，
		
		接著再進入一次內while迴圈，這次要尋找分隔符號，next要不斷++直到:
		"  ./cat   ../../kimweng01.txt    "，
		        ^
                next
		現在已經解析到分隔符號了，把分隔符號的位置設為'0'，然後next++，變成:
		"  ./cat空  ../../kimweng01.txt    "，
		          ^
                  next
		這動作也使得argv[argc]內存的內容從"./cat   ../../kim···"變成"./cat"，
		
		檢查argc有沒有大於MAX_ARG_NR，有表示指令的參數過多，回傳-1，
		
		argc++，然後進入下一外while迴圈，
		
		一直重複動作，直到:
		"  ./cat空   ../../kimweng01.txt空   "，
									      ^
									      next
										  
		現在進入下一外while迴圈，然後進入到第一個內while迴圈把next之後的空格都去除，變成:
		"  ./cat空   ../../kimweng01.txt空   "，
									         ^
									         next
		現在next指的位置是NULL，所以會進入if (*next == 0)，然後break，脫離外while迴圈，回傳argc，
		
		此時的結果應該為:
		argv[0] = ./cat				argc = 2
		argv[1] = ../../kim
		
	回到my_shell函數，檢查argc是不是為-1，若為-1表示指令的參數過多，
	直接printf("num of arguments exceed %d\n", MAX_ARG_NR)，並continue到下一迴圈重新顯示"[rabbit@localhost /]$ "重來，
	
	若檢查通過，則進入cmd_execute函數，傳入argc和argv，開始做輸入的指令要做的事，
	
		cmd_execute函數內，檢查argv[0]什麼，
		如果是"ls"，則進入buildin_ls函數，傳入argc和argv，
		如果是"pwd"，則進入buildin_pwd函數，傳入argc和argv，
		以此類推，
		特別是如果是"cd"，除了進入buildin_cd函數外，
		還要把cwd_cache用memset先清0，再填入final_path，
		比如你輸入"cd /KIM/weng"，則上述動作可以讓print_prompt的結果為"[rabbit@localhost /KIM/weng]$ "，
		
		但現在是argv[0]是/cat，不是內建的指令
		(內建的指令可以類比為工作管理員、控制台等windows內建的功能，而外部指令可以類比為你從商店載到某個目錄內的應用程式)，
		所以程式會跑到else，
		fork出孫程序，
		
----------->子程序會呼叫wait，把自己block住以等待孫程序，
			等到孫程序執行完喚醒子程序後，把孫程序的狀態存入staus，最後呼叫thread_exit函數回收孫程序的pcb(殺掉)，
			回傳孫程序的pid號，
		
		~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		
----------->孫程序會呼叫make_clear_abs_path函數，傳入argv[0](/cat)和final_path(全域變數)，
		
/buildin_cmd.c
			make_clear_abs_path函數內，
			設置char abs_path[MAX_PATH_LEN] = {0}，此用來放絕對路徑，
			
			然後判斷傳入的path是不是絕對路徑，判斷方式為看path[0]是不是為'/'，
			==>如果不是(例如argv[0]為 ../cat 或 ./cat)，
			先用memset把abs_path全部清0，這動作應該只是在添保險，
			進入getcwd函數，傳入abs_path和MAX_PATH_LEN，把abs_path"目前位置"的絕對路徑，
			例如目前位置在c內，則把/a/b/c填入abs_path，
			填完絕對路徑後檢查填入的絕對路徑是不是根目錄，
			如果不是，則在絕對路徑後面再加一個"/"，
			根目錄不用加"/"，否則會變成這樣:"//"，
			把傳進來的路徑填入絕對路徑內，
			
			舉例:說如果傳進來的路徑是"../cat"，而現在操作的位置在c資料夾，
			則先用getcwd函數把目前位置的絕對路徑填入abs_path內，使abs_path的內容為/a/b/c，
			再把"../cat"填入abs_path，使其內容為/a/b/c/../cat，
			
			==>因為目前傳進來的是/cat，該路徑已經是絕對路徑了，cat應用程式就載在/cat這個位置，
			所以不用經過把當前操作的資料夾位置換成絕對路徑的過程，直接把/cat填入abs_path，
			使其內容為/cat，這就是cat應用程式被載入的位置，
			
			假如傳進來的路徑是相對路徑，但是 把當前操作的資料夾位置換成絕對路徑 這個動作失敗了，
			也就是getcwd函數回傳結果為-1的情況，abs_path就先什麼也不填，然後直接把傳進來的路徑填入abs_path，
			即如果現在操作的位置在c資料夾，但getcwd函數回傳為-1，
			表示 把當前操作的資料夾位置換成絕對路徑 這個動作失敗，直接在abs_path內填入"../cat"，
			
			經過相對路徑轉絕對路徑的過程後，進入wash_path函數，傳入abs_path和全域變數final_path，
			
				wash_path函數內，該函數目的是要把傳進來的abs_path內的".."或"."去除，
				例如:把/a/b/c/../cat變成/a/b/cat
				
				檢查old_abs_path[0]有沒有等於'/'，如果不等於表示剛剛getcwd函數失敗，
				例如abs_path內填的是"../cat"，會被ASSERT檔下，
				
				設置char name[MAX_FILE_NAME_LEN] = {0}，
				設置char* sub_path = old_abs_path，old_abs_path為傳進來的abs_path，sub_path存"已被拔頭的路徑"
				
				開始進行類似search_file函數"開貨車"的行為(有改寫程式，看筆記照!!!)，
				先把new_abs_path[0]設為0，避免new_abs_path不乾淨，
				接著用strcat先在new_abs_path內填入"/"(為什麼要先填，接下來的 需要注意 會解釋)，
				
				--------------------------------------------------------------------
				然後進入while迴圈，先用memset把name清0，
				開始用path_parse函數"拔sub_path(最初被賦予old_abs_path，old_abs_path為傳進來的abs_path)的頭"，
				然後每次把拔完頭的路徑重新賦予sub_path，而name經過path_parse函數後會被賦予"被拔下來的頭"，			<===========重要!!!
				
				~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				若name[0]的結果為'0'，
				表示剛傳進去的sub_path(最初被賦予old_abs_path，old_abs_path為傳進來的abs_path)是根目錄，
				在new_abs_path(final_path傳進來變的)內填入"/0"後，直接返回，
				^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				##以上的code後來分析為沒必要，若傳進來的sub_path是根目錄，
				##則會發生以下第二個 需要注意 的情況。
				
				==>如果被拔的頭是".."，則先把char* slash_ptr定位為new_abs_path的最後一個"/"的位置，
				舉例:
				假設傳進來的old_abs_path(abs_path傳進來變的)是:/a/b/c/../cat，
				若目前拔到的是".."，則現在new_abs_path內理論上已經被填入"/a/b/c"，
				用strrchr獲得目前new_abs_path內最後一個'/'的位置，把該位置賦予char* slash_ptr，
				即現在new_abs_path狀況為:	"/a/b/c"
												 ^slash_ptr，
				現在分為兩種狀況:
					==>如果slash_ptr的位置和new_abs_path的起始位置是不一樣的，那現在可能的狀況為:
												"/a/b/c"
													 ^slash_ptr，
					則直接把*slash_ptr設為0，
					即把"/a/b/c"變成"/a/b空c"，形同"/a/b"，
				
				==>如果slash_ptr的位置和new_abs_path的起始位置是一樣的，那現在可能的狀況為:
												"/a"
												 ^slash_ptr，
					則把*(slash_ptr + 1)設為0，即把"/a"變成"/空"，形同"/"，
				
					###需要注意:
					###	假如現在欲把"/.."變成"/"，
					###	則用strrchr獲得目前new_abs_path內最後一個'/'的位置，把該位置賦予char* slash_ptr後，
					###	若new_abs_path內起初有被填入"/"的話，則目前的狀況會為:
					###							"/"
					###						 	 ^slash_ptr，
					###	因為現在slash_ptr的位置和new_abs_path的起始位置是一樣的，
					###	所以會進入第二個if，把*(slash_ptr + 1)設為0，即把"/"變成"/空"，形同"/"，
					###	結果與預期的相符，
					###	
					###	由此可見，若new_abs_path內起初有沒被填入"/"的話，
					###	則strrchr會回傳NULL並把值賦予slash_ptr，
					###	然後接著又要把*(slash_ptr + 1)設為0，
					###	因為slash_ptr為NULL，加1可能會出問題，
					###	所以進入while迴圈前，要用strcat先在new_abs_path內填入"/"。
				
				==>如果被拔的頭是"普通名字"，即不是"."，
				則確認new_abs_path不是'/'後，在new_abs_path填入'/'，
				確認的目的是避免new_abs_path原本是"/"，填完後變"//"
				(該情況會發生在傳入的路徑譬如說為"/a/../b"的時候，
				new_abs_path會先變成"/"，再變成"/b")，
				把拔下來的名字填入new_abs_path，像現在傳進來的old_abs_path是"/cat"，
				則"cat"被sub_path函數拔下來，然後在new_abs_path內填入'/'後，接著填入"cat"，
				使new_abs_path內為"/cat"，
				
				假如被拔的頭是"."，則無須理會，即不會進入任何if，
				因為"/a/b/c/./d"的結果與"/a/b/c/d"是一樣的，
				
				把name用memset清0，然後繼續下一迴圈，直到sub_path為空，然後離開wash_path函數，
				
				###需要注意:
				###	假如被拔的頭是"空"，即name[0]的結果為'0'，
				###	該情況只會發生在傳入的sub_path(最初被賦予old_abs_path，old_abs_path為傳進來的abs_path)為 根目錄 的狀況，
				###	然後由於sub_path為"/"而不為空，所以不會被while擋下，
				###	則也無須理會，即不進入任何if，繼續下一迴圈，
				###	因為每次把拔完頭的路徑會重新賦予sub_path，
				###	所以要進入第二次while時sub_path會為NULL，此時就會被while擋下，然後離開wash_path函數，
				###	因為進入while迴圈前，new_abs_path會被先填入'/'，
				###	所以離開wash_path函數後new_abs_path內會為"/"，符合預期。
				--------------------------------------------------------------------
				
			回到make_clear_abs_path函數，new_abs_path回來變為final_path，而final_path又是全域變數，
			所以由此可知，絕對路徑內的".."或"."去除後，最終結果會存在final_path內，
			離開make_clear_abs_path函數，
			
/shell.c	
		回到cmd_execute函數，把final_path(內為欲操作的相對路徑轉絕對路徑後再去除".."和"."的結果)重新賦予argv[0]，
		設置struct stat file_stat，然後用memset把file_stat清0，
		進入stat函數，傳入argv[0]和&file_stat，獲得argv[0]之檔案(資料夾)的各項屬性，並把各項屬性存入傳入的file_stat內，
=======>如果沒有找到檔案(資料夾)，則回傳-1，因此stat函數可以檢測argv[0]內填的檔案或資料夾是否真實存在，
		若不存在printf("my_shell: cannot access %s: No such file or directory\n", argv[0])，
		然後進入exit函數，傳入-1，直接退出，-1代表出錯，
			
			sys_exit函數內，把當前程序(執行緒)賦予child_thread，
			把child_thread->exit_status設為傳進來的狀態，如果是-1，就把-1給child_thread->exit_status，
			檢查child_thread->parent_pid是否不為-1，不通過要PANIC，
			孫程序正式結束前，要把孫程序所有的曾孫都交給init收養，避免所有的曾孫都變孤兒，
			遍歷所有隊列(all_list)，用init_adopt_a_child函數把所有父親為child_thread->pid的程序的父親都改為1(init程序的pid)，
			
			進入release_prog_resource函數，傳入child_thread，開始回收child_pid的資源，
				
				release_prog_resource函數內，要釋放使用者的分頁目錄表內指向的所有分頁表和分頁，
				當初根據3.所建立的分頁目錄表內是還沒有填任何東西，
				但要釋放的時候裡面可能就被填東西了，而每申請一個分頁表或分頁會在物理位址的點陣圖的其中一個位設1，
				所以要連同 分頁目錄表內指向的所有分頁表和分頁 都釋放掉，做法是把對應到的物理位址的點陣圖的位歸0，
				
				把release_thread->pgdir賦予pgdir_vaddr，此為使用者所用的分頁目錄表的基底虛擬位址，
				因為使用者所用的部分為分頁目錄表的第0到第767項，所以把768賦予user_pde_nr，然後設置pde_idx = 0，
				因為核心所用的部分為分頁目錄表的第768到第1023項，所以把1024賦予user_pde_nr，然後設置pde_idx = 0，
				設置uint32_t pde = 0，設置uint32_t* v_pde_ptr = NULL，
				設置uint32_t pte = 0，設置uint32_t* v_pte_ptr = NULL，
				設置uint32_t* first_pte_vaddr_in_pde = NULL，設置uint32_t pg_phy_addr = 0，
				
				現在開始"搜查"傳進來使用者程序的分頁目錄表，方法為先檢查分頁目錄表內的紅色箭頭在不在，
				如果在，就要檢查紅色箭頭指向的分頁表內的黑色箭頭在不在，如果在，就把黑色箭頭指向的位址送入pfree函數把該分頁free掉，
				分頁表內的黑色箭頭都搜完後，再把紅色箭頭所指向的位址送入pfree函數把該分頁表所占用的頁free掉，
				(*	free_a_phy_page函數的內容與pfree函數完全一樣，不知為何要多寫一個free_a_phy_page函數)，
				
				進入外while迴圈，把pgdir_vaddr加上pde_idx後賦予v_pde_ptr，
				因為v_pde_ptr的型別是32位元的地址，v_pde_ptr+1等於加4位元組，
				把*v_pde_ptr賦予pde，此pde為pgdir_vaddr+pde_idx這個地址內存的內容，
				此內容為紅色箭頭的"指向"，和0xfffff000作and後為 "分頁表"的 基底"物理"位址，					<-------------------重要!!!
				若pde和0x00000001作and的結果有值，表示pgdir_vaddr+pde_idx這個地址內存有紅色箭頭，
				要開始掃黑色箭頭，現在要獲得紅色箭頭所指的分頁表內第0個位置的"虛擬地址"，
				因為紅色箭頭指的是實體位指，所以不能直接從紅色箭頭拿，
				方法為先把pde_idx乘以0x400000，pde_idx代表分頁目錄表內的第幾個位置，
				假如分頁目錄表內的第2個位置(從0開始算)有紅色箭頭，則pde_idx為2，2 * 0x400000 = 0x800000，
				0x800000=10_0000000000_000000000000，
				這個虛擬位址會映射到分頁目錄表的第2個位置，然後映射到分頁表中的第0個的位置，然後再映射到分頁內的第0個元素的位址，
				所以可以得知藉由乘以0x400000即為第0個 "分頁" 的基底虛擬位址，
				把這個基底虛擬位址送入pte_ptr函數即可獲得 "分頁表"內 第0個可以放黑色箭頭的虛擬位址，
				
				把pte_idx歸0，現在開始進入內while迴圈，把first_pte_vaddr_in_pde加上pte_idx後賦予v_pte_ptr，
				因為v_pte_ptr的型別是32位元的地址，v_pte_ptr+1等於加4位元組，
				把*v_pte_ptr賦予pte，此pte為first_pte_vaddr_in_pde+pte_idx這個地址內存的內容，
				此內容為黑色箭頭的"指向"，和0xfffff000作and後為 "分頁"的 基底"物理"位址，					<-------------------重要!!!
				若pte和0x00000001作and的結果有值，表示first_pte_vaddr_in_pde+pte_idx這個地址內存有黑色箭頭，
				把pte & 0xfffff000賦予pg_phy_addr，此為 "分頁"的 基底"物理"位址，
				把該值送入pfree函數內，該函數內會把對應到的物理位址點陣圖的位歸0，
				pte_idx++，不斷內while迴圈掃完所有能放黑色箭頭的位置，離開內while迴圈，
				
				除了分頁要釋放，分頁表也要釋放，
				把pde & 0xfffff000賦予pg_phy_addr，此為 "分頁表"的 基底"物理"位址，
				把該值送入pfree函數內，該函數內會把對應到的物理位址點陣圖的位歸0，
				pde_idx++，不斷外while迴圈掃完所有能放紅色箭頭的位置，離開外while迴圈，
				
				根據2.，要釋放使用者的虛擬位址點陣圖所用的分頁"群"，
				(release_thread->userprog_vaddr.vaddr_bitmap.btmp_bytes_len) / PG_SIZE為該點陣圖所占用的分頁數量，把該值給bitmap_pg_cnt，
				進入mfree_page函數，把該點陣圖用的分頁"群"釋放掉
				
				(*接著應該要釋放核心的分頁目錄表，但是不知為何書上沒做)，
				
				當初創建程序時，是沒有掛上任何已開啟的檔案的，但是要結束掉程序時，會有檔案掛在PCB上，
				現在要把上面掛的檔案都關閉一次，
				把fd_idx設為3，此為X值，因為前3個是"標準XX"，
				進入while迴圈，把release_thread->fd_table[X]不為-1的檔案都關閉，
				
				離開release_prog_resource函數，
				
			回到sys_exit函數，現在要確認傳進來的程序的父程序是不是在TASK_WAITING的狀態，是的話要把父程序喚醒，
			首先要得到父程序(執行緒)的基底虛擬位址，作法為進入pid2thread函數，傳入child_thread->parent_pid，

/thread.c
				pid2thread函數內，用list_traversal遍歷所有隊列(all_list)，
				期間不斷用pid_check函數找出pid為父程序編號的程序，然後回傳all_list_tag，接著把all_list_tag賦予pelem，
				用elem2entry把pelem轉換為程序(執行緒)的基底虛擬位址，把該值賦予thread，回傳thread，
				
			回到sys_exit函數，把pid2thread函數的回傳值給parent_thread，
			若parent_thread->status為TASK_WAITING，則用thread_unblock把parent_thread喚醒，
			
			現在子程序(目前狀況應該為孫)正式結束，用thread_block把自己block住，使子程序不會再往下執行並交棒出去，

/shell.c			
=======>如果有找到檔案(資料夾)，進入execv函數，傳入argv[0]、argv，

/wait_exit.c
			execv函數內，設置uint32_t argc = 0，用while迴圈算argv內有多少參數，每迴圈一次就argc++，加完後就是參數個數，
			進入load函數，傳入path(argv[0]變的，內為欲操作的相對路徑轉絕對路徑後再去除".."和"."的結果)，
				
				load函數內，設置struct Elf32_Ehdr elf_header和struct Elf32_Phdr prog_header，此為elf結構和prog結構的C語言版，
				先用memset把elf_header清0，然後sys_open傳進來的pathname，把檔案的X值賦予fd，失敗則回傳-1，

				現在開始用sys_read把fd的elf的內容讀到elf_header內，
				若回傳的讀取大小與elf_header不一致，表示讀取失敗，要把ret設為-1，然後goto done，
				
				現在開始校驗elf結構，
				memcmp(elf_header.e_ident, "\177ELF\1\1\1", 7) <===elf_header.e_ident為魔術參數，為固定值，
				""內加入\x表示真實數字的16進位格式，而\表示真實數字的8進位格式，
				\x7f為16進位，等於8進位的\177，不寫\x7f的原因是怕編譯器會把ELF的也視為真實數字的一部份，所以故意寫成8進位，
				elf_header.e_type 		<===== 該值應為2，此為目的檔案型態，2表示ET_EXEC，
				elf_header.e_machine 	<===== 該值應為3，此為系統結構，3表示EM_386，
				elf_header.e_version 	<===== 該值應為1，此為版本資訊，
				elf_header.e_phnum 		<===== 該值不應超過1024，此為段的個數，
				elf_header.e_phentsize 	<===== 該值應等於struct Elf32_Phdr的大小，
				如果以上任何一個不通過，要把ret設為-1，然後goto done，
				
				設置Elf32_Off prog_header_offset = elf_header.e_phoff，此為"程式"頭的起始位址，
				設置Elf32_Half prog_header_size = elf_header.e_phentsize，此為"程式"頭的大小，
			
				設置unit32_t prog_idx = 0，然後進入while迴圈，
				在迴圈內，先用memset把prog_header清0，
				然後用sys_lseek把fd檔案內的操作位置設定在prog_header_offset，
				接著用sys_read把fd檔案的內容從操作位置開始讀prog_header_size的大小到prog_header，失敗的話把ret設為-1，然後goto done，
				
				檢查prog_header.p_type，若為PT_LOAD，表示"可載入之段"，
				於是進入segment_load函數，傳入fd、prog_header.p_offset、prog_header.p_filesz、prog_header.p_vaddr
				分別為:檔案描述符號、段在檔案中的位元組偏移量、段大小、段被載入到的虛擬位址，				
				
					segment_load函數內，先把vaddr跟0xfffff000作and，此結果為vaddr位址所在的頁框(頁的基底虛擬位址)，
					把該值賦予vaddr_first_page，
					再把vaddr跟0x00000fff作and，然後用PG_SIZE減掉該值，此為vaddr在分頁內"剩餘的大小"，
					把該值賦予size_in_first_page，
					
					設置occupy_pages = 0，
					==>如果filesz大於size_in_first_page，表示一個分頁內容納不下該檔案，
					設置uint32_t left_size = filesz - size_in_first_page，
					此為原本檔案扣掉在第一個分頁置占用的大小後所剩餘的大小，
					把left_size向上取整除以PG_SIZE後，加1(第1個分頁)即為檔案所在用的分頁數，
					把該值賦予occupy_pages，
					==>如果filesz未大於size_in_first_page，表示一個分頁內就能容納該檔案，
					直接把1賦予occupy_pages，即只占用第1個分頁，
					
					現在開始檢查以vaddr為起始的該檔案所占用的occupy_pages個分頁有沒有都被分配了，
					沒有的話要用get_a_page函數為其分配，判斷分頁有沒有被分配的方式為判斷紅色和黑色箭頭存不存在，
					
					設置page_idx = 0，
					設置vaddr_page = vaddr_first_page，
					進入while迴圈，
					先用pde_ptr取得vaddr_page的紅色箭頭的存放位址，
					再用pte_ptr取得vaddr_page的黑色箭頭的存放位址，
					
					如果紅色箭頭不存在或者黑色箭頭不存在，
					就進入get_a_page函數用vaddr_page要一個分頁，失敗則回傳false，
					(紅色箭頭的判斷須在黑色箭頭判斷之前，否則若紅色箭頭不在，黑色箭頭存放位址pte_ptr是不可預期的，
					拿去作and可能會出事，所以紅色箭頭要先判斷)，
					如果紅色箭頭和黑色箭頭都存在，表示vaddr_page所屬的分頁已經存在，
					則不用get_a_page，直接繼續下一步驟，
					
					現在開始把檔案內的程式讀到該程式應該要擺的位址，
					把vaddr_page加上PG_SIZE把vaddr_page設為下一分頁的虛擬基底位址，
					然後把page_idx++，繼續下一迴圈直到page_idx等於occupy_pages為止，
					
					把檔案內的操作位置用sys_lseek函數設為offset，此為欲執行程式在"檔案內"真正開始的位置，
					用sys_read函數把fd檔案內的內容讀filesz的大小到vaddr，vaddr為該程式真正應該要被擺放的位置，
					
					回傳true，
					
				回到load函數，若segment_load函數回傳flase，則goto done，
				
				把prog_header_offset加上elf_header.e_phentsize，這樣prog_header_offset就變成下一個程式頭的偏移了，
				prog_idx++，繼續下一迴圈，直到prog_idx等於elf_header.e_phnum(段的個數)為止，
				
				ret設為elf_header.e_entry，此為程式"真正執行"的起始位址(被複製到prog_header.p_vaddr的程式可能包含"純資料"的部分)
				
				進入done，把fd檔案sys_close掉，回傳ret，
				
			回到sys_execv函數，把load函數回傳的 程式"真正執行"的起始位址 給entry_point，
			如果entry_point的值為-1，表示失敗，回傳-1，
			
			用running_thread獲取當前程序(執行緒)的基底虛擬位址，然後賦予struct task_struct* cur，
			把cur->name設為傳進來的path，
			把cur + PG_SIZE - sizeof(struct intr_stack)賦予struct intr_stack* intr_0_stack，
			因為指標不能強制轉換成另一個指標，所以要先強制轉換成一般整數再轉換成另一個指標，
			目前intr_0_stack的位置:
			
			##############################################################################################
			##	struct thread_stack {                                          							##
			##		uint32_t ebp;							         									##
			##		uint32_t ebx;                                              							##
			##		uint32_t edi;                                              							##
			##		uint32_t esi;                                              							##
			##	                                                               							##
			##		void (*eip) (thread_func* func, void* func_arg);           							##
			##		void (*unused_retaddr);                                    							##
			##		thread_func* function;	由Kernel_thread所调用的函数名，類型為void (*function)(void*)##
			##		void* func_arg;    	  	由Kernel_thread所调用的函数所需的参数						##
			##	};                                                              						##
			##############################################################################################
							!!!thread_stack緊接在intr_stack的上面(低地址處)!!!
			##############################################################################################
			##	struct intr_stack {                                                           			##
			##		uint32_t vec_no; <---低地址  	<=== !!!intr_0_stack!!! 							##
			##		uint32_t edi;                                                                 		##
			##		uint32_t esi;                                                                 		##
			##		uint32_t ebp;                                                                 		##
			##		uint32_t esp_dummy;	 虽然pushad把esp也压入,但esp是不断变化的,所以会被popad忽略		##
			##		uint32_t ebx;                                                                 		##
			##		uint32_t edx;                                                                 		##
			##		uint32_t ecx;                                                                 		##
			##		uint32_t eax;                                                                 		##
			##		uint32_t gs;                                                                  		##
			##		uint32_t fs;                                                                  		##
			##		uint32_t es;                                                                  		##
			##		uint32_t ds;                                                                  		##
			##		                                                                              		##
			##		以下由cpu从低特权级进入高特权级时压入                                         		##
			##		uint32_t err_code;	err_code会被压入在eip之后                                 		##
			##		void (*eip) (void);                                                           		##
			##		uint32_t cs;                                                                  		##
			##		uint32_t eflags;                                                              		##
			##		void* esp;                                                                    		##
			##		uint32_t ss;     <---高地址                                                			##
			##	};                                                                            			##
			##############################################################################################			

			把intr_0_stack->ebx設為(int32_t)argv，ebx擺的是argv的位址，
			intr_0_stack->ecx = argc，ecx擺的是參數個數，
			intr_0_stack->eip = (void*)entry_point，此為程式"真正執行"的起始位址，
			intr_0_stack->esp = (void*)0xc0000000，此為使用者的最高堆疊位址
			(使用者堆疊所使用的分頁已經在父程序根據4.創建了，也就是使用者用的分頁目錄表也已經填了，
			然後也用fork複製給子程序了，所以0xc0000000可以成功映射到最高堆疊位址)，

			接著把intr_0_stack賦予esp，最後jmp到intr_exit，
			直接去執行程式，一去不復返了，最後的return 0也只是配合編譯器的語法而已，
			
/start.S
現在開始正式執行cat程式，先進入_start，存入argv和argc，然後call main
	
/main.c
	進入main函數，

	若參數個數不等於2，進入exit函數，傳入-2，直接結束cat程式的運行，
	
	設置buf_size為1024、abs_path[512]為{0}，
	malloc buf_size 的記憶體，把地址賦予buf，失敗則回傳-1，
	
	cat程式的目的在於把某路徑對應到的檔案的內容讀到螢幕上，
	若輸入的路徑是沒有"/"且非".."或"."，則默認該路徑為"當前資料夾/輸入的路徑"，
	例如說輸入的路徑為kimweng01，且現在在的位置為c，則默認該路徑為/a/b/c/kimweng01，要讀位於/a/b/c之kimweng01檔案，
	
	首先判斷輸入的路徑是不是絕對路徑，
	==>如果不是絕對路徑，則先用getcwd取得當前位置，
	接著接入"/"，然後把輸入的路徑接入當前位置之路徑，
	例如輸入的路徑為../../KIM，且當前位於d之資料夾內工作，則先藉由getcwd取得當前位置為/a/b/c/d，
	接著接入"/"，再把../../KIM接入變為/a/b/c/d../../KIM，
	若輸入的路徑為WENG，，且當前位於c之資料夾內工作，則最後的路徑變為/a/b/c/WENG，
	==>如果是絕對路徑，則把輸入的路徑接入空的abs_path，形同則直接採用輸入的絕對路徑，

	用open函數把路徑為abs_path的檔案打開，把檔案的X值賦予fd，失敗則回傳-1，
	
	設置int_read_byte = 0，
	
	進入while迴圈，開始讀編號為X值的檔案，讀到buf內，讀的大小為buf_size，
	讀完了以後藉由write函數把buf的內容write到螢幕上，
	
	繼續下一迴圈，直到read函數把資料讀完，然後因為讀不到資料而回傳-1，
	也因此會進入if(read_bytes == -1)內的break跳出迴圈，
	
	把buf free掉，把fd之檔案close掉，回傳66，
	
/start.S
回到_start，main函數的回傳值在eax內，把eax壓入棧作為exit函數的參數，
call exit，在sys_exit函數內會把自己的父親喚醒並把自己block住，

<管線統整>

/shell.c
	在my_shell函數中，
	若輸入的指令有'|'，表示多重管道操作，
	
	則程式進入到if(pipe_symbol)，
	設置int32_t fd[2] = {-1}，{-1}表示fd內兩個元素都是-1，
	
	進入pipe函數，傳入fd，
	
/pipe.c
		sys_pipe函數內，
		用get_free_slot_in_global函數獲得一個檔案的"編號"，把獲得的編號賦予int32_t global_fd，
		
		用get_kernel_pages申請一個核心分頁，把該分頁的虛擬基底位址賦予gfile_table[global_fd].fd_inode，
		若失敗則回傳-1(*應該先檢查有無申請成功，不應該放在ioqueue_init後面才檢查?)，
		
		進入ioqueue_init函數，傳入(struct ioqueue*)file_table[global_fd].fd_inode，目的為初始化環形緩衝區，
	
		設置file_table[global_fd].fd_flag為PIPE_FLAG，
		把file_table[global_fd].fd_pos設為2，
		
		把global_fd傳入pcb_fd_install函數內，得到第1個X值，把該值賦予pipefd[0]，
		把global_fd傳入pcb_fd_install函數內，得到第2個X值，把該值賦予pipefd[1]，
		
		回傳0，
		
		###以上可以分析成:
		###	創建管線的方式為，申請一頁大小的記憶體，然後把地址賦予file_table內其中一個struct file的fd_inode，
		###	此時file_table.fd_inode可以說是指向"假的"inode，該inode結構其實是"管線"，
		###	然後要為該"特殊"檔案設置兩個X值，一個是輸出，另一個是輸入，
		###	創建檔案可視為"另類的"開啟檔案，因為有兩個X值，所以可以視為被開啟"兩次"，
		###	所以前面要設置file_table[global_fd].fd_pos為2，
		###	由此可見管線這個"特殊檔案"使用了1個"檔案編號"，但使用了2個X值(分別用於輸入和輸出)。

/shell.c	
	回到my_shell函數，現在管線已經創建完成，接著要重新導向，
	所以要進入到fd_redirect函數，傳入1和fd[1]，
	fd[1]內存著管線這個特殊檔案的"輸出用"X值，
	###	所以把1和fd[1]傳入fd_redirect函數的意思是:
	###	把X對應到的 cur->fd_table[X]內的內容(內存的是檔案的"編號") 也賦予cur->fd_table[1]，

/pipe.c
		fd_redirect函數內，
		先用running_thread獲得當前程序(執行緒)的基底位址，
		
		==>如果new_local_fd小於3，直接把new_local_fd賦予cur->fd_table[1]，
		因為cur->fd_table[0]內存的檔案編號一定等於0、
		cur->fd_table[1]內存的檔案編號一定等於1、
		cur->fd_table[2]內存的檔案編號一定等於2，
		==>如果new_local_fd大於等於3，
		先把X對應到的 cur->fd_table[X]內的內容(內存的是檔案的"編號") 賦予unit32_t new_global_fd，
		然後把new_global_fd賦予cur->fd_table[1]，

/shell.c
	回到my_shell函數，
	設置char* each_cmd = cmd_line，cmd_line是輸入的指令的第一個字的位址，each_cmd待會會一直增加以掃描輸入的指令，
	
	現在處理第一個命令，
	用strchr獲得第1個"/"的位址，把該位址賦予pipe_symbol，
	把*pipe_symbol設為0，變成"ls -l0../cat|/cat"，這樣cmd_parse函數就會從each_cmd掃到"0"的位置為止，
	
	現在開始填argc和argv，先把argc初始化為-1，
	然後進入cmd_parse函數，傳入each_cmd、argv和' '，要告訴cmd_parse函數要以空白鍵為分割符號，
		
		目前是處理ls -l<===這個指令，所以在cmd_parse函數內要把ls填入argv[0]、-l填入argv[1]，

/shell.c		
	回到my_shell函數，
	(*不用檢查argc是不是為-1?)
	進入cmd_execute函數，傳入argc和argv，開始做輸入的指令要做的事，即做ls -l這個指令要做的事，
	
----------------------------------------------------
/fs.c
		ls -l這個指令會把當前操作位置內的所有檔案或資料夾的資訊都輸出到螢幕上，
		但由於現在是管線操作，所以輸出的資訊會被重新導向到管線中，
		
		ls指令會利用printf來輸出資訊，printf內含有write，所以會進入到sys_write函數中，
		
		標準輸出到螢幕 或者 把資料寫入某個檔案 皆有可能被重新導向到緩衝區，
		所以要把if(is_pipe(fd))寫在else if(fd == stdout_no)和else的前面
								   ^~~~新加的
		( *書上好像寫得太複雜了，寫了兩個if(is_pipe(fd)) )，
		
		進入到is_pipe函數判斷傳進來的X值對應到的檔案(write出去的目標)是不是管線，
		
/pipe.c		
			is_pipe函數內，藉由fd_local2global獲得該X值對應到的檔案編號，賦予global_fd
			(*不直接傳入global_fd就好?)，
			若file_table[global_fd].fd_flag為PIPE_FLAG，回傳true，現在理論上會回傳true，
			
/fs.c
		回到sys_write函數，因為是管線，所以會進入if(is_pipe(fd))，
		進入pipe_write函數，傳入fd(X值)、buf(要write的內容的基底位址)、count(要write的位元組數)，
		
/pipe.c
			pipe_write函數內，
			先設置unit32_t bytes_write並初始化為0，bytes_write會記錄已write的位元組數
			再用fd_local2global獲得X值對應到的檔案編號，
			把file_table[global_fd].fd_inode賦予ioq，即把管線的位址賦予ioq，
			
			進入ioq_length函數，獲得管線內的資料長度，
			
/ioqueue.c
				ioq_length函數內，該函數的目的是計算緩衝區(管線算是一種特殊的檔案，也是緩衝區)內資料的長度，
				所謂的資料長度，指的是在緩衝區(管線)內還沒被消費的資料長度，
				==>如果ioq->head大於等於ioq->tail，則資料長度為ioq->head - ioq->tail，把該值賦予len
				(創建管線時會在ioqueue_init內先把ioq->head和ioq->tail都初始化為0)，
				==>如果ioq->head小於ioq->tail，表示ioq->head已經超過管線大小並"回繞"了，
				則資料長度為bufsize-(ioq->tail - ioq->head)，把該值賦予len
				(bufsize為2048，定義在ioqueue.h)，
				
				回傳管線內的資料長度，
				
/pipe.c	
			回到pipe_write函數，把bufsize(bufsize為2048，定義在ioqueue.h)減去管線內的資料長度並賦予ioq_left，該值為管線內 "剩餘"可放資料的長度，
			若"剩餘"可放資料的長度(ioq_left)大於要write的位元組數(count)，則把count賦予size，表示直接寫入count位元組的資料到管線即可，
			否則把ioq_left賦予size，表示只寫入ioq_left位元組的資料到管線，
			
			進入while迴圈，不斷的呼叫ioq_putchar函數，
			期間bytes_write(記錄已write的位元組數)不斷++ 以及 buffer(要write的內容的基底位址)不斷++，
			迴圈到buffer等於size為止，
			
			回傳bytes_write，
			
			###需要注意:
			###	假如輸入的指令為A|B|C，該指令為"一個"程序，
			###	如果A指令要pipe_write到管線內的資料太多，導致當前程序會被block，
			###	但是A放進管線內的資料只會被B讀取，由於當前程序被block了，
			###	也就是沒有人會去讀(消費)管線內的資料，
			###	這樣會造成永久block，所以在此限制 寫入管線的最大資料量 一定要少於 管線內剩餘可放資料的長度，
			###	
			###	(*由於判斷管線(緩衝區)為滿的條件為ioq->head的"下一個"位置是不是ioq->tail，
			###	也就是說管線內最多只能放ioq_left-1的資料量，也就是說當你正要放第ioq_left的資料時就會被block
			###	所以若 剩餘可放資料的長度(ioq_left)小於等於要write的位元組數(count)時，應該把ioq_left-1賦予size才對?)
			
/fs.c
		回到sys_write函數，至此ls -l指令完成一次資料寫入管線的動作，
----------------------------------------------------

/shell.c
	ls -l執行完後，就會回到my_shell函數，
	
	接著要處理第二個指令，把pipe_symbol + 1賦予each_cmd，
	此時each_cmd會指向"|"的下一個位置，目前狀況為:
	       v each_cmd
	"ls -l0../cat|/cat"
	      ^pipe_symbol(被賦值後立刻把指向的位置賦予'0')
	
	接著要準備執行../cat，目前是在/dir，../cat意即 執行位於../cat這個位置的檔案內的程式，
	但是該指令只有../cat一個參數而已，沒有說要去讀哪裡的檔案，
	所以../cat會默認去讀"理論上應該要輸入到螢幕上的內容"，即要從 標準輸入 去讀資料，
	然而，由於是管線，ls -l指令原本要輸出到螢幕的資訊要藉由管線轉交給cat，
	也就是"理論上應該要輸入到螢幕上的內容"現在已經存放到管線裡了，
	所以cat現在應該要去管線讀內容，所以要從"標準輸入"讀內容 改成(重新導向) 從"管線"讀內容，
	所以要進入到fd_redirect函數，傳入0和fd[0]，
	fd[0]內存著管線這個特殊檔案的"輸入用"X值，
	###	所以把0和fd[0]傳入fd_redirect函數的意思是:
	###	把X對應到的 cur->fd_table[X]內的內容(內存的是檔案的"編號") 也賦予cur->fd_table[0]，
	
	現在進入while迴圈，開始處理第二個(中間的指令)，
	因為中間的指令可能有很多個，所以要進入到while迴圈，
	其間不斷調用strchr，從each_cmd開始搜尋下一個'|'，把回傳地址賦予pipe_symbol，
	在while迴圈內不斷的做跟第一個指令一樣的事情，不過涉及到read的部分都會去管線讀資料，
	
----------------------------------------------------
/fs.c
		../cat指令如果不帶其他參數的話，會從鍵盤緩衝區標準輸入到自己的buf，
		但由於現在是管線操作，所以讀資訊的位置會被重新導向到管線中，
		
		cat指令會利用read函數來讀取資訊，所以會進入到sys_read函數中，
		
		從鍵盤緩衝區標準輸入或者去某個檔案讀去資料皆有可能被重新導向到緩衝區，
		所以要把if(is_pipe(fd))寫在else if(fd == stdin_out)和else的前面
								   ^~~~新加的
		( *書上好像寫得太複雜了，寫了兩個if(is_pipe(fd)) )，
		
		進入到is_pipe函數判斷傳進來的X值對應到的檔案(被read的對象)是不是管線，
		由於是管線，所以會進入if(is_pipe(fd))，
		進入pipe_read函數，傳入fd(X值)、buf(read的內容要存放的的基底位址)、count(要read的位元組數)，
		
/pipe.c
			pipe_read函數內，
			先設置unit32_t bytes_read並初始化為0，bytes_read會記錄已read的位元組數
			再用fd_local2global獲得X值對應到的檔案編號，
			把file_table[global_fd].fd_inode賦予ioq，即把管線的位址賦予ioq，
			
			進入ioq_length函數，以獲得管線內的資料長度，該值可視為 管線內還可以再讀的資料長度，把該值賦予ioq_len，
			若管線內還可以再讀的資料長度(ioq_len)大於要read的位元組數(count)，則把count賦予size，表示直接寫入count位元組的資料到管線即可，
			否則把ioq_len賦予size，表示只寫入ioq_len位元組的資料到管線，
			
			進入while迴圈，不斷的呼叫ioq_getchar函數，
			期間bytes_read(記錄已write的位元組數)不斷++ 以及 buffer(read的內容要存放的的基底位址)不斷++，
			迴圈到buffer等於size為止，
			
			回傳bytes_read，
			
			###需要注意:
			###	假如輸入的指令為A|B|C，該指令為"一個"程序，
			###	如果B指令想要從管線pipe_read的資料太多，導致當前程序會被block，直到管線內再度被放新的資料，
			###	但是能放資料到管線內的只有A、B、C，皆屬於同一個程序，由於當前程序被block了，
			###	也就是沒有人會去生產資料並放入管線內，
			###	這樣會造成永久block，所以在此限制 讀取管線的最大資料量 一定要少於等於 管線內還可以再讀的資料長度，
			
/fs.c
		回到sys_read函數，至此../cat指令完成一次資料寫入管線的動作，
----------------------------------------------------

/shell.c
	回到my_shell函數，繼續處理中間的指令，繼續while迴圈下去，直到strchr搜不到'|'為止，此時現在的狀況應該是這樣:
				  v each_cmd
	"ls -l0../cat0/cat"
	             ^pipe_symbol(被賦值後立刻把指向的位置賦予'0')

	現在要處理最後一個指令，由於最後的結果不能轉交給下一指令了，要直接"標準輸出"到螢幕上，
	所以要進入fd_redirect把1填入cur->fd_table[1]，也就是把"檔案編號1"填入cur->fd_table[1]，
	把cur->fd_table[1]回復成最原始的狀態，這樣最後輸出的結果就會正常的"標準輸出"到螢幕上，
	
	接著做跟第一個指令一樣的事情，處理最後一個指令，
	
	至此全部結束，進入fd_redirect把0填入cur->fd_table[0]，也就是把"檔案編號0"填入cur->fd_table[0]，
	所以要進入fd_redirect把0填入cur->fd_table[0]，也就是把"檔案編號0"填入cur->fd_table[0]，
	把cur->fd_table[0]回復成最原始的狀態，這樣最後指令就可以正常的從鍵盤緩衝區"標準輸入(sys_read)"，
	
	接著要用close關閉 fd[0] 和 fd[1]，所以進入到close函數，先傳入fd[0]，

/fs.c
		sys_close函數內，
		fd[0]內存著管線這個特殊檔案的"輸入用"X值，
		這個X值是藉由pcb_fd_install獲得的，所以這個X值一定大於2，所以會進入if(fd>2)，
		
		藉由fd_local2global獲得該X值對應到的檔案編號，賦予global_fd，
		進入is_pipe函數，檢查X值對應到的檔案是不是管線，
		此時is_pipe函數回傳true，所以會進入if(is_pipe)，
		
		把file_table[global_fd].fd_pos減掉一次1，現在file_table[global_fd].fd_pos應該會從2變為1，
		由於還沒完全減到0，所以不會進入到if(--file_table[global_fd] == 0)，
		把ret設為0，
		
		把running_thread()->fd_table[fd]還原為-1，使該X值可用，		
		回傳ret，
		
/shell.c
	回到my_shell函數，接著再進入到close函數，此次傳入fd[1]，
	
/fs.c
		sys_close函數，本次做的事情跟close(fd[0])時一樣，直到把file_table[global_fd].fd_pos減掉一次1這個步驟，
		由於現在file_table[global_fd].fd_pos會從1變為0，所以會進入到if(--file_table[global_fd] == 0)，
		
		用mfree_page把file_table[global_fd].fd_inode釋放掉
		(file_table.fd_inode是指向"假的"inode，該inode結構其實是"管線"，佔據一個分頁)，
		把file_table[global_fd]].fd_inode恢復為NULL，
		
		剩下的步驟都與close(fd[0])時一樣，
		
		###由以上可知:
		###	由於管線的構造含有一個檔案編號+兩個X值，
		###	所以close(fd[0])時先釋放掉一個X值，
		###	然後close(fd[1])時再釋放掉一個X值，並把檔案編號給釋放掉，
		###	這樣可以完整地把管線給釋放掉，不會有重複釋放的情況。
		
		
<內建參數介紹>
/buildin_cmd.c

###需要注意:
###	有些函數會有char** argv UNUSED，定義在global.h裡面，
###	內容為#define UNUSED __attribute__ ((unused))，
###	這樣做的目的是避免gcc因為你在函數內用到這個參數而給警告。


=====>pwd(print work directory)指令目的為印出當前工作目錄<=====
檢查argc是不是為1，否則printf("pwd: no argument support!\n")並回傳NULL
進入getcwd函數，傳入final_path(全域變數)和最大路徑長度，獲得當前工作目錄的絕對路徑並記錄在final_path中，
printf("%s\n", final_path)，
若getcwd失敗，則printf("pwd: get current work directory failed.\n")。


---------------------------------------------------------------------------------------------------------------------
=====>cd(change directory)指令目的為修改當前工作目錄<=====

檢查argc有沒有小於等於2，否則printf("cd: only support 1 argument!\n")並回傳NULL，
==>如果argc等於1，表示只輸入cd而未輸入參數，則直接把當前工作路徑修改成根目錄，
先final_path[0] = '/'，再final_path[1] = 0，
==>如果argc不等於1，表示有第二個參數，該參數為 當前要被修改成的目標路徑 ，
進入make_clear_abs_path函數，把目標路徑修改成絕對路徑並存在final_path中，

現在開始正式修改當前工作目錄，進入chdir函數，傳入被填入絕對路徑的final_path，
若回傳值為-1，表示修改失敗，printf("cd: no such directory %s\n", final_path)並回傳NULL，

修改結束，回傳final_path，

###需要注意:
###	cd指令涉及到當前工作目錄的改變，所以回到cmd_execute函數時，
###	要先用memset把cwd_cache歸0，然後用strcpy把final_path複製到cwd_cache，
###	這樣print_prompt才會輸出當前的工作目錄，即"[rabbit@localhost %s]$ "
###																 ^~HERE!!!


---------------------------------------------------------------------------------------------------------------------
=====>ls(list)指令目的為列出某個路徑對應到的檔案(包括目錄的資訊)<=====

設置char* pathname初始值為NULL，
設置struct stat file_stat，
用memset把file_stat都清0，
設置bool long_info初始值為false，long_info表示要列出詳細資訊還是精簡資訊，
設置uint32_t arg_path_nr初始值為0，arg_path_nr表示掃到的參數為"路徑"的個數，
設置uint32_t arg_idx初始值為1，此為argv[X]的X，因為argv[0]為ls，所以設為1的目的是要跨過，

進入while迴圈，
==>如果argv[arg_idx][0]等於'-'(arg_idx目前為1)，表示輸入的指令為ls -Y形式，所以現在要判斷Y為什麼，
	==>如果是ls -l，表示要列出詳細資訊，所以要賦予true給long_info，-l的意思為long，
	==>如果是ls -h，表示要列出關於ls指令的help，
	printf ls指令可以多輸入哪些-Y，分別可以幹嘛，
	==>如果是ls -Y的Y是其他值，表示輸入一個未知的選項，
	因為當前的ls只支援-l和-h兩種選項，所以輸出錯誤資訊並回傳，
==>如果argv[arg_idx][0]不等於'-'(arg_idx目前為1)，表示目前掃到的參數為"路徑"，
	==>檢查arg_path_nr是否為0，如果為0，表示目前未掃到 為路徑的參數
	把argv[arg_idx]賦予pathname，然後把arg_path_nr設為1，表示目前已掃到1個為"路徑"的參數，
	==>如果arg_path_nr不為為0，表示目前已經掃到第2個為"路徑"的參數，
	由於ls指令為列出 "某一個"路徑 對應到的檔案(包括目錄)的內容，你如果輸入兩個以上為"路徑"的參數的話會"打架"，
	所以在此printf("ls: only support one path\n")並回傳，
目前已經掃完ls指令的第2個參數(第1個參數為"ls")，arg_idx++並繼續下一迴圈以掃描下一個參數，直到arg_idx等於argc為止，

目前已經掃完ls完整的指令，現在要把"路徑"存入pathname，
==>如果pathname為NULL，表示只輸入了ls或ls -l，沒有輸入"路徑"，所以默認當前工作的路徑的絕對路徑為參數，
所以現在要進入getcwd函數獲得當前工作的絕對路徑並存入final_path，
	==>如果成功則把final_path賦予pathname，
	==>如果getcwd失敗則printf("ls: getcwd for default path failed\n")並返回，
==>如果pathname不為NULL，表示有輸入"路徑"，則採用這個"路徑"，
只不過這個路徑有可能是相對路徑，需要送入make_clear_abs_path把相對路徑轉換成絕對路徑，並存於final_path，
然後把final_path賦予pathname，

現在pathname已經被賦予要被看的普通檔案或資料夾的路徑了，被對應到的 普通檔案或資料夾 存不存在，
先用stat函數獲得pathname對應到的 普通檔案或資料夾的 狀態，
若回傳結果為-1，表示該路徑 對應到的 普通檔案或資料夾 不存在，printf錯誤資訊並返回，

若程式能運行到這裡，表示該路徑 對應到的 普通檔案或資料夾 確實存在，現在開始正式準備輸出 被對應到的 普通檔案或資料夾內的內容，
==>如果file_stat.st_filetype為目錄，表示你現在輸出某個"目錄(資料夾)"的資訊，
先用opendir打開pathname對應到的目錄(資料夾)，然後把該目錄的基底地址給struct dir* dir，
設置struct dir_entry* dir_e，初始化其值為NULL，
設置char sub_pathname[MAX_PATH_LEN]並初始化為{0}，{0}的意思是所有的sub_pathname[X]內皆為'0'，
設置uint32_t pathname_len，其值為pathname的長度，
設置uint32_t last_char_idx，其值為pathname_len - 1，即改成從0開始算，

現在用m emcpy把pathname接進sub_pathname，長度為pathname_len，
若sub_pathname[last_char_idx]不等於'/'，表示當初輸入的路徑不是"根目錄"，需要把sub_pathname[pathname_len]賦予'/'，
多接一個'/'在sub_pathname後面，等於路徑變長了，即多一個字元，所以要pathname_len++，
用rewinddir把dir的dir_pos歸0，

	==>如果long_info等於1，表示你有輸入-l，要輸出詳細資訊，
	設置char ftype，
	printf("total: %d\n", file_stat.st_size)，即輸出 輸入的路徑 對應到的 普通檔案或資料夾的 大小，
	
	進入while迴圈，不斷的用readdir讀取dir，
	每進入一次readdir函數就會讀取dir內下一個還沒被讀取的"目錄項(圖示)"，
	直到dir內的所有"圖示"都被讀過為止，此時readdir函數就會回傳NULL，使程式離開while迴圈，
	先默認ftype為'd'，代表目前讀到的"目錄項(圖示)"是目錄(資料夾)，
	若dir_e->f_type為普通檔案則把ftype改成'-'，
	
	把sub_pathname[pathname_len]設為0，例如:
	假設目前sub_pathname是"/"，則sub_pathname[pathname_len]設為0後為"/0"，
							^sub_pathname[pathname_len]
						   ^sub_pathname[0]
						   
	假設目前sub_pathname是"/a/b/c/"，則sub_pathname[pathname_len]設為0後為"/a/b/c/0"，
						          ^sub_pathname[pathname_len]
                           ^sub_pathname[0]
						   
	把dir_e->filename接進sub_pathname，例如dir_e->filename為d，則:
	假設目前sub_pathname是"/0"，則接完變"/d"，
	假設目前sub_pathname是"/a/b/c/0"，則接完變"/a/b/c/d"，
	
	用memset把file_stat清0添保險，
	然後用stat函數獲得sub_pathname對應到的 普通檔案或資料夾的 狀態，
	若 回傳結果為-1，表示該路徑 對應到的 普通檔案或資料夾 不存在，printf錯誤資訊並返回
	(應該不可能，除非你sys_mkdir函數或sys_readdir函數內的程式哪裡寫錯)，
	此時file_stat結構的內容已經從 輸入的路徑對應到的資料夾的資訊 改成資料夾內目錄項(圖示)的資訊了，			<==================重要!!!
	
	若程式能運行到這裡，表示該路徑 對應到的 普通檔案或資料夾 確實存在，
	printf目錄(資料夾)內目錄項(圖示)的詳細資訊，包括 ftype, dir_e->i_no, file_stat.st_size, dir_e->filename，
	
	printf("\n")換行，繼續下一迴圈，用readdir讀取dir內下一個還沒被讀取的"目錄項(圖示)"，


	==>如果long_info不等於1，表示輸入的指令未含-l，
	一樣進入while迴圈，不斷的用readdir讀取dir，
	每進入一次readdir函數就會讀取dir內下一個還沒被讀取的"目錄項(圖示)"，
	直到dir內的所有"圖示"都被讀過為止，此時readdir函數就會回傳NULL，使程式離開while迴圈，
	
	由於指令未含-l，只要printf目錄(資料夾)內目錄項(圖示)的簡單資訊就好，即只輸出dir_e->filename，
	printf("\n")換行，繼續下一迴圈，用readdir讀取dir內下一個還沒被讀取的"目錄項(圖示)"，
	
	現在資訊已經輸出完畢，用closedir關閉dir，
	
==>如果file_stat.st_filetype為普通檔案，則輸出該檔案的資訊，
由於普通檔案不會像資料夾一樣點開後裡面擺很多目錄項(圖示)，
所以只要輸出該普通檔案的資訊就好，

	==>如果long_info等於1，表示你有輸入-l，要輸出詳細資訊，
	printf傳進來的路徑 對應到的檔案的 詳細資訊，包括file_stat.st_ino, file_stat.st_size, pathname，
	
	==>如果long_info不等於1，表示輸入的指令未含-l，
	由於指令未含-l，只要printf傳進來的路徑 對應到的檔案的 簡單資訊就好，即只輸出pathname。
	

---------------------------------------------------------------------------------------------------------------------
=====>ps(process status)指令目的為列出系統中當前運行的程序<=====

/buildin_cmd.c
檢查argc是不是為1，否則printf錯誤資訊並返回，
進入ps函數，
	
/thread.c
	sys_ps函數內，先設置char* ps_title = "PID            PPID           STAT           TICKS          COMMAND\n"，
	然後sys_write(stdout_no, ps_title, strlen(ps_title))，代表標準輸出ps_title到螢幕上，
	這個時候螢幕就會顯示"PID            PPID           STAT           TICKS          COMMAND\n"，
	接著藉由list_traversal函數遍歷所有隊列(all_list)，期間不斷的呼叫elem2thread函數，
	送入elem2thread函數內的兩個參數分別為all_list上其中一個執行緒(程序)的tag地址 和 "可作為"判斷條件用的arg，
	由於elem2thread函數的arg用不到，所以傳入list_traversal函數的最後一個參數就隨便寫一個0，
	該0傳入elem2thread函數內會被轉化成int arg UNUSED，
	
		elem2thread函數內，
		先用elem2entry把傳進來的執行緒(程序)的tag地址 轉化為 執行緒(程序)的基底虛擬位址，把該值賦予struct task_struct* pthread，
		設置char out_pad[16] = {0}，out_pad會送入pad_print函數作為buffer用，
		
		進入pad_print函數，傳入out_pad(作為buffer)、16(作為buffer的長度)、
		&pthread->pid(pthread的pid號的地址)、'd'(代表輸出的格式為10進位)，
		
			pad_print函數內，現在準備要輸出掛在all_list上的其中一個執行緒(程序)的資訊，
			該資訊每一個都要跟標題靠左對齊，例如:
			PID            PPID           STAT           TICKS          COMMAND
			4			   1			  RUNNING		 167			init	<=====HERE!!!
			所以不能簡單的printk，要先把要輸出的內容先用sprintf填入buf，再把剩餘的空間補空格，再write出去
			這樣輸出的結果就會向左對齊了，
			
			先用memset把buf都清0，
			然後設置uint8_t out_pad_0idx並初始化為0，out_pad_0idx用來存放輸到buf內的數值的長度，
			例如sprintf 7個長度的字元到buf內，sprintf就會回傳7，該值會賦予out_pad_0idx，從buf[out_pad_0idx]開始補空格進去，
			
			用switch判斷傳入的format為何，目前format為'd'，表示輸出十進位數字，
			*((int16_t*)ptr))--->表示把ptr(由&pthread->pid變成)強制轉化為型別長度為16的指標並轉化為該指標內的內容(即pthread->pid)，
			由於pad_print的參數ptr的型別是void*，所以在此要特別用強制轉換的方式把ptr設置為16位元長度的型別，
			由於前面寫的程式碼是把pthread->pid的型別設為16位元，所以switch"特別"弄一個選項來處理16位元的型別，
			所以在此"刻意"使'd'表示只能輸出16位元，這樣輸出到螢幕上的內容最多就只會是16位元，多出來的這一段處理是一般的printf沒有的，
			sprintf ptr((即pthread->pid))到buf，sprintf就會回傳sprintf到buf內的數值長度，該值會賦予out_pad_0idx，
			(*在此作者似乎少加一個break，所以結果會被下一個case覆蓋掉，所以特別設'd'處理16位元的pid號等於白做工?)
			
			現在進入while迴圈，從buf[out_pad_0idx]開始補空格進去，補到out_pad_0idx等於buf_len為止，
			
			最後sys_write buf內buf_len - 1長度的內容到螢幕上
			(*PID            PPID...
				 ^~~~~~~~~~~~書上的設計是空15位元，所以是sys_write buf_len - 1的位元長度到螢幕，
			為何不直接傳15到pad_print內就好?)
			
			離開pad_print函數，
			
		回到elem2thread_info函數，接著要輸出父程序的pid，
		==>如果pthread->parent_pid為-1(創建程序時會在init_thread函數內被初始化為-1)，表示該程序沒有父程序，
		pad_print(out_pad, 16, "NULL", 's')，因為是輸出"NULL"這個"字串"，所以要傳入's'，
		==>如果pthread->parent_pid不為-1，表示該程序有父程序，
		pad_print(out_pad, 16, &pthread->parent_pid, 'd')，因為是輸出"pthread->parent_pid"這個"數字"，所以要傳入'd'，
		
		接著要輸出程序的狀態，即輸出pthread->status，有5種被列舉的狀態，
		用switch判斷pthread->status為何，並用pad_print輸出到螢幕，
		例如case 0代表RUNNING，則用pad_print輸出"RUNNING"字串到螢幕，
		
		接著要輸出該程序的pthread->elapsed_ticks，此為該程序目前為止已經執行的tick數，
		直接pad_print pthread->elapsed_ticks到螢幕上，輸出的格式為'x'，代表要輸出16進位數字到螢幕上，
		
		因為已經準備要輸出最後一項資訊了，即後面有沒有空格都沒差，
		所以不用特別再進入pad_print函數去補空格了，直接sys_write就好，所以至此已經不會再進入到pad_print函數了，
		
		最後要輸出該程序的名字到螢幕，會把名字memcpy到out_pad中，
		現在out_pad還保留"pthread->elapsed_ticks加上空格"，在此要用memset清0，
		
		用ASSERT檢查pthread->name的長度有沒有小於17，
		然後用memcpy把pthread->name複製到out_pad內，再strcat一個換行符號"\n"，因為已經是最後一項了，所以要換行
		最後sys_write pthread->name到螢幕上，
		
		最後返回false，此處返回false是為了迎合主調函數list_traversal，只有回調函數返回false時才會繼續調用此函數，
		
	回到sys_ps函數，從sys_ps函數離開

/buildin_cmd.c
回到buildin_ps函數。
		
	
---------------------------------------------------------------------------------------------------------------------
=====>clear指令目的為清除螢幕<=====

/buildin_cmd.c
檢查argc是不是為1，否則printf錯誤資訊並返回，
進入clear函數，開始清屏，

/print.S
	cls_screen函數內(不知為何不是sys_clear，可能linux都習慣寫成cls_screen)，
	先清屏0，再把游標移到最左上角的位置，
	從cls_screen函數返回，
	
/buildin_cmd.c
回到buildin_clear函數。


---------------------------------------------------------------------------------------------------------------------
=====>mkdir(make directory)指令的目的為建立目錄<=====

該函數的輸入參數的數量一定要等於2，若不等於2，則輸出錯誤資訊並返回，
設置int32_t ret並初始化其值為-1，

用make_clear_abs_path把傳進來的路徑(argv[1])轉換為絕對路徑並存入final_path，
若final_path不是根目錄，則用mkdir函數建立目錄，傳入final_path，成功則把ret設為0，失敗則輸出錯誤資訊，
若final_path是根目錄，則無須理會，因為根目錄永遠存在，保持ret為-1，

回傳ret。


---------------------------------------------------------------------------------------------------------------------
=====>rmdir(remove directory)指令的目的為移除空目錄<=====

該函數的輸入參數的數量一定要等於2，若不等於2，則輸出錯誤資訊並返回，
設置int32_t ret並初始化其值為-1，

用make_clear_abs_path把傳進來的路徑(argv[1])轉換為絕對路徑並存入final_path，
若final_path不是根目錄，則用rmdir函數移除目錄，傳入final_path，成功則把ret設為0，失敗則輸出錯誤資訊，
若final_path是根目錄，則無須理會，因為根目錄永遠不能刪除，保持ret為-1，

回傳ret。


---------------------------------------------------------------------------------------------------------------------
=====>rm(remove)指令的目的為移除普通檔案<=====

該函數的輸入參數的數量一定要等於2，若不等於2，則輸出錯誤資訊並返回，
設置int32_t ret並初始化其值為-1，

用make_clear_abs_path把傳進來的路徑(argv[1])轉換為絕對路徑並存入final_path，
若final_path不是根目錄，則用unlink函數移除普通檔案，傳入final_path，成功則把ret設為0，失敗則輸出錯誤資訊，
若final_path是根目錄，則無須理會，因為根目錄永遠不能刪除，保持ret為-1，

回傳ret。

	